Logging to ./Logging/TRPO_Forward_Baseline_10_200
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 1000     |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 2000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    fps             | 84       |
|    iterations      | 1        |
|    time_elapsed    | 24       |
|    total_timesteps | 2048     |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 3000     |
| train/                    |          |
|    explained_variance     | 0.875    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00578  |
|    learning_rate          | 0.001    |
|    n_updates              | 1        |
|    policy_objective       | 0.0375   |
|    value_loss             | 0.0179   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 4000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.775    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 2        |
|    time_elapsed    | 48       |
|    total_timesteps | 4096     |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 5000     |
| train/                    |          |
|    explained_variance     | 0.864    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00528  |
|    learning_rate          | 0.001    |
|    n_updates              | 2        |
|    policy_objective       | 0.0444   |
|    value_loss             | 0.0108   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 6000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.767    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 3        |
|    time_elapsed    | 72       |
|    total_timesteps | 6144     |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 7000     |
| train/                    |          |
|    explained_variance     | 0.664    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00396  |
|    learning_rate          | 0.001    |
|    n_updates              | 3        |
|    policy_objective       | 0.0513   |
|    value_loss             | 0.00563  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 8000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    fps             | 84       |
|    iterations      | 4        |
|    time_elapsed    | 97       |
|    total_timesteps | 8192     |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 9000     |
| train/                    |          |
|    explained_variance     | 0.886    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00569  |
|    learning_rate          | 0.001    |
|    n_updates              | 4        |
|    policy_objective       | 0.0409   |
|    value_loss             | 0.0018   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 10000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    fps             | 84       |
|    iterations      | 5        |
|    time_elapsed    | 121      |
|    total_timesteps | 10240    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 11000    |
| train/                    |          |
|    explained_variance     | 0.748    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0049   |
|    learning_rate          | 0.001    |
|    n_updates              | 5        |
|    policy_objective       | 0.0536   |
|    value_loss             | 0.00161  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 12000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    fps             | 84       |
|    iterations      | 6        |
|    time_elapsed    | 145      |
|    total_timesteps | 12288    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 13000    |
| train/                    |          |
|    explained_variance     | 0.722    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00633  |
|    learning_rate          | 0.001    |
|    n_updates              | 6        |
|    policy_objective       | 0.0461   |
|    value_loss             | 0.00527  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 14000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    fps             | 84       |
|    iterations      | 7        |
|    time_elapsed    | 170      |
|    total_timesteps | 14336    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 15000    |
| train/                    |          |
|    explained_variance     | 0.905    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00651  |
|    learning_rate          | 0.001    |
|    n_updates              | 7        |
|    policy_objective       | 0.0373   |
|    value_loss             | 0.00163  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 16000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    fps             | 84       |
|    iterations      | 8        |
|    time_elapsed    | 194      |
|    total_timesteps | 16384    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 17000    |
| train/                    |          |
|    explained_variance     | 0.812    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00612  |
|    learning_rate          | 0.001    |
|    n_updates              | 8        |
|    policy_objective       | 0.0452   |
|    value_loss             | 0.00311  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 18000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    fps             | 84       |
|    iterations      | 9        |
|    time_elapsed    | 218      |
|    total_timesteps | 18432    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 19000    |
| train/                    |          |
|    explained_variance     | 0.804    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00591  |
|    learning_rate          | 0.001    |
|    n_updates              | 9        |
|    policy_objective       | 0.0434   |
|    value_loss             | 0.0024   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 20000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    fps             | 84       |
|    iterations      | 10       |
|    time_elapsed    | 242      |
|    total_timesteps | 20480    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 21000    |
| train/                    |          |
|    explained_variance     | 0.896    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00599  |
|    learning_rate          | 0.001    |
|    n_updates              | 10       |
|    policy_objective       | 0.0395   |
|    value_loss             | 0.00093  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 22000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.745    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 11       |
|    time_elapsed    | 267      |
|    total_timesteps | 22528    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 23000    |
| train/                    |          |
|    explained_variance     | 0.793    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00485  |
|    learning_rate          | 0.001    |
|    n_updates              | 11       |
|    policy_objective       | 0.0449   |
|    value_loss             | 0.00135  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 24000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 983      |
|    ep_rew_mean     | 0.776    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 12       |
|    time_elapsed    | 291      |
|    total_timesteps | 24576    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 25000    |
| train/                    |          |
|    explained_variance     | 0.816    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.001    |
|    n_updates              | 12       |
|    policy_objective       | 0.046    |
|    value_loss             | 0.0015   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 26000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    fps             | 84       |
|    iterations      | 13       |
|    time_elapsed    | 315      |
|    total_timesteps | 26624    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 27000    |
| train/                    |          |
|    explained_variance     | 0.757    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00492  |
|    learning_rate          | 0.001    |
|    n_updates              | 13       |
|    policy_objective       | 0.0515   |
|    value_loss             | 0.00254  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 28000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.796    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 14       |
|    time_elapsed    | 340      |
|    total_timesteps | 28672    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 29000    |
| train/                    |          |
|    explained_variance     | 0.838    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00527  |
|    learning_rate          | 0.001    |
|    n_updates              | 14       |
|    policy_objective       | 0.0471   |
|    value_loss             | 0.00102  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 30000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.783    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 15       |
|    time_elapsed    | 364      |
|    total_timesteps | 30720    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 31000    |
| train/                    |          |
|    explained_variance     | 0.89     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00564  |
|    learning_rate          | 0.001    |
|    n_updates              | 15       |
|    policy_objective       | 0.0455   |
|    value_loss             | 0.000642 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 32000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.781    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 16       |
|    time_elapsed    | 388      |
|    total_timesteps | 32768    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 33000    |
| train/                    |          |
|    explained_variance     | 0.827    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00611  |
|    learning_rate          | 0.001    |
|    n_updates              | 16       |
|    policy_objective       | 0.041    |
|    value_loss             | 0.00136  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 34000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.782    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 17       |
|    time_elapsed    | 413      |
|    total_timesteps | 34816    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 35000    |
| train/                    |          |
|    explained_variance     | 0.778    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0065   |
|    learning_rate          | 0.001    |
|    n_updates              | 17       |
|    policy_objective       | 0.0461   |
|    value_loss             | 0.000983 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 36000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.783    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 18       |
|    time_elapsed    | 437      |
|    total_timesteps | 36864    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 37000    |
| train/                    |          |
|    explained_variance     | 0.724    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00474  |
|    learning_rate          | 0.001    |
|    n_updates              | 18       |
|    policy_objective       | 0.043    |
|    value_loss             | 0.00112  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 38000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.779    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 19       |
|    time_elapsed    | 461      |
|    total_timesteps | 38912    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 39000    |
| train/                    |          |
|    explained_variance     | 0.868    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00504  |
|    learning_rate          | 0.001    |
|    n_updates              | 19       |
|    policy_objective       | 0.0471   |
|    value_loss             | 0.000967 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 40000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.775    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 20       |
|    time_elapsed    | 485      |
|    total_timesteps | 40960    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 41000    |
| train/                    |          |
|    explained_variance     | 0.736    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00607  |
|    learning_rate          | 0.001    |
|    n_updates              | 20       |
|    policy_objective       | 0.0385   |
|    value_loss             | 0.00132  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 42000    |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 43000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.774    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 21       |
|    time_elapsed    | 520      |
|    total_timesteps | 43008    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 44000    |
| train/                    |          |
|    explained_variance     | 0.789    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00529  |
|    learning_rate          | 0.001    |
|    n_updates              | 21       |
|    policy_objective       | 0.0413   |
|    value_loss             | 0.00111  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 45000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.773    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 22       |
|    time_elapsed    | 544      |
|    total_timesteps | 45056    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 46000    |
| train/                    |          |
|    explained_variance     | 0.874    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.006    |
|    learning_rate          | 0.001    |
|    n_updates              | 22       |
|    policy_objective       | 0.0438   |
|    value_loss             | 0.000883 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 47000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.785    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 23       |
|    time_elapsed    | 568      |
|    total_timesteps | 47104    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 48000    |
| train/                    |          |
|    explained_variance     | 0.851    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0049   |
|    learning_rate          | 0.001    |
|    n_updates              | 23       |
|    policy_objective       | 0.0589   |
|    value_loss             | 0.000805 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 49000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.782    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 24       |
|    time_elapsed    | 593      |
|    total_timesteps | 49152    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 50000    |
| train/                    |          |
|    explained_variance     | 0.6      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00524  |
|    learning_rate          | 0.001    |
|    n_updates              | 24       |
|    policy_objective       | 0.0438   |
|    value_loss             | 0.00116  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 51000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 992      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 25       |
|    time_elapsed    | 617      |
|    total_timesteps | 51200    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 52000    |
| train/                    |          |
|    explained_variance     | 0.855    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00668  |
|    learning_rate          | 0.001    |
|    n_updates              | 25       |
|    policy_objective       | 0.0444   |
|    value_loss             | 0.00117  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 53000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.785    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 26       |
|    time_elapsed    | 641      |
|    total_timesteps | 53248    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 54000    |
| train/                    |          |
|    explained_variance     | 0.778    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00458  |
|    learning_rate          | 0.001    |
|    n_updates              | 26       |
|    policy_objective       | 0.0486   |
|    value_loss             | 0.000547 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 55000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.784    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 27       |
|    time_elapsed    | 666      |
|    total_timesteps | 55296    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 56000    |
| train/                    |          |
|    explained_variance     | 0.899    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0047   |
|    learning_rate          | 0.001    |
|    n_updates              | 27       |
|    policy_objective       | 0.0384   |
|    value_loss             | 0.000311 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 57000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 998      |
|    ep_rew_mean     | 0.782    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 28       |
|    time_elapsed    | 690      |
|    total_timesteps | 57344    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 58000    |
| train/                    |          |
|    explained_variance     | 0.802    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.006    |
|    learning_rate          | 0.001    |
|    n_updates              | 28       |
|    policy_objective       | 0.036    |
|    value_loss             | 0.000796 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 59000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.783    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 29       |
|    time_elapsed    | 714      |
|    total_timesteps | 59392    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 60000    |
| train/                    |          |
|    explained_variance     | 0.83     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00617  |
|    learning_rate          | 0.001    |
|    n_updates              | 29       |
|    policy_objective       | 0.0346   |
|    value_loss             | 0.00068  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 61000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.784    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 30       |
|    time_elapsed    | 738      |
|    total_timesteps | 61440    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 62000    |
| train/                    |          |
|    explained_variance     | 0.709    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00485  |
|    learning_rate          | 0.001    |
|    n_updates              | 30       |
|    policy_objective       | 0.0534   |
|    value_loss             | 0.000694 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 63000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.794    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 31       |
|    time_elapsed    | 763      |
|    total_timesteps | 63488    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 64000    |
| train/                    |          |
|    explained_variance     | 0.872    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00547  |
|    learning_rate          | 0.001    |
|    n_updates              | 31       |
|    policy_objective       | 0.0499   |
|    value_loss             | 0.000663 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 65000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 999      |
|    ep_rew_mean     | 0.794    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 32       |
|    time_elapsed    | 787      |
|    total_timesteps | 65536    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 66000    |
| train/                    |          |
|    explained_variance     | 0.703    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00407  |
|    learning_rate          | 0.001    |
|    n_updates              | 32       |
|    policy_objective       | 0.0641   |
|    value_loss             | 0.000495 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 67000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.794    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 33       |
|    time_elapsed    | 811      |
|    total_timesteps | 67584    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 68000    |
| train/                    |          |
|    explained_variance     | 0.74     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00395  |
|    learning_rate          | 0.001    |
|    n_updates              | 33       |
|    policy_objective       | 0.0659   |
|    value_loss             | 0.000366 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 69000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.794    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 34       |
|    time_elapsed    | 836      |
|    total_timesteps | 69632    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 70000    |
| train/                    |          |
|    explained_variance     | 0.76     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00436  |
|    learning_rate          | 0.001    |
|    n_updates              | 34       |
|    policy_objective       | 0.0566   |
|    value_loss             | 0.000592 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 71000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 993      |
|    ep_rew_mean     | 0.797    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 35       |
|    time_elapsed    | 860      |
|    total_timesteps | 71680    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 72000    |
| train/                    |          |
|    explained_variance     | 0.821    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00535  |
|    learning_rate          | 0.001    |
|    n_updates              | 35       |
|    policy_objective       | 0.0658   |
|    value_loss             | 0.000856 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 73000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.805    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 36       |
|    time_elapsed    | 884      |
|    total_timesteps | 73728    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 74000    |
| train/                    |          |
|    explained_variance     | 0.852    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00457  |
|    learning_rate          | 0.001    |
|    n_updates              | 36       |
|    policy_objective       | 0.0541   |
|    value_loss             | 0.00101  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 75000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 994      |
|    ep_rew_mean     | 0.805    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 37       |
|    time_elapsed    | 909      |
|    total_timesteps | 75776    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 76000    |
| train/                    |          |
|    explained_variance     | 0.94     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00566  |
|    learning_rate          | 0.001    |
|    n_updates              | 37       |
|    policy_objective       | 0.0519   |
|    value_loss             | 0.000419 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 77000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.813    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 38       |
|    time_elapsed    | 933      |
|    total_timesteps | 77824    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 78000    |
| train/                    |          |
|    explained_variance     | 0.782    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00579  |
|    learning_rate          | 0.001    |
|    n_updates              | 38       |
|    policy_objective       | 0.0536   |
|    value_loss             | 0.000768 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 79000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 999      |
|    ep_rew_mean     | 0.814    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 39       |
|    time_elapsed    | 957      |
|    total_timesteps | 79872    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 80000    |
| train/                    |          |
|    explained_variance     | 0.895    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 39       |
|    policy_objective       | 0.058    |
|    value_loss             | 0.000446 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 81000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 992      |
|    ep_rew_mean     | 0.815    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 40       |
|    time_elapsed    | 981      |
|    total_timesteps | 81920    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 82000    |
| train/                    |          |
|    explained_variance     | 0.819    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00517  |
|    learning_rate          | 0.001    |
|    n_updates              | 40       |
|    policy_objective       | 0.0539   |
|    value_loss             | 0.000493 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 83000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.825    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 41       |
|    time_elapsed    | 1006     |
|    total_timesteps | 83968    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 84000    |
| train/                    |          |
|    explained_variance     | 0.881    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00547  |
|    learning_rate          | 0.001    |
|    n_updates              | 41       |
|    policy_objective       | 0.0461   |
|    value_loss             | 0.000829 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 85000    |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 86000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 995      |
|    ep_rew_mean     | 0.835    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 42       |
|    time_elapsed    | 1040     |
|    total_timesteps | 86016    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 87000    |
| train/                    |          |
|    explained_variance     | 0.751    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00673  |
|    learning_rate          | 0.001    |
|    n_updates              | 42       |
|    policy_objective       | 0.0428   |
|    value_loss             | 0.00134  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 88000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 999      |
|    ep_rew_mean     | 0.851    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 43       |
|    time_elapsed    | 1064     |
|    total_timesteps | 88064    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 89000    |
| train/                    |          |
|    explained_variance     | 0.843    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00507  |
|    learning_rate          | 0.001    |
|    n_updates              | 43       |
|    policy_objective       | 0.0517   |
|    value_loss             | 0.00071  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 90000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.856    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 44       |
|    time_elapsed    | 1089     |
|    total_timesteps | 90112    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 91000    |
| train/                    |          |
|    explained_variance     | 0.888    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00457  |
|    learning_rate          | 0.001    |
|    n_updates              | 44       |
|    policy_objective       | 0.0456   |
|    value_loss             | 0.000418 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 92000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.862    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 45       |
|    time_elapsed    | 1113     |
|    total_timesteps | 92160    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 93000    |
| train/                    |          |
|    explained_variance     | 0.883    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00564  |
|    learning_rate          | 0.001    |
|    n_updates              | 45       |
|    policy_objective       | 0.0451   |
|    value_loss             | 0.000687 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 94000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 997      |
|    ep_rew_mean     | 0.862    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 46       |
|    time_elapsed    | 1137     |
|    total_timesteps | 94208    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 95000    |
| train/                    |          |
|    explained_variance     | 0.915    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00588  |
|    learning_rate          | 0.001    |
|    n_updates              | 46       |
|    policy_objective       | 0.0523   |
|    value_loss             | 0.000445 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 96000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 997      |
|    ep_rew_mean     | 0.871    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 47       |
|    time_elapsed    | 1162     |
|    total_timesteps | 96256    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 97000    |
| train/                    |          |
|    explained_variance     | 0.893    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00693  |
|    learning_rate          | 0.001    |
|    n_updates              | 47       |
|    policy_objective       | 0.0465   |
|    value_loss             | 0.00101  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 98000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.882    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 48       |
|    time_elapsed    | 1186     |
|    total_timesteps | 98304    |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 99000    |
| train/                    |          |
|    explained_variance     | 0.832    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00547  |
|    learning_rate          | 0.001    |
|    n_updates              | 48       |
|    policy_objective       | 0.043    |
|    value_loss             | 0.00065  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 100000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 996      |
|    ep_rew_mean     | 0.889    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 49       |
|    time_elapsed    | 1210     |
|    total_timesteps | 100352   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 101000   |
| train/                    |          |
|    explained_variance     | 0.799    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00687  |
|    learning_rate          | 0.001    |
|    n_updates              | 49       |
|    policy_objective       | 0.0415   |
|    value_loss             | 0.00153  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 102000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 992      |
|    ep_rew_mean     | 0.905    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 50       |
|    time_elapsed    | 1235     |
|    total_timesteps | 102400   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 103000   |
| train/                    |          |
|    explained_variance     | 0.727    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00611  |
|    learning_rate          | 0.001    |
|    n_updates              | 50       |
|    policy_objective       | 0.0449   |
|    value_loss             | 0.0011   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 104000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 998      |
|    ep_rew_mean     | 0.914    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 51       |
|    time_elapsed    | 1259     |
|    total_timesteps | 104448   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 105000   |
| train/                    |          |
|    explained_variance     | 0.864    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 51       |
|    policy_objective       | 0.0546   |
|    value_loss             | 0.000432 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 106000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.929    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 52       |
|    time_elapsed    | 1283     |
|    total_timesteps | 106496   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 107000   |
| train/                    |          |
|    explained_variance     | 0.836    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00579  |
|    learning_rate          | 0.001    |
|    n_updates              | 52       |
|    policy_objective       | 0.0426   |
|    value_loss             | 0.000742 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 108000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 999      |
|    ep_rew_mean     | 0.932    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 53       |
|    time_elapsed    | 1307     |
|    total_timesteps | 108544   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 109000   |
| train/                    |          |
|    explained_variance     | 0.896    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00572  |
|    learning_rate          | 0.001    |
|    n_updates              | 53       |
|    policy_objective       | 0.0484   |
|    value_loss             | 0.000494 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 110000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.946    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 54       |
|    time_elapsed    | 1332     |
|    total_timesteps | 110592   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 111000   |
| train/                    |          |
|    explained_variance     | 0.879    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00499  |
|    learning_rate          | 0.001    |
|    n_updates              | 54       |
|    policy_objective       | 0.0638   |
|    value_loss             | 0.000317 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 112000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.95     |
| time/              |          |
|    fps             | 83       |
|    iterations      | 55       |
|    time_elapsed    | 1356     |
|    total_timesteps | 112640   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 113000   |
| train/                    |          |
|    explained_variance     | 0.871    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00527  |
|    learning_rate          | 0.001    |
|    n_updates              | 55       |
|    policy_objective       | 0.0429   |
|    value_loss             | 0.000333 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 114000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.951    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 56       |
|    time_elapsed    | 1380     |
|    total_timesteps | 114688   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 115000   |
| train/                    |          |
|    explained_variance     | 0.906    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00566  |
|    learning_rate          | 0.001    |
|    n_updates              | 56       |
|    policy_objective       | 0.0434   |
|    value_loss             | 0.000388 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 116000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 987      |
|    ep_rew_mean     | 0.961    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 57       |
|    time_elapsed    | 1405     |
|    total_timesteps | 116736   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 117000   |
| train/                    |          |
|    explained_variance     | 0.835    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00618  |
|    learning_rate          | 0.001    |
|    n_updates              | 57       |
|    policy_objective       | 0.0459   |
|    value_loss             | 0.00143  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 118000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 990      |
|    ep_rew_mean     | 0.971    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 58       |
|    time_elapsed    | 1429     |
|    total_timesteps | 118784   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 119000   |
| train/                    |          |
|    explained_variance     | 0.877    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00592  |
|    learning_rate          | 0.001    |
|    n_updates              | 58       |
|    policy_objective       | 0.0417   |
|    value_loss             | 0.00106  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 120000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 988      |
|    ep_rew_mean     | 0.982    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 59       |
|    time_elapsed    | 1453     |
|    total_timesteps | 120832   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 121000   |
| train/                    |          |
|    explained_variance     | 0.89     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00686  |
|    learning_rate          | 0.001    |
|    n_updates              | 59       |
|    policy_objective       | 0.0362   |
|    value_loss             | 0.00104  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 122000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 989      |
|    ep_rew_mean     | 0.99     |
| time/              |          |
|    fps             | 83       |
|    iterations      | 60       |
|    time_elapsed    | 1478     |
|    total_timesteps | 122880   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 123000   |
| train/                    |          |
|    explained_variance     | 0.825    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00727  |
|    learning_rate          | 0.001    |
|    n_updates              | 60       |
|    policy_objective       | 0.0337   |
|    value_loss             | 0.00175  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 124000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 988      |
|    ep_rew_mean     | 0.994    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 61       |
|    time_elapsed    | 1502     |
|    total_timesteps | 124928   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 125000   |
| train/                    |          |
|    explained_variance     | 0.905    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00589  |
|    learning_rate          | 0.001    |
|    n_updates              | 61       |
|    policy_objective       | 0.0377   |
|    value_loss             | 0.000812 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 126000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 975      |
|    ep_rew_mean     | 1.01     |
| time/              |          |
|    fps             | 83       |
|    iterations      | 62       |
|    time_elapsed    | 1526     |
|    total_timesteps | 126976   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 127000   |
| train/                    |          |
|    explained_variance     | 0.856    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00665  |
|    learning_rate          | 0.001    |
|    n_updates              | 62       |
|    policy_objective       | 0.0421   |
|    value_loss             | 0.00123  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 128000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 129000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 980      |
|    ep_rew_mean     | 1.02     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 63       |
|    time_elapsed    | 1560     |
|    total_timesteps | 129024   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 130000   |
| train/                    |          |
|    explained_variance     | 0.847    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00597  |
|    learning_rate          | 0.001    |
|    n_updates              | 63       |
|    policy_objective       | 0.029    |
|    value_loss             | 0.000981 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 131000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 980      |
|    ep_rew_mean     | 1.02     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 64       |
|    time_elapsed    | 1585     |
|    total_timesteps | 131072   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 132000   |
| train/                    |          |
|    explained_variance     | 0.968    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00459  |
|    learning_rate          | 0.001    |
|    n_updates              | 64       |
|    policy_objective       | 0.0609   |
|    value_loss             | 0.000116 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 133000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 980      |
|    ep_rew_mean     | 1.02     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 65       |
|    time_elapsed    | 1609     |
|    total_timesteps | 133120   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 134000   |
| train/                    |          |
|    explained_variance     | 0.971    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00514  |
|    learning_rate          | 0.001    |
|    n_updates              | 65       |
|    policy_objective       | 0.046    |
|    value_loss             | 9.88e-05 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 135000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 980      |
|    ep_rew_mean     | 1.02     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 66       |
|    time_elapsed    | 1633     |
|    total_timesteps | 135168   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 136000   |
| train/                    |          |
|    explained_variance     | 0.973    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00598  |
|    learning_rate          | 0.001    |
|    n_updates              | 66       |
|    policy_objective       | 0.0535   |
|    value_loss             | 0.000122 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 137000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 967      |
|    ep_rew_mean     | 1.03     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 67       |
|    time_elapsed    | 1658     |
|    total_timesteps | 137216   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 138000   |
| train/                    |          |
|    explained_variance     | 0.859    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00519  |
|    learning_rate          | 0.001    |
|    n_updates              | 67       |
|    policy_objective       | 0.032    |
|    value_loss             | 0.00142  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 139000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 970      |
|    ep_rew_mean     | 1.04     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 68       |
|    time_elapsed    | 1682     |
|    total_timesteps | 139264   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 140000   |
| train/                    |          |
|    explained_variance     | 0.877    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00723  |
|    learning_rate          | 0.001    |
|    n_updates              | 68       |
|    policy_objective       | 0.0302   |
|    value_loss             | 0.00132  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 141000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 964      |
|    ep_rew_mean     | 1.06     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 69       |
|    time_elapsed    | 1706     |
|    total_timesteps | 141312   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 142000   |
| train/                    |          |
|    explained_variance     | 0.816    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00639  |
|    learning_rate          | 0.001    |
|    n_updates              | 69       |
|    policy_objective       | 0.0353   |
|    value_loss             | 0.00184  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 143000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 962      |
|    ep_rew_mean     | 1.06     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 70       |
|    time_elapsed    | 1731     |
|    total_timesteps | 143360   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 144000   |
| train/                    |          |
|    explained_variance     | 0.969    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.001    |
|    n_updates              | 70       |
|    policy_objective       | 0.0471   |
|    value_loss             | 0.00013  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 145000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 969      |
|    ep_rew_mean     | 1.07     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 71       |
|    time_elapsed    | 1755     |
|    total_timesteps | 145408   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 146000   |
| train/                    |          |
|    explained_variance     | 0.845    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00714  |
|    learning_rate          | 0.001    |
|    n_updates              | 71       |
|    policy_objective       | 0.0423   |
|    value_loss             | 0.00158  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 147000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 953      |
|    ep_rew_mean     | 1.08     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 72       |
|    time_elapsed    | 1779     |
|    total_timesteps | 147456   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 148000   |
| train/                    |          |
|    explained_variance     | 0.949    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00471  |
|    learning_rate          | 0.001    |
|    n_updates              | 72       |
|    policy_objective       | 0.0463   |
|    value_loss             | 0.000423 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 149000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 960      |
|    ep_rew_mean     | 1.09     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 73       |
|    time_elapsed    | 1803     |
|    total_timesteps | 149504   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 150000   |
| train/                    |          |
|    explained_variance     | 0.836    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00708  |
|    learning_rate          | 0.001    |
|    n_updates              | 73       |
|    policy_objective       | 0.0397   |
|    value_loss             | 0.000976 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 151000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 952      |
|    ep_rew_mean     | 1.1      |
| time/              |          |
|    fps             | 82       |
|    iterations      | 74       |
|    time_elapsed    | 1828     |
|    total_timesteps | 151552   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 152000   |
| train/                    |          |
|    explained_variance     | 0.877    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00664  |
|    learning_rate          | 0.001    |
|    n_updates              | 74       |
|    policy_objective       | 0.0351   |
|    value_loss             | 0.0016   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 153000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 952      |
|    ep_rew_mean     | 1.12     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 75       |
|    time_elapsed    | 1852     |
|    total_timesteps | 153600   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 154000   |
| train/                    |          |
|    explained_variance     | 0.824    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00734  |
|    learning_rate          | 0.001    |
|    n_updates              | 75       |
|    policy_objective       | 0.0256   |
|    value_loss             | 0.00243  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 155000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 939      |
|    ep_rew_mean     | 1.14     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 76       |
|    time_elapsed    | 1876     |
|    total_timesteps | 155648   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 156000   |
| train/                    |          |
|    explained_variance     | 0.795    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00697  |
|    learning_rate          | 0.001    |
|    n_updates              | 76       |
|    policy_objective       | 0.0242   |
|    value_loss             | 0.00256  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 157000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 927      |
|    ep_rew_mean     | 1.16     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 77       |
|    time_elapsed    | 1901     |
|    total_timesteps | 157696   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 158000   |
| train/                    |          |
|    explained_variance     | 0.813    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00666  |
|    learning_rate          | 0.001    |
|    n_updates              | 77       |
|    policy_objective       | 0.0287   |
|    value_loss             | 0.00273  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 159000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 930      |
|    ep_rew_mean     | 1.16     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 78       |
|    time_elapsed    | 1925     |
|    total_timesteps | 159744   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 160000   |
| train/                    |          |
|    explained_variance     | 0.807    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00834  |
|    learning_rate          | 0.001    |
|    n_updates              | 78       |
|    policy_objective       | 0.0265   |
|    value_loss             | 0.00151  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 161000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 911      |
|    ep_rew_mean     | 1.17     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 79       |
|    time_elapsed    | 1949     |
|    total_timesteps | 161792   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 162000   |
| train/                    |          |
|    explained_variance     | 0.885    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00654  |
|    learning_rate          | 0.001    |
|    n_updates              | 79       |
|    policy_objective       | 0.0269   |
|    value_loss             | 0.00144  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 163000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 909      |
|    ep_rew_mean     | 1.18     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 80       |
|    time_elapsed    | 1974     |
|    total_timesteps | 163840   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 164000   |
| train/                    |          |
|    explained_variance     | 0.816    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00674  |
|    learning_rate          | 0.001    |
|    n_updates              | 80       |
|    policy_objective       | 0.0522   |
|    value_loss             | 0.00228  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 165000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 907      |
|    ep_rew_mean     | 1.19     |
| time/              |          |
|    fps             | 83       |
|    iterations      | 81       |
|    time_elapsed    | 1998     |
|    total_timesteps | 165888   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 166000   |
| train/                    |          |
|    explained_variance     | 0.851    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00555  |
|    learning_rate          | 0.001    |
|    n_updates              | 81       |
|    policy_objective       | 0.037    |
|    value_loss             | 0.00163  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 167000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 887      |
|    ep_rew_mean     | 1.2      |
| time/              |          |
|    fps             | 83       |
|    iterations      | 82       |
|    time_elapsed    | 2022     |
|    total_timesteps | 167936   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 168000   |
| train/                    |          |
|    explained_variance     | 0.886    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00712  |
|    learning_rate          | 0.001    |
|    n_updates              | 82       |
|    policy_objective       | 0.0273   |
|    value_loss             | 0.00174  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 169000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 874      |
|    ep_rew_mean     | 1.21     |
| time/              |          |
|    fps             | 83       |
|    iterations      | 83       |
|    time_elapsed    | 2047     |
|    total_timesteps | 169984   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 170000   |
| train/                    |          |
|    explained_variance     | 0.751    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00845  |
|    learning_rate          | 0.001    |
|    n_updates              | 83       |
|    policy_objective       | 0.0236   |
|    value_loss             | 0.00306  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 171000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 172000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 876      |
|    ep_rew_mean     | 1.22     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 84       |
|    time_elapsed    | 2081     |
|    total_timesteps | 172032   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 173000   |
| train/                    |          |
|    explained_variance     | 0.754    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00829  |
|    learning_rate          | 0.001    |
|    n_updates              | 84       |
|    policy_objective       | 0.0209   |
|    value_loss             | 0.00334  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 174000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 877      |
|    ep_rew_mean     | 1.22     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 85       |
|    time_elapsed    | 2105     |
|    total_timesteps | 174080   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 175000   |
| train/                    |          |
|    explained_variance     | 0.807    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00694  |
|    learning_rate          | 0.001    |
|    n_updates              | 85       |
|    policy_objective       | 0.0228   |
|    value_loss             | 0.00165  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 176000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 853      |
|    ep_rew_mean     | 1.22     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 86       |
|    time_elapsed    | 2129     |
|    total_timesteps | 176128   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 177000   |
| train/                    |          |
|    explained_variance     | 0.803    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00759  |
|    learning_rate          | 0.001    |
|    n_updates              | 86       |
|    policy_objective       | 0.0236   |
|    value_loss             | 0.00298  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 178000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 857      |
|    ep_rew_mean     | 1.23     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 87       |
|    time_elapsed    | 2154     |
|    total_timesteps | 178176   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 179000   |
| train/                    |          |
|    explained_variance     | 0.796    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00683  |
|    learning_rate          | 0.001    |
|    n_updates              | 87       |
|    policy_objective       | 0.0255   |
|    value_loss             | 0.00222  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 180000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 842      |
|    ep_rew_mean     | 1.23     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 88       |
|    time_elapsed    | 2178     |
|    total_timesteps | 180224   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 181000   |
| train/                    |          |
|    explained_variance     | 0.95     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00566  |
|    learning_rate          | 0.001    |
|    n_updates              | 88       |
|    policy_objective       | 0.0537   |
|    value_loss             | 0.000716 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 182000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 824      |
|    ep_rew_mean     | 1.23     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 89       |
|    time_elapsed    | 2202     |
|    total_timesteps | 182272   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 183000   |
| train/                    |          |
|    explained_variance     | 0.953    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00753  |
|    learning_rate          | 0.001    |
|    n_updates              | 89       |
|    policy_objective       | 0.0579   |
|    value_loss             | 0.000595 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 184000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 822      |
|    ep_rew_mean     | 1.21     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 90       |
|    time_elapsed    | 2227     |
|    total_timesteps | 184320   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 185000   |
| train/                    |          |
|    explained_variance     | 0.835    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00868  |
|    learning_rate          | 0.001    |
|    n_updates              | 90       |
|    policy_objective       | 0.0218   |
|    value_loss             | 0.00164  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 186000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 809      |
|    ep_rew_mean     | 1.21     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 91       |
|    time_elapsed    | 2251     |
|    total_timesteps | 186368   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 187000   |
| train/                    |          |
|    explained_variance     | 0.839    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00518  |
|    learning_rate          | 0.001    |
|    n_updates              | 91       |
|    policy_objective       | 0.0339   |
|    value_loss             | 0.00204  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 188000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 808      |
|    ep_rew_mean     | 1.21     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 92       |
|    time_elapsed    | 2275     |
|    total_timesteps | 188416   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 189000   |
| train/                    |          |
|    explained_variance     | 0.751    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00688  |
|    learning_rate          | 0.001    |
|    n_updates              | 92       |
|    policy_objective       | 0.0193   |
|    value_loss             | 0.00194  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 190000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 809      |
|    ep_rew_mean     | 1.22     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 93       |
|    time_elapsed    | 2300     |
|    total_timesteps | 190464   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 191000   |
| train/                    |          |
|    explained_variance     | 0.7      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00922  |
|    learning_rate          | 0.001    |
|    n_updates              | 93       |
|    policy_objective       | 0.0224   |
|    value_loss             | 0.00329  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 192000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 804      |
|    ep_rew_mean     | 1.25     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 94       |
|    time_elapsed    | 2324     |
|    total_timesteps | 192512   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 193000   |
| train/                    |          |
|    explained_variance     | 0.748    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00801  |
|    learning_rate          | 0.001    |
|    n_updates              | 94       |
|    policy_objective       | 0.0229   |
|    value_loss             | 0.00314  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 194000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 800      |
|    ep_rew_mean     | 1.26     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 95       |
|    time_elapsed    | 2348     |
|    total_timesteps | 194560   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 195000   |
| train/                    |          |
|    explained_variance     | 0.835    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00809  |
|    learning_rate          | 0.001    |
|    n_updates              | 95       |
|    policy_objective       | 0.0196   |
|    value_loss             | 0.00154  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 196000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 806      |
|    ep_rew_mean     | 1.26     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 96       |
|    time_elapsed    | 2372     |
|    total_timesteps | 196608   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 197000   |
| train/                    |          |
|    explained_variance     | 0.806    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00806  |
|    learning_rate          | 0.001    |
|    n_updates              | 96       |
|    policy_objective       | 0.0242   |
|    value_loss             | 0.00157  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 198000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 813      |
|    ep_rew_mean     | 1.25     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 97       |
|    time_elapsed    | 2397     |
|    total_timesteps | 198656   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 199000   |
| train/                    |          |
|    explained_variance     | 0.977    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00571  |
|    learning_rate          | 0.001    |
|    n_updates              | 97       |
|    policy_objective       | 0.038    |
|    value_loss             | 7.98e-05 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 200000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 795      |
|    ep_rew_mean     | 1.24     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 98       |
|    time_elapsed    | 2421     |
|    total_timesteps | 200704   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 201000   |
| train/                    |          |
|    explained_variance     | 0.929    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0073   |
|    learning_rate          | 0.001    |
|    n_updates              | 98       |
|    policy_objective       | 0.0673   |
|    value_loss             | 0.000631 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 202000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 776      |
|    ep_rew_mean     | 1.22     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 99       |
|    time_elapsed    | 2445     |
|    total_timesteps | 202752   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 203000   |
| train/                    |          |
|    explained_variance     | 0.949    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00452  |
|    learning_rate          | 0.001    |
|    n_updates              | 99       |
|    policy_objective       | 0.0869   |
|    value_loss             | 0.000394 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 204000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 756      |
|    ep_rew_mean     | 1.22     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 100      |
|    time_elapsed    | 2470     |
|    total_timesteps | 204800   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 205000   |
| train/                    |          |
|    explained_variance     | 0.753    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00829  |
|    learning_rate          | 0.001    |
|    n_updates              | 100      |
|    policy_objective       | 0.0255   |
|    value_loss             | 0.0044   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 206000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 734      |
|    ep_rew_mean     | 1.24     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 101      |
|    time_elapsed    | 2494     |
|    total_timesteps | 206848   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 207000   |
| train/                    |          |
|    explained_variance     | 0.822    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00665  |
|    learning_rate          | 0.001    |
|    n_updates              | 101      |
|    policy_objective       | 0.0528   |
|    value_loss             | 0.00249  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 208000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 715      |
|    ep_rew_mean     | 1.25     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 102      |
|    time_elapsed    | 2518     |
|    total_timesteps | 208896   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 209000   |
| train/                    |          |
|    explained_variance     | 0.797    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00762  |
|    learning_rate          | 0.001    |
|    n_updates              | 102      |
|    policy_objective       | 0.0231   |
|    value_loss             | 0.00375  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 210000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 688      |
|    ep_rew_mean     | 1.23     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 103      |
|    time_elapsed    | 2543     |
|    total_timesteps | 210944   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 211000   |
| train/                    |          |
|    explained_variance     | 0.982    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0068   |
|    learning_rate          | 0.001    |
|    n_updates              | 103      |
|    policy_objective       | 0.0541   |
|    value_loss             | 0.00018  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 212000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 690      |
|    ep_rew_mean     | 1.24     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 104      |
|    time_elapsed    | 2567     |
|    total_timesteps | 212992   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 213000   |
| train/                    |          |
|    explained_variance     | 0.74     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00915  |
|    learning_rate          | 0.001    |
|    n_updates              | 104      |
|    policy_objective       | 0.0204   |
|    value_loss             | 0.0017   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 214000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 215000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 673      |
|    ep_rew_mean     | 1.23     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 105      |
|    time_elapsed    | 2601     |
|    total_timesteps | 215040   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 216000   |
| train/                    |          |
|    explained_variance     | 0.802    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00833  |
|    learning_rate          | 0.001    |
|    n_updates              | 105      |
|    policy_objective       | 0.0164   |
|    value_loss             | 0.00356  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 217000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 657      |
|    ep_rew_mean     | 1.23     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 106      |
|    time_elapsed    | 2626     |
|    total_timesteps | 217088   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 218000   |
| train/                    |          |
|    explained_variance     | 0.754    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00909  |
|    learning_rate          | 0.001    |
|    n_updates              | 106      |
|    policy_objective       | 0.0226   |
|    value_loss             | 0.0037   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 219000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 653      |
|    ep_rew_mean     | 1.23     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 107      |
|    time_elapsed    | 2650     |
|    total_timesteps | 219136   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 220000   |
| train/                    |          |
|    explained_variance     | 0.824    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00669  |
|    learning_rate          | 0.001    |
|    n_updates              | 107      |
|    policy_objective       | 0.0273   |
|    value_loss             | 0.0021   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 221000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 665      |
|    ep_rew_mean     | 1.23     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 108      |
|    time_elapsed    | 2674     |
|    total_timesteps | 221184   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 222000   |
| train/                    |          |
|    explained_variance     | 0.793    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00823  |
|    learning_rate          | 0.001    |
|    n_updates              | 108      |
|    policy_objective       | 0.0208   |
|    value_loss             | 0.00185  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 223000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 655      |
|    ep_rew_mean     | 1.21     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 109      |
|    time_elapsed    | 2698     |
|    total_timesteps | 223232   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 224000   |
| train/                    |          |
|    explained_variance     | 0.758    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00925  |
|    learning_rate          | 0.001    |
|    n_updates              | 109      |
|    policy_objective       | 0.0196   |
|    value_loss             | 0.00212  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 225000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 629      |
|    ep_rew_mean     | 1.21     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 110      |
|    time_elapsed    | 2723     |
|    total_timesteps | 225280   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 226000   |
| train/                    |          |
|    explained_variance     | 0.791    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00879  |
|    learning_rate          | 0.001    |
|    n_updates              | 110      |
|    policy_objective       | 0.0174   |
|    value_loss             | 0.00412  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 227000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 610      |
|    ep_rew_mean     | 1.2      |
| time/              |          |
|    fps             | 82       |
|    iterations      | 111      |
|    time_elapsed    | 2747     |
|    total_timesteps | 227328   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 228000   |
| train/                    |          |
|    explained_variance     | 0.759    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00955  |
|    learning_rate          | 0.001    |
|    n_updates              | 111      |
|    policy_objective       | 0.0204   |
|    value_loss             | 0.00386  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 229000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 616      |
|    ep_rew_mean     | 1.2      |
| time/              |          |
|    fps             | 82       |
|    iterations      | 112      |
|    time_elapsed    | 2771     |
|    total_timesteps | 229376   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 230000   |
| train/                    |          |
|    explained_variance     | 0.645    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00919  |
|    learning_rate          | 0.001    |
|    n_updates              | 112      |
|    policy_objective       | 0.0173   |
|    value_loss             | 0.00391  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 231000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 620      |
|    ep_rew_mean     | 1.2      |
| time/              |          |
|    fps             | 82       |
|    iterations      | 113      |
|    time_elapsed    | 2796     |
|    total_timesteps | 231424   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 232000   |
| train/                    |          |
|    explained_variance     | 0.696    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00811  |
|    learning_rate          | 0.001    |
|    n_updates              | 113      |
|    policy_objective       | 0.0184   |
|    value_loss             | 0.00224  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 233000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 620      |
|    ep_rew_mean     | 1.2      |
| time/              |          |
|    fps             | 82       |
|    iterations      | 114      |
|    time_elapsed    | 2820     |
|    total_timesteps | 233472   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 234000   |
| train/                    |          |
|    explained_variance     | 0.649    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00882  |
|    learning_rate          | 0.001    |
|    n_updates              | 114      |
|    policy_objective       | 0.0145   |
|    value_loss             | 0.00211  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 235000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 612      |
|    ep_rew_mean     | 1.2      |
| time/              |          |
|    fps             | 82       |
|    iterations      | 115      |
|    time_elapsed    | 2844     |
|    total_timesteps | 235520   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 236000   |
| train/                    |          |
|    explained_variance     | 0.729    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0095   |
|    learning_rate          | 0.001    |
|    n_updates              | 115      |
|    policy_objective       | 0.0163   |
|    value_loss             | 0.00417  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 237000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 611      |
|    ep_rew_mean     | 1.2      |
| time/              |          |
|    fps             | 82       |
|    iterations      | 116      |
|    time_elapsed    | 2869     |
|    total_timesteps | 237568   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 238000   |
| train/                    |          |
|    explained_variance     | 0.813    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00552  |
|    learning_rate          | 0.001    |
|    n_updates              | 116      |
|    policy_objective       | 0.0365   |
|    value_loss             | 0.0027   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 239000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 592      |
|    ep_rew_mean     | 1.2      |
| time/              |          |
|    fps             | 82       |
|    iterations      | 117      |
|    time_elapsed    | 2893     |
|    total_timesteps | 239616   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 240000   |
| train/                    |          |
|    explained_variance     | 0.751    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00733  |
|    learning_rate          | 0.001    |
|    n_updates              | 117      |
|    policy_objective       | 0.0189   |
|    value_loss             | 0.00461  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 241000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 601      |
|    ep_rew_mean     | 1.2      |
| time/              |          |
|    fps             | 82       |
|    iterations      | 118      |
|    time_elapsed    | 2917     |
|    total_timesteps | 241664   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 242000   |
| train/                    |          |
|    explained_variance     | 0.727    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0077   |
|    learning_rate          | 0.001    |
|    n_updates              | 118      |
|    policy_objective       | 0.0405   |
|    value_loss             | 0.00246  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 243000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 596      |
|    ep_rew_mean     | 1.2      |
| time/              |          |
|    fps             | 82       |
|    iterations      | 119      |
|    time_elapsed    | 2942     |
|    total_timesteps | 243712   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 244000   |
| train/                    |          |
|    explained_variance     | 0.66     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00923  |
|    learning_rate          | 0.001    |
|    n_updates              | 119      |
|    policy_objective       | 0.024    |
|    value_loss             | 0.00236  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 245000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 598      |
|    ep_rew_mean     | 1.21     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 120      |
|    time_elapsed    | 2966     |
|    total_timesteps | 245760   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 246000   |
| train/                    |          |
|    explained_variance     | 0.84     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00824  |
|    learning_rate          | 0.001    |
|    n_updates              | 120      |
|    policy_objective       | 0.0205   |
|    value_loss             | 0.00205  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 247000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 599      |
|    ep_rew_mean     | 1.22     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 121      |
|    time_elapsed    | 2990     |
|    total_timesteps | 247808   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 248000   |
| train/                    |          |
|    explained_variance     | 0.642    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0085   |
|    learning_rate          | 0.001    |
|    n_updates              | 121      |
|    policy_objective       | 0.0112   |
|    value_loss             | 0.00394  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 249000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 564      |
|    ep_rew_mean     | 1.19     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 122      |
|    time_elapsed    | 3015     |
|    total_timesteps | 249856   |
---------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+03    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 250000   |
| train/                    |          |
|    explained_variance     | 0.85     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0069   |
|    learning_rate          | 0.001    |
|    n_updates              | 122      |
|    policy_objective       | 0.0427   |
|    value_loss             | 0.00226  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 251000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 558      |
|    ep_rew_mean     | 1.18     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 123      |
|    time_elapsed    | 3039     |
|    total_timesteps | 251904   |
---------------------------------
