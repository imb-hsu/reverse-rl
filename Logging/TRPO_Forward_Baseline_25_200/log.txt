Logging to ./Logging/TRPO_Forward_Baseline_25_200
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 1000     |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 2000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 1    |
|    time_elapsed    | 204  |
|    total_timesteps | 2048 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 3000     |
| train/                    |          |
|    explained_variance     | 0.55     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00463  |
|    learning_rate          | 0.001    |
|    n_updates              | 1        |
|    policy_objective       | 0.0691   |
|    value_loss             | 0.00215  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 4000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 2    |
|    time_elapsed    | 408  |
|    total_timesteps | 4096 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 5000     |
| train/                    |          |
|    explained_variance     | 0.797    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00547  |
|    learning_rate          | 0.001    |
|    n_updates              | 2        |
|    policy_objective       | 0.0473   |
|    value_loss             | 0.00751  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 6000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 3    |
|    time_elapsed    | 612  |
|    total_timesteps | 6144 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 7000     |
| train/                    |          |
|    explained_variance     | 0.787    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00564  |
|    learning_rate          | 0.001    |
|    n_updates              | 3        |
|    policy_objective       | 0.0513   |
|    value_loss             | 0.00977  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 8000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 4    |
|    time_elapsed    | 817  |
|    total_timesteps | 8192 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 9000     |
| train/                    |          |
|    explained_variance     | 0.916    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.006    |
|    learning_rate          | 0.001    |
|    n_updates              | 4        |
|    policy_objective       | 0.0397   |
|    value_loss             | 0.00108  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 10000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 5     |
|    time_elapsed    | 1021  |
|    total_timesteps | 10240 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 11000    |
| train/                    |          |
|    explained_variance     | 0.887    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00485  |
|    learning_rate          | 0.001    |
|    n_updates              | 5        |
|    policy_objective       | 0.0492   |
|    value_loss             | 0.00304  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 12000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 6     |
|    time_elapsed    | 1225  |
|    total_timesteps | 12288 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 13000    |
| train/                    |          |
|    explained_variance     | 0.851    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00545  |
|    learning_rate          | 0.001    |
|    n_updates              | 6        |
|    policy_objective       | 0.0511   |
|    value_loss             | 0.00447  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 14000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 7     |
|    time_elapsed    | 1429  |
|    total_timesteps | 14336 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 15000    |
| train/                    |          |
|    explained_variance     | 0.912    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0062   |
|    learning_rate          | 0.001    |
|    n_updates              | 7        |
|    policy_objective       | 0.0433   |
|    value_loss             | 0.0124   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 16000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 8     |
|    time_elapsed    | 1634  |
|    total_timesteps | 16384 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 17000    |
| train/                    |          |
|    explained_variance     | 0.923    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 8        |
|    policy_objective       | 0.0471   |
|    value_loss             | 0.00258  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 18000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 9     |
|    time_elapsed    | 1838  |
|    total_timesteps | 18432 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 19000    |
| train/                    |          |
|    explained_variance     | 0.885    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00522  |
|    learning_rate          | 0.001    |
|    n_updates              | 9        |
|    policy_objective       | 0.0638   |
|    value_loss             | 0.00315  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 20000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 10    |
|    time_elapsed    | 2042  |
|    total_timesteps | 20480 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 21000    |
| train/                    |          |
|    explained_variance     | 0.751    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00507  |
|    learning_rate          | 0.001    |
|    n_updates              | 10       |
|    policy_objective       | 0.0629   |
|    value_loss             | 0.00255  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 22000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 11    |
|    time_elapsed    | 2247  |
|    total_timesteps | 22528 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 23000    |
| train/                    |          |
|    explained_variance     | 0.852    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00458  |
|    learning_rate          | 0.001    |
|    n_updates              | 11       |
|    policy_objective       | 0.0589   |
|    value_loss             | 0.00268  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 24000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 12    |
|    time_elapsed    | 2451  |
|    total_timesteps | 24576 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 25000    |
| train/                    |          |
|    explained_variance     | 0.858    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00437  |
|    learning_rate          | 0.001    |
|    n_updates              | 12       |
|    policy_objective       | 0.0454   |
|    value_loss             | 0.00208  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 26000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 13    |
|    time_elapsed    | 2655  |
|    total_timesteps | 26624 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 27000    |
| train/                    |          |
|    explained_variance     | 0.875    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0058   |
|    learning_rate          | 0.001    |
|    n_updates              | 13       |
|    policy_objective       | 0.0497   |
|    value_loss             | 0.00353  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 28000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 14    |
|    time_elapsed    | 2860  |
|    total_timesteps | 28672 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 29000    |
| train/                    |          |
|    explained_variance     | 0.867    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00539  |
|    learning_rate          | 0.001    |
|    n_updates              | 14       |
|    policy_objective       | 0.0462   |
|    value_loss             | 0.00363  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 30000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 15    |
|    time_elapsed    | 3064  |
|    total_timesteps | 30720 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 31000    |
| train/                    |          |
|    explained_variance     | 0.802    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00484  |
|    learning_rate          | 0.001    |
|    n_updates              | 15       |
|    policy_objective       | 0.0604   |
|    value_loss             | 0.0018   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 32000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 16    |
|    time_elapsed    | 3268  |
|    total_timesteps | 32768 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 33000    |
| train/                    |          |
|    explained_variance     | 0.737    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00363  |
|    learning_rate          | 0.001    |
|    n_updates              | 16       |
|    policy_objective       | 0.0671   |
|    value_loss             | 0.00256  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 34000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 17    |
|    time_elapsed    | 3473  |
|    total_timesteps | 34816 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 35000    |
| train/                    |          |
|    explained_variance     | 0.87     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00564  |
|    learning_rate          | 0.001    |
|    n_updates              | 17       |
|    policy_objective       | 0.0494   |
|    value_loss             | 0.00309  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 36000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 18    |
|    time_elapsed    | 3677  |
|    total_timesteps | 36864 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 37000    |
| train/                    |          |
|    explained_variance     | 0.813    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00438  |
|    learning_rate          | 0.001    |
|    n_updates              | 18       |
|    policy_objective       | 0.051    |
|    value_loss             | 0.00322  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 38000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 19    |
|    time_elapsed    | 3881  |
|    total_timesteps | 38912 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 39000    |
| train/                    |          |
|    explained_variance     | 0.92     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00604  |
|    learning_rate          | 0.001    |
|    n_updates              | 19       |
|    policy_objective       | 0.0506   |
|    value_loss             | 0.00118  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 40000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 20    |
|    time_elapsed    | 4086  |
|    total_timesteps | 40960 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 41000    |
| train/                    |          |
|    explained_variance     | 0.808    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00403  |
|    learning_rate          | 0.001    |
|    n_updates              | 20       |
|    policy_objective       | 0.0645   |
|    value_loss             | 0.00189  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 42000    |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 43000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 21    |
|    time_elapsed    | 4390  |
|    total_timesteps | 43008 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 44000    |
| train/                    |          |
|    explained_variance     | 0.888    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00458  |
|    learning_rate          | 0.001    |
|    n_updates              | 21       |
|    policy_objective       | 0.0483   |
|    value_loss             | 0.00299  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 45000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 22    |
|    time_elapsed    | 4594  |
|    total_timesteps | 45056 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 46000    |
| train/                    |          |
|    explained_variance     | 0.863    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00603  |
|    learning_rate          | 0.001    |
|    n_updates              | 22       |
|    policy_objective       | 0.0527   |
|    value_loss             | 0.00245  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 47000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 23    |
|    time_elapsed    | 4799  |
|    total_timesteps | 47104 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 48000    |
| train/                    |          |
|    explained_variance     | 0.907    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00563  |
|    learning_rate          | 0.001    |
|    n_updates              | 23       |
|    policy_objective       | 0.0451   |
|    value_loss             | 0.00212  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 49000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 24    |
|    time_elapsed    | 5003  |
|    total_timesteps | 49152 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 50000    |
| train/                    |          |
|    explained_variance     | 0.911    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 24       |
|    policy_objective       | 0.0496   |
|    value_loss             | 0.000779 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 51000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 25    |
|    time_elapsed    | 5207  |
|    total_timesteps | 51200 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 52000    |
| train/                    |          |
|    explained_variance     | 0.799    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00539  |
|    learning_rate          | 0.001    |
|    n_updates              | 25       |
|    policy_objective       | 0.0512   |
|    value_loss             | 0.00363  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 53000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 26    |
|    time_elapsed    | 5411  |
|    total_timesteps | 53248 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 54000    |
| train/                    |          |
|    explained_variance     | 0.633    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00302  |
|    learning_rate          | 0.001    |
|    n_updates              | 26       |
|    policy_objective       | 0.073    |
|    value_loss             | 0.00184  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 55000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 27    |
|    time_elapsed    | 5616  |
|    total_timesteps | 55296 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 56000    |
| train/                    |          |
|    explained_variance     | 0.867    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00494  |
|    learning_rate          | 0.001    |
|    n_updates              | 27       |
|    policy_objective       | 0.0524   |
|    value_loss             | 0.00144  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 57000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 28    |
|    time_elapsed    | 5820  |
|    total_timesteps | 57344 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 58000    |
| train/                    |          |
|    explained_variance     | 0.923    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00604  |
|    learning_rate          | 0.001    |
|    n_updates              | 28       |
|    policy_objective       | 0.0462   |
|    value_loss             | 0.00103  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 59000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 29    |
|    time_elapsed    | 6024  |
|    total_timesteps | 59392 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 60000    |
| train/                    |          |
|    explained_variance     | 0.746    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00518  |
|    learning_rate          | 0.001    |
|    n_updates              | 29       |
|    policy_objective       | 0.0671   |
|    value_loss             | 0.00128  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 61000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 30    |
|    time_elapsed    | 6229  |
|    total_timesteps | 61440 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 62000    |
| train/                    |          |
|    explained_variance     | 0.796    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0049   |
|    learning_rate          | 0.001    |
|    n_updates              | 30       |
|    policy_objective       | 0.0506   |
|    value_loss             | 0.00145  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 63000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 31    |
|    time_elapsed    | 6433  |
|    total_timesteps | 63488 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 64000    |
| train/                    |          |
|    explained_variance     | 0.593    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00357  |
|    learning_rate          | 0.001    |
|    n_updates              | 31       |
|    policy_objective       | 0.094    |
|    value_loss             | 0.00125  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 65000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 32    |
|    time_elapsed    | 6637  |
|    total_timesteps | 65536 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 66000    |
| train/                    |          |
|    explained_variance     | 0.834    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00507  |
|    learning_rate          | 0.001    |
|    n_updates              | 32       |
|    policy_objective       | 0.0571   |
|    value_loss             | 0.000699 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 67000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 33    |
|    time_elapsed    | 6842  |
|    total_timesteps | 67584 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 68000    |
| train/                    |          |
|    explained_variance     | 0.791    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00577  |
|    learning_rate          | 0.001    |
|    n_updates              | 33       |
|    policy_objective       | 0.06     |
|    value_loss             | 0.000814 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 69000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 34    |
|    time_elapsed    | 7046  |
|    total_timesteps | 69632 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 70000    |
| train/                    |          |
|    explained_variance     | 0.864    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00487  |
|    learning_rate          | 0.001    |
|    n_updates              | 34       |
|    policy_objective       | 0.0561   |
|    value_loss             | 0.0014   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 71000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 35    |
|    time_elapsed    | 7250  |
|    total_timesteps | 71680 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 72000    |
| train/                    |          |
|    explained_variance     | 0.696    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00469  |
|    learning_rate          | 0.001    |
|    n_updates              | 35       |
|    policy_objective       | 0.059    |
|    value_loss             | 0.00177  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 73000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 36    |
|    time_elapsed    | 7455  |
|    total_timesteps | 73728 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 74000    |
| train/                    |          |
|    explained_variance     | 0.909    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00423  |
|    learning_rate          | 0.001    |
|    n_updates              | 36       |
|    policy_objective       | 0.053    |
|    value_loss             | 0.00103  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 75000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 37    |
|    time_elapsed    | 7659  |
|    total_timesteps | 75776 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 76000    |
| train/                    |          |
|    explained_variance     | 0.854    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00578  |
|    learning_rate          | 0.001    |
|    n_updates              | 37       |
|    policy_objective       | 0.0593   |
|    value_loss             | 0.00171  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 77000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 38    |
|    time_elapsed    | 7863  |
|    total_timesteps | 77824 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 78000    |
| train/                    |          |
|    explained_variance     | 0.795    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00409  |
|    learning_rate          | 0.001    |
|    n_updates              | 38       |
|    policy_objective       | 0.0687   |
|    value_loss             | 0.00122  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 79000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 39    |
|    time_elapsed    | 8068  |
|    total_timesteps | 79872 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 80000    |
| train/                    |          |
|    explained_variance     | 0.859    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00702  |
|    learning_rate          | 0.001    |
|    n_updates              | 39       |
|    policy_objective       | 0.0644   |
|    value_loss             | 0.00179  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 81000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 40    |
|    time_elapsed    | 8272  |
|    total_timesteps | 81920 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 82000    |
| train/                    |          |
|    explained_variance     | 0.847    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00679  |
|    learning_rate          | 0.001    |
|    n_updates              | 40       |
|    policy_objective       | 0.054    |
|    value_loss             | 0.00443  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 83000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 41    |
|    time_elapsed    | 8476  |
|    total_timesteps | 83968 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 84000    |
| train/                    |          |
|    explained_variance     | 0.691    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00433  |
|    learning_rate          | 0.001    |
|    n_updates              | 41       |
|    policy_objective       | 0.0493   |
|    value_loss             | 0.0017   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 85000    |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 86000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 42    |
|    time_elapsed    | 8780  |
|    total_timesteps | 86016 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 87000    |
| train/                    |          |
|    explained_variance     | 0.758    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00498  |
|    learning_rate          | 0.001    |
|    n_updates              | 42       |
|    policy_objective       | 0.0619   |
|    value_loss             | 0.00118  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 88000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 43    |
|    time_elapsed    | 8985  |
|    total_timesteps | 88064 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 89000    |
| train/                    |          |
|    explained_variance     | 0.783    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00514  |
|    learning_rate          | 0.001    |
|    n_updates              | 43       |
|    policy_objective       | 0.0503   |
|    value_loss             | 0.000909 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 90000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 44    |
|    time_elapsed    | 9189  |
|    total_timesteps | 90112 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 91000    |
| train/                    |          |
|    explained_variance     | 0.783    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00536  |
|    learning_rate          | 0.001    |
|    n_updates              | 44       |
|    policy_objective       | 0.0506   |
|    value_loss             | 0.000703 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 92000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 45    |
|    time_elapsed    | 9393  |
|    total_timesteps | 92160 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 93000    |
| train/                    |          |
|    explained_variance     | 0.288    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00414  |
|    learning_rate          | 0.001    |
|    n_updates              | 45       |
|    policy_objective       | 0.0674   |
|    value_loss             | 0.00108  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 94000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 46    |
|    time_elapsed    | 9598  |
|    total_timesteps | 94208 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 95000    |
| train/                    |          |
|    explained_variance     | 0.84     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00485  |
|    learning_rate          | 0.001    |
|    n_updates              | 46       |
|    policy_objective       | 0.0519   |
|    value_loss             | 0.000405 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 96000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 47    |
|    time_elapsed    | 9802  |
|    total_timesteps | 96256 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 97000    |
| train/                    |          |
|    explained_variance     | 0.836    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00535  |
|    learning_rate          | 0.001    |
|    n_updates              | 47       |
|    policy_objective       | 0.0536   |
|    value_loss             | 0.00131  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 98000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 48    |
|    time_elapsed    | 10006 |
|    total_timesteps | 98304 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 99000    |
| train/                    |          |
|    explained_variance     | 0.867    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00595  |
|    learning_rate          | 0.001    |
|    n_updates              | 48       |
|    policy_objective       | 0.0512   |
|    value_loss             | 0.000683 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 100000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 49     |
|    time_elapsed    | 10211  |
|    total_timesteps | 100352 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 101000   |
| train/                    |          |
|    explained_variance     | 0.782    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00471  |
|    learning_rate          | 0.001    |
|    n_updates              | 49       |
|    policy_objective       | 0.0565   |
|    value_loss             | 0.00108  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 102000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 50     |
|    time_elapsed    | 10415  |
|    total_timesteps | 102400 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 103000   |
| train/                    |          |
|    explained_variance     | 0.876    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 50       |
|    policy_objective       | 0.0528   |
|    value_loss             | 0.000928 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 104000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 51     |
|    time_elapsed    | 10619  |
|    total_timesteps | 104448 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 105000   |
| train/                    |          |
|    explained_variance     | 0.45     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00568  |
|    learning_rate          | 0.001    |
|    n_updates              | 51       |
|    policy_objective       | 0.0518   |
|    value_loss             | 0.000853 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 106000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 52     |
|    time_elapsed    | 10823  |
|    total_timesteps | 106496 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 107000   |
| train/                    |          |
|    explained_variance     | 0.843    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 52       |
|    policy_objective       | 0.0547   |
|    value_loss             | 0.00132  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 108000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 53     |
|    time_elapsed    | 11028  |
|    total_timesteps | 108544 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 109000   |
| train/                    |          |
|    explained_variance     | 0.906    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00538  |
|    learning_rate          | 0.001    |
|    n_updates              | 53       |
|    policy_objective       | 0.0536   |
|    value_loss             | 0.0013   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 110000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 54     |
|    time_elapsed    | 11232  |
|    total_timesteps | 110592 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 111000   |
| train/                    |          |
|    explained_variance     | 0.873    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00513  |
|    learning_rate          | 0.001    |
|    n_updates              | 54       |
|    policy_objective       | 0.0571   |
|    value_loss             | 0.000825 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 112000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 55     |
|    time_elapsed    | 11436  |
|    total_timesteps | 112640 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 113000   |
| train/                    |          |
|    explained_variance     | 0.873    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00661  |
|    learning_rate          | 0.001    |
|    n_updates              | 55       |
|    policy_objective       | 0.0511   |
|    value_loss             | 0.000743 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 114000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 56     |
|    time_elapsed    | 11641  |
|    total_timesteps | 114688 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 115000   |
| train/                    |          |
|    explained_variance     | 0.227    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00449  |
|    learning_rate          | 0.001    |
|    n_updates              | 56       |
|    policy_objective       | 0.0663   |
|    value_loss             | 0.000807 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 116000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 57     |
|    time_elapsed    | 11845  |
|    total_timesteps | 116736 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 117000   |
| train/                    |          |
|    explained_variance     | 0.654    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00425  |
|    learning_rate          | 0.001    |
|    n_updates              | 57       |
|    policy_objective       | 0.0732   |
|    value_loss             | 0.000795 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 118000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 58     |
|    time_elapsed    | 12049  |
|    total_timesteps | 118784 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 119000   |
| train/                    |          |
|    explained_variance     | 0.849    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00656  |
|    learning_rate          | 0.001    |
|    n_updates              | 58       |
|    policy_objective       | 0.0501   |
|    value_loss             | 0.0011   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 120000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 59     |
|    time_elapsed    | 12254  |
|    total_timesteps | 120832 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 121000   |
| train/                    |          |
|    explained_variance     | 0.518    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00474  |
|    learning_rate          | 0.001    |
|    n_updates              | 59       |
|    policy_objective       | 0.0595   |
|    value_loss             | 0.000881 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 122000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 60     |
|    time_elapsed    | 12458  |
|    total_timesteps | 122880 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 123000   |
| train/                    |          |
|    explained_variance     | 0.706    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00566  |
|    learning_rate          | 0.001    |
|    n_updates              | 60       |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.000566 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 124000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 61     |
|    time_elapsed    | 12662  |
|    total_timesteps | 124928 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 125000   |
| train/                    |          |
|    explained_variance     | 0.512    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00367  |
|    learning_rate          | 0.001    |
|    n_updates              | 61       |
|    policy_objective       | 0.0754   |
|    value_loss             | 0.00052  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 126000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 62     |
|    time_elapsed    | 12866  |
|    total_timesteps | 126976 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 127000   |
| train/                    |          |
|    explained_variance     | 0.437    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0046   |
|    learning_rate          | 0.001    |
|    n_updates              | 62       |
|    policy_objective       | 0.069    |
|    value_loss             | 0.000612 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 128000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 129000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 63     |
|    time_elapsed    | 13171  |
|    total_timesteps | 129024 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 130000   |
| train/                    |          |
|    explained_variance     | 0.5      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00415  |
|    learning_rate          | 0.001    |
|    n_updates              | 63       |
|    policy_objective       | 0.0756   |
|    value_loss             | 0.0011   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 131000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 64     |
|    time_elapsed    | 13375  |
|    total_timesteps | 131072 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 132000   |
| train/                    |          |
|    explained_variance     | 0.874    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00619  |
|    learning_rate          | 0.001    |
|    n_updates              | 64       |
|    policy_objective       | 0.0507   |
|    value_loss             | 0.00032  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 133000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 65     |
|    time_elapsed    | 13579  |
|    total_timesteps | 133120 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 134000   |
| train/                    |          |
|    explained_variance     | 0.847    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00571  |
|    learning_rate          | 0.001    |
|    n_updates              | 65       |
|    policy_objective       | 0.0524   |
|    value_loss             | 0.00124  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 135000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 66     |
|    time_elapsed    | 13784  |
|    total_timesteps | 135168 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 136000   |
| train/                    |          |
|    explained_variance     | 0.87     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00568  |
|    learning_rate          | 0.001    |
|    n_updates              | 66       |
|    policy_objective       | 0.051    |
|    value_loss             | 0.00057  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 137000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 67     |
|    time_elapsed    | 13988  |
|    total_timesteps | 137216 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 138000   |
| train/                    |          |
|    explained_variance     | 0.635    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00469  |
|    learning_rate          | 0.001    |
|    n_updates              | 67       |
|    policy_objective       | 0.0635   |
|    value_loss             | 0.00104  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 139000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 68     |
|    time_elapsed    | 14192  |
|    total_timesteps | 139264 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 140000   |
| train/                    |          |
|    explained_variance     | 0.886    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00511  |
|    learning_rate          | 0.001    |
|    n_updates              | 68       |
|    policy_objective       | 0.0552   |
|    value_loss             | 0.000772 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 141000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 69     |
|    time_elapsed    | 14397  |
|    total_timesteps | 141312 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 142000   |
| train/                    |          |
|    explained_variance     | 0.701    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.001    |
|    n_updates              | 69       |
|    policy_objective       | 0.0646   |
|    value_loss             | 0.000832 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 143000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 70     |
|    time_elapsed    | 14601  |
|    total_timesteps | 143360 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 144000   |
| train/                    |          |
|    explained_variance     | 0.802    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0048   |
|    learning_rate          | 0.001    |
|    n_updates              | 70       |
|    policy_objective       | 0.059    |
|    value_loss             | 0.00061  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 145000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 71     |
|    time_elapsed    | 14805  |
|    total_timesteps | 145408 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 146000   |
| train/                    |          |
|    explained_variance     | 0.85     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00542  |
|    learning_rate          | 0.001    |
|    n_updates              | 71       |
|    policy_objective       | 0.0615   |
|    value_loss             | 0.000522 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 147000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 72     |
|    time_elapsed    | 15010  |
|    total_timesteps | 147456 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 148000   |
| train/                    |          |
|    explained_variance     | 0.815    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00569  |
|    learning_rate          | 0.001    |
|    n_updates              | 72       |
|    policy_objective       | 0.0497   |
|    value_loss             | 0.000894 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 149000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 73     |
|    time_elapsed    | 15214  |
|    total_timesteps | 149504 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 150000   |
| train/                    |          |
|    explained_variance     | 0.868    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00545  |
|    learning_rate          | 0.001    |
|    n_updates              | 73       |
|    policy_objective       | 0.055    |
|    value_loss             | 0.000787 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 151000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 74     |
|    time_elapsed    | 15418  |
|    total_timesteps | 151552 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 152000   |
| train/                    |          |
|    explained_variance     | 0.683    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00515  |
|    learning_rate          | 0.001    |
|    n_updates              | 74       |
|    policy_objective       | 0.0626   |
|    value_loss             | 0.000621 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 153000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 75     |
|    time_elapsed    | 15622  |
|    total_timesteps | 153600 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 154000   |
| train/                    |          |
|    explained_variance     | 0.719    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.001    |
|    n_updates              | 75       |
|    policy_objective       | 0.0621   |
|    value_loss             | 0.000465 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 155000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 76     |
|    time_elapsed    | 15827  |
|    total_timesteps | 155648 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 156000   |
| train/                    |          |
|    explained_variance     | 0.827    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00613  |
|    learning_rate          | 0.001    |
|    n_updates              | 76       |
|    policy_objective       | 0.0618   |
|    value_loss             | 0.000844 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 157000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 77     |
|    time_elapsed    | 16031  |
|    total_timesteps | 157696 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 158000   |
| train/                    |          |
|    explained_variance     | 0.864    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00647  |
|    learning_rate          | 0.001    |
|    n_updates              | 77       |
|    policy_objective       | 0.0561   |
|    value_loss             | 0.000499 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 159000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 78     |
|    time_elapsed    | 16235  |
|    total_timesteps | 159744 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 160000   |
| train/                    |          |
|    explained_variance     | 0.892    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00551  |
|    learning_rate          | 0.001    |
|    n_updates              | 78       |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.000803 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 161000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 79     |
|    time_elapsed    | 16440  |
|    total_timesteps | 161792 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 162000   |
| train/                    |          |
|    explained_variance     | 0.84     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00645  |
|    learning_rate          | 0.001    |
|    n_updates              | 79       |
|    policy_objective       | 0.0481   |
|    value_loss             | 0.000475 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 163000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 80     |
|    time_elapsed    | 16644  |
|    total_timesteps | 163840 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 164000   |
| train/                    |          |
|    explained_variance     | 0.758    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00441  |
|    learning_rate          | 0.001    |
|    n_updates              | 80       |
|    policy_objective       | 0.069    |
|    value_loss             | 0.000568 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 165000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 81     |
|    time_elapsed    | 16848  |
|    total_timesteps | 165888 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 166000   |
| train/                    |          |
|    explained_variance     | 0.573    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00519  |
|    learning_rate          | 0.001    |
|    n_updates              | 81       |
|    policy_objective       | 0.061    |
|    value_loss             | 0.000687 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 167000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 82     |
|    time_elapsed    | 17053  |
|    total_timesteps | 167936 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 168000   |
| train/                    |          |
|    explained_variance     | 0.655    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00528  |
|    learning_rate          | 0.001    |
|    n_updates              | 82       |
|    policy_objective       | 0.0656   |
|    value_loss             | 0.000921 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 169000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 83     |
|    time_elapsed    | 17257  |
|    total_timesteps | 169984 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 170000   |
| train/                    |          |
|    explained_variance     | 0.585    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00519  |
|    learning_rate          | 0.001    |
|    n_updates              | 83       |
|    policy_objective       | 0.0688   |
|    value_loss             | 0.000879 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 171000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 172000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 84     |
|    time_elapsed    | 17561  |
|    total_timesteps | 172032 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 173000   |
| train/                    |          |
|    explained_variance     | 0.515    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00454  |
|    learning_rate          | 0.001    |
|    n_updates              | 84       |
|    policy_objective       | 0.0633   |
|    value_loss             | 0.000666 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 174000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 85     |
|    time_elapsed    | 17766  |
|    total_timesteps | 174080 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 175000   |
| train/                    |          |
|    explained_variance     | 0.756    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00538  |
|    learning_rate          | 0.001    |
|    n_updates              | 85       |
|    policy_objective       | 0.0564   |
|    value_loss             | 0.000564 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 176000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 86     |
|    time_elapsed    | 17970  |
|    total_timesteps | 176128 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 177000   |
| train/                    |          |
|    explained_variance     | 0.782    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00552  |
|    learning_rate          | 0.001    |
|    n_updates              | 86       |
|    policy_objective       | 0.0581   |
|    value_loss             | 0.000602 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 178000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 87     |
|    time_elapsed    | 18174  |
|    total_timesteps | 178176 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 179000   |
| train/                    |          |
|    explained_variance     | 0.755    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00464  |
|    learning_rate          | 0.001    |
|    n_updates              | 87       |
|    policy_objective       | 0.0564   |
|    value_loss             | 0.000883 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 180000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 88     |
|    time_elapsed    | 18379  |
|    total_timesteps | 180224 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 181000   |
| train/                    |          |
|    explained_variance     | 0.826    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00525  |
|    learning_rate          | 0.001    |
|    n_updates              | 88       |
|    policy_objective       | 0.055    |
|    value_loss             | 0.000427 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 182000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 89     |
|    time_elapsed    | 18583  |
|    total_timesteps | 182272 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 183000   |
| train/                    |          |
|    explained_variance     | 0.737    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00425  |
|    learning_rate          | 0.001    |
|    n_updates              | 89       |
|    policy_objective       | 0.0725   |
|    value_loss             | 0.000484 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 184000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 90     |
|    time_elapsed    | 18787  |
|    total_timesteps | 184320 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 185000   |
| train/                    |          |
|    explained_variance     | 0.828    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00597  |
|    learning_rate          | 0.001    |
|    n_updates              | 90       |
|    policy_objective       | 0.0568   |
|    value_loss             | 0.000417 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 186000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 91     |
|    time_elapsed    | 18991  |
|    total_timesteps | 186368 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 187000   |
| train/                    |          |
|    explained_variance     | 0.718    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0049   |
|    learning_rate          | 0.001    |
|    n_updates              | 91       |
|    policy_objective       | 0.0611   |
|    value_loss             | 0.000464 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 188000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 92     |
|    time_elapsed    | 19196  |
|    total_timesteps | 188416 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 189000   |
| train/                    |          |
|    explained_variance     | 0.657    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 92       |
|    policy_objective       | 0.0598   |
|    value_loss             | 0.000729 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 190000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 93     |
|    time_elapsed    | 19400  |
|    total_timesteps | 190464 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 191000   |
| train/                    |          |
|    explained_variance     | 0.671    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00575  |
|    learning_rate          | 0.001    |
|    n_updates              | 93       |
|    policy_objective       | 0.0651   |
|    value_loss             | 0.000327 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 192000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 94     |
|    time_elapsed    | 19604  |
|    total_timesteps | 192512 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 193000   |
| train/                    |          |
|    explained_variance     | 0.615    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00477  |
|    learning_rate          | 0.001    |
|    n_updates              | 94       |
|    policy_objective       | 0.0609   |
|    value_loss             | 0.00055  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 194000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 95     |
|    time_elapsed    | 19809  |
|    total_timesteps | 194560 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 195000   |
| train/                    |          |
|    explained_variance     | 0.574    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00523  |
|    learning_rate          | 0.001    |
|    n_updates              | 95       |
|    policy_objective       | 0.0599   |
|    value_loss             | 0.000452 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 196000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 96     |
|    time_elapsed    | 20013  |
|    total_timesteps | 196608 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 197000   |
| train/                    |          |
|    explained_variance     | 0.499    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00455  |
|    learning_rate          | 0.001    |
|    n_updates              | 96       |
|    policy_objective       | 0.0565   |
|    value_loss             | 0.000698 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 198000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 97     |
|    time_elapsed    | 20217  |
|    total_timesteps | 198656 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 199000   |
| train/                    |          |
|    explained_variance     | 0.593    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.001    |
|    n_updates              | 97       |
|    policy_objective       | 0.0664   |
|    value_loss             | 0.000596 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 200000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 98     |
|    time_elapsed    | 20422  |
|    total_timesteps | 200704 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 201000   |
| train/                    |          |
|    explained_variance     | 0.549    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00534  |
|    learning_rate          | 0.001    |
|    n_updates              | 98       |
|    policy_objective       | 0.0646   |
|    value_loss             | 0.000593 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 202000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 99     |
|    time_elapsed    | 20626  |
|    total_timesteps | 202752 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 203000   |
| train/                    |          |
|    explained_variance     | 0.509    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00522  |
|    learning_rate          | 0.001    |
|    n_updates              | 99       |
|    policy_objective       | 0.0645   |
|    value_loss             | 0.000626 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 204000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 100    |
|    time_elapsed    | 20830  |
|    total_timesteps | 204800 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 205000   |
| train/                    |          |
|    explained_variance     | 0.544    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00485  |
|    learning_rate          | 0.001    |
|    n_updates              | 100      |
|    policy_objective       | 0.0631   |
|    value_loss             | 0.000597 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 206000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 101    |
|    time_elapsed    | 21035  |
|    total_timesteps | 206848 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 207000   |
| train/                    |          |
|    explained_variance     | 0.686    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00523  |
|    learning_rate          | 0.001    |
|    n_updates              | 101      |
|    policy_objective       | 0.0583   |
|    value_loss             | 0.000407 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 208000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 102    |
|    time_elapsed    | 21239  |
|    total_timesteps | 208896 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 209000   |
| train/                    |          |
|    explained_variance     | 0.702    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00519  |
|    learning_rate          | 0.001    |
|    n_updates              | 102      |
|    policy_objective       | 0.059    |
|    value_loss             | 0.000548 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 210000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 103    |
|    time_elapsed    | 21443  |
|    total_timesteps | 210944 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 211000   |
| train/                    |          |
|    explained_variance     | 0.769    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00625  |
|    learning_rate          | 0.001    |
|    n_updates              | 103      |
|    policy_objective       | 0.0749   |
|    value_loss             | 0.000584 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 212000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 104    |
|    time_elapsed    | 21647  |
|    total_timesteps | 212992 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 213000   |
| train/                    |          |
|    explained_variance     | 0.0622   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00467  |
|    learning_rate          | 0.001    |
|    n_updates              | 104      |
|    policy_objective       | 0.0655   |
|    value_loss             | 0.000474 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 214000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 215000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 105    |
|    time_elapsed    | 21952  |
|    total_timesteps | 215040 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 216000   |
| train/                    |          |
|    explained_variance     | 0.533    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00569  |
|    learning_rate          | 0.001    |
|    n_updates              | 105      |
|    policy_objective       | 0.0535   |
|    value_loss             | 0.00067  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 217000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 106    |
|    time_elapsed    | 22156  |
|    total_timesteps | 217088 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 218000   |
| train/                    |          |
|    explained_variance     | 0.432    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00467  |
|    learning_rate          | 0.001    |
|    n_updates              | 106      |
|    policy_objective       | 0.0649   |
|    value_loss             | 0.000469 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 219000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 107    |
|    time_elapsed    | 22360  |
|    total_timesteps | 219136 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 220000   |
| train/                    |          |
|    explained_variance     | 0.415    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00516  |
|    learning_rate          | 0.001    |
|    n_updates              | 107      |
|    policy_objective       | 0.0638   |
|    value_loss             | 0.000412 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 221000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 108    |
|    time_elapsed    | 22565  |
|    total_timesteps | 221184 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 222000   |
| train/                    |          |
|    explained_variance     | 0.718    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00487  |
|    learning_rate          | 0.001    |
|    n_updates              | 108      |
|    policy_objective       | 0.0584   |
|    value_loss             | 0.00045  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 223000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 109    |
|    time_elapsed    | 22769  |
|    total_timesteps | 223232 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 224000   |
| train/                    |          |
|    explained_variance     | 0.795    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00532  |
|    learning_rate          | 0.001    |
|    n_updates              | 109      |
|    policy_objective       | 0.0608   |
|    value_loss             | 0.000557 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 225000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 110    |
|    time_elapsed    | 22973  |
|    total_timesteps | 225280 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 226000   |
| train/                    |          |
|    explained_variance     | 0.74     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00561  |
|    learning_rate          | 0.001    |
|    n_updates              | 110      |
|    policy_objective       | 0.061    |
|    value_loss             | 0.000653 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 227000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 111    |
|    time_elapsed    | 23178  |
|    total_timesteps | 227328 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 228000   |
| train/                    |          |
|    explained_variance     | 0.729    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00495  |
|    learning_rate          | 0.001    |
|    n_updates              | 111      |
|    policy_objective       | 0.0673   |
|    value_loss             | 0.000639 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 229000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 112    |
|    time_elapsed    | 23382  |
|    total_timesteps | 229376 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 230000   |
| train/                    |          |
|    explained_variance     | 0.681    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00483  |
|    learning_rate          | 0.001    |
|    n_updates              | 112      |
|    policy_objective       | 0.0603   |
|    value_loss             | 0.000771 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 231000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 113    |
|    time_elapsed    | 23586  |
|    total_timesteps | 231424 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 232000   |
| train/                    |          |
|    explained_variance     | 0.618    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00557  |
|    learning_rate          | 0.001    |
|    n_updates              | 113      |
|    policy_objective       | 0.0542   |
|    value_loss             | 0.000757 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 233000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 114    |
|    time_elapsed    | 23791  |
|    total_timesteps | 233472 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 234000   |
| train/                    |          |
|    explained_variance     | 0.779    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00592  |
|    learning_rate          | 0.001    |
|    n_updates              | 114      |
|    policy_objective       | 0.0565   |
|    value_loss             | 0.000527 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 235000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 115    |
|    time_elapsed    | 23995  |
|    total_timesteps | 235520 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 236000   |
| train/                    |          |
|    explained_variance     | 0.825    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00533  |
|    learning_rate          | 0.001    |
|    n_updates              | 115      |
|    policy_objective       | 0.0623   |
|    value_loss             | 0.000843 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 237000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 116    |
|    time_elapsed    | 24199  |
|    total_timesteps | 237568 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 238000   |
| train/                    |          |
|    explained_variance     | 0.585    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 116      |
|    policy_objective       | 0.0652   |
|    value_loss             | 0.000523 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 239000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 117    |
|    time_elapsed    | 24403  |
|    total_timesteps | 239616 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 240000   |
| train/                    |          |
|    explained_variance     | 0.559    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00563  |
|    learning_rate          | 0.001    |
|    n_updates              | 117      |
|    policy_objective       | 0.0617   |
|    value_loss             | 0.000479 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 241000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 118    |
|    time_elapsed    | 24608  |
|    total_timesteps | 241664 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 242000   |
| train/                    |          |
|    explained_variance     | 0.631    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00495  |
|    learning_rate          | 0.001    |
|    n_updates              | 118      |
|    policy_objective       | 0.0619   |
|    value_loss             | 0.000491 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 243000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 119    |
|    time_elapsed    | 24812  |
|    total_timesteps | 243712 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 244000   |
| train/                    |          |
|    explained_variance     | 0.714    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00586  |
|    learning_rate          | 0.001    |
|    n_updates              | 119      |
|    policy_objective       | 0.063    |
|    value_loss             | 0.000546 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 245000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 120    |
|    time_elapsed    | 25016  |
|    total_timesteps | 245760 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 246000   |
| train/                    |          |
|    explained_variance     | 0.379    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00536  |
|    learning_rate          | 0.001    |
|    n_updates              | 120      |
|    policy_objective       | 0.0673   |
|    value_loss             | 0.000677 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 247000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 121    |
|    time_elapsed    | 25221  |
|    total_timesteps | 247808 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 248000   |
| train/                    |          |
|    explained_variance     | 0.59     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00522  |
|    learning_rate          | 0.001    |
|    n_updates              | 121      |
|    policy_objective       | 0.0668   |
|    value_loss             | 0.000402 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 249000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 122    |
|    time_elapsed    | 25425  |
|    total_timesteps | 249856 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 250000   |
| train/                    |          |
|    explained_variance     | 0.527    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00495  |
|    learning_rate          | 0.001    |
|    n_updates              | 122      |
|    policy_objective       | 0.0626   |
|    value_loss             | 0.000482 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 251000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 123    |
|    time_elapsed    | 25629  |
|    total_timesteps | 251904 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 252000   |
| train/                    |          |
|    explained_variance     | 0.373    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00528  |
|    learning_rate          | 0.001    |
|    n_updates              | 123      |
|    policy_objective       | 0.0741   |
|    value_loss             | 0.000748 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 253000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 124    |
|    time_elapsed    | 25834  |
|    total_timesteps | 253952 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 254000   |
| train/                    |          |
|    explained_variance     | 0.46     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00488  |
|    learning_rate          | 0.001    |
|    n_updates              | 124      |
|    policy_objective       | 0.0703   |
|    value_loss             | 0.000471 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 255000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 256000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 125    |
|    time_elapsed    | 26138  |
|    total_timesteps | 256000 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 257000   |
| train/                    |          |
|    explained_variance     | 0.579    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00439  |
|    learning_rate          | 0.001    |
|    n_updates              | 125      |
|    policy_objective       | 0.0863   |
|    value_loss             | 0.000636 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 258000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 126    |
|    time_elapsed    | 26342  |
|    total_timesteps | 258048 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 259000   |
| train/                    |          |
|    explained_variance     | 0.763    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00602  |
|    learning_rate          | 0.001    |
|    n_updates              | 126      |
|    policy_objective       | 0.0569   |
|    value_loss             | 0.000623 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 260000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 127    |
|    time_elapsed    | 26546  |
|    total_timesteps | 260096 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 261000   |
| train/                    |          |
|    explained_variance     | 0.338    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00573  |
|    learning_rate          | 0.001    |
|    n_updates              | 127      |
|    policy_objective       | 0.0687   |
|    value_loss             | 0.000642 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 262000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 128    |
|    time_elapsed    | 26751  |
|    total_timesteps | 262144 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 263000   |
| train/                    |          |
|    explained_variance     | 0.473    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.001    |
|    n_updates              | 128      |
|    policy_objective       | 0.0585   |
|    value_loss             | 0.000728 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 264000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 129    |
|    time_elapsed    | 26955  |
|    total_timesteps | 264192 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 265000   |
| train/                    |          |
|    explained_variance     | 0.416    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00536  |
|    learning_rate          | 0.001    |
|    n_updates              | 129      |
|    policy_objective       | 0.0586   |
|    value_loss             | 0.000886 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 266000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 130    |
|    time_elapsed    | 27159  |
|    total_timesteps | 266240 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 267000   |
| train/                    |          |
|    explained_variance     | 0.642    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 130      |
|    policy_objective       | 0.0558   |
|    value_loss             | 0.000457 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 268000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 131    |
|    time_elapsed    | 27364  |
|    total_timesteps | 268288 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 269000   |
| train/                    |          |
|    explained_variance     | 0.355    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00526  |
|    learning_rate          | 0.001    |
|    n_updates              | 131      |
|    policy_objective       | 0.0605   |
|    value_loss             | 0.000528 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 270000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 132    |
|    time_elapsed    | 27568  |
|    total_timesteps | 270336 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 271000   |
| train/                    |          |
|    explained_variance     | 0.456    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00563  |
|    learning_rate          | 0.001    |
|    n_updates              | 132      |
|    policy_objective       | 0.0633   |
|    value_loss             | 0.000668 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 272000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 133    |
|    time_elapsed    | 27772  |
|    total_timesteps | 272384 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 273000   |
| train/                    |          |
|    explained_variance     | 0.511    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 133      |
|    policy_objective       | 0.0603   |
|    value_loss             | 0.000772 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 274000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 134    |
|    time_elapsed    | 27977  |
|    total_timesteps | 274432 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 275000   |
| train/                    |          |
|    explained_variance     | 0.596    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0072   |
|    learning_rate          | 0.001    |
|    n_updates              | 134      |
|    policy_objective       | 0.0654   |
|    value_loss             | 0.000798 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 276000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 135    |
|    time_elapsed    | 28181  |
|    total_timesteps | 276480 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 277000   |
| train/                    |          |
|    explained_variance     | 0.622    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00479  |
|    learning_rate          | 0.001    |
|    n_updates              | 135      |
|    policy_objective       | 0.0742   |
|    value_loss             | 0.00068  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 278000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 136    |
|    time_elapsed    | 28385  |
|    total_timesteps | 278528 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 279000   |
| train/                    |          |
|    explained_variance     | 0.516    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00486  |
|    learning_rate          | 0.001    |
|    n_updates              | 136      |
|    policy_objective       | 0.0684   |
|    value_loss             | 0.000799 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 280000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 137    |
|    time_elapsed    | 28590  |
|    total_timesteps | 280576 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 281000   |
| train/                    |          |
|    explained_variance     | 0.642    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00595  |
|    learning_rate          | 0.001    |
|    n_updates              | 137      |
|    policy_objective       | 0.0588   |
|    value_loss             | 0.000852 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 282000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 138    |
|    time_elapsed    | 28794  |
|    total_timesteps | 282624 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 283000   |
| train/                    |          |
|    explained_variance     | 0.671    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00669  |
|    learning_rate          | 0.001    |
|    n_updates              | 138      |
|    policy_objective       | 0.0615   |
|    value_loss             | 0.000835 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 284000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 139    |
|    time_elapsed    | 28998  |
|    total_timesteps | 284672 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 285000   |
| train/                    |          |
|    explained_variance     | 0.685    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00591  |
|    learning_rate          | 0.001    |
|    n_updates              | 139      |
|    policy_objective       | 0.0581   |
|    value_loss             | 0.00108  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 286000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 140    |
|    time_elapsed    | 29203  |
|    total_timesteps | 286720 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 287000   |
| train/                    |          |
|    explained_variance     | 0.588    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00508  |
|    learning_rate          | 0.001    |
|    n_updates              | 140      |
|    policy_objective       | 0.0612   |
|    value_loss             | 0.00118  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 288000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 141    |
|    time_elapsed    | 29407  |
|    total_timesteps | 288768 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 289000   |
| train/                    |          |
|    explained_variance     | 0.69     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0066   |
|    learning_rate          | 0.001    |
|    n_updates              | 141      |
|    policy_objective       | 0.0523   |
|    value_loss             | 0.0013   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 290000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 142    |
|    time_elapsed    | 29611  |
|    total_timesteps | 290816 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 291000   |
| train/                    |          |
|    explained_variance     | 0.666    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00819  |
|    learning_rate          | 0.001    |
|    n_updates              | 142      |
|    policy_objective       | 0.0609   |
|    value_loss             | 0.00094  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 292000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 143    |
|    time_elapsed    | 29816  |
|    total_timesteps | 292864 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 293000   |
| train/                    |          |
|    explained_variance     | 0.622    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00479  |
|    learning_rate          | 0.001    |
|    n_updates              | 143      |
|    policy_objective       | 0.0879   |
|    value_loss             | 0.000752 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 294000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 144    |
|    time_elapsed    | 30020  |
|    total_timesteps | 294912 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 295000   |
| train/                    |          |
|    explained_variance     | 0.488    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00613  |
|    learning_rate          | 0.001    |
|    n_updates              | 144      |
|    policy_objective       | 0.0599   |
|    value_loss             | 0.00108  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 296000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 145    |
|    time_elapsed    | 30224  |
|    total_timesteps | 296960 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 297000   |
| train/                    |          |
|    explained_variance     | 0.526    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00566  |
|    learning_rate          | 0.001    |
|    n_updates              | 145      |
|    policy_objective       | 0.0767   |
|    value_loss             | 0.00103  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 298000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 299000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 146    |
|    time_elapsed    | 30529  |
|    total_timesteps | 299008 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 300000   |
| train/                    |          |
|    explained_variance     | 0.231    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 146      |
|    policy_objective       | 0.0734   |
|    value_loss             | 0.00088  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 301000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 147    |
|    time_elapsed    | 30733  |
|    total_timesteps | 301056 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 302000   |
| train/                    |          |
|    explained_variance     | 0.588    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00562  |
|    learning_rate          | 0.001    |
|    n_updates              | 147      |
|    policy_objective       | 0.0578   |
|    value_loss             | 0.00106  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 303000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 148    |
|    time_elapsed    | 30937  |
|    total_timesteps | 303104 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 304000   |
| train/                    |          |
|    explained_variance     | 0.58     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00514  |
|    learning_rate          | 0.001    |
|    n_updates              | 148      |
|    policy_objective       | 0.0695   |
|    value_loss             | 0.000816 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 305000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 149    |
|    time_elapsed    | 31142  |
|    total_timesteps | 305152 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 306000   |
| train/                    |          |
|    explained_variance     | 0.453    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00488  |
|    learning_rate          | 0.001    |
|    n_updates              | 149      |
|    policy_objective       | 0.0591   |
|    value_loss             | 0.000945 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 307000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 150    |
|    time_elapsed    | 31346  |
|    total_timesteps | 307200 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 308000   |
| train/                    |          |
|    explained_variance     | 0.585    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00637  |
|    learning_rate          | 0.001    |
|    n_updates              | 150      |
|    policy_objective       | 0.0577   |
|    value_loss             | 0.001    |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 309000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 151    |
|    time_elapsed    | 31550  |
|    total_timesteps | 309248 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 310000   |
| train/                    |          |
|    explained_variance     | 0.623    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00602  |
|    learning_rate          | 0.001    |
|    n_updates              | 151      |
|    policy_objective       | 0.0572   |
|    value_loss             | 0.00118  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 311000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 152    |
|    time_elapsed    | 31754  |
|    total_timesteps | 311296 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 312000   |
| train/                    |          |
|    explained_variance     | 0.747    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00431  |
|    learning_rate          | 0.001    |
|    n_updates              | 152      |
|    policy_objective       | 0.0507   |
|    value_loss             | 0.00092  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 313000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 153    |
|    time_elapsed    | 31959  |
|    total_timesteps | 313344 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 314000   |
| train/                    |          |
|    explained_variance     | 0.525    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.001    |
|    n_updates              | 153      |
|    policy_objective       | 0.0533   |
|    value_loss             | 0.00127  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 315000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 154    |
|    time_elapsed    | 32163  |
|    total_timesteps | 315392 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 316000   |
| train/                    |          |
|    explained_variance     | 0.684    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00593  |
|    learning_rate          | 0.001    |
|    n_updates              | 154      |
|    policy_objective       | 0.0429   |
|    value_loss             | 0.0014   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 317000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 155    |
|    time_elapsed    | 32367  |
|    total_timesteps | 317440 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 318000   |
| train/                    |          |
|    explained_variance     | 0.717    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0069   |
|    learning_rate          | 0.001    |
|    n_updates              | 155      |
|    policy_objective       | 0.0548   |
|    value_loss             | 0.00153  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 319000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 156    |
|    time_elapsed    | 32572  |
|    total_timesteps | 319488 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 320000   |
| train/                    |          |
|    explained_variance     | 0.649    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00616  |
|    learning_rate          | 0.001    |
|    n_updates              | 156      |
|    policy_objective       | 0.0719   |
|    value_loss             | 0.00135  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 321000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 157    |
|    time_elapsed    | 32776  |
|    total_timesteps | 321536 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 322000   |
| train/                    |          |
|    explained_variance     | 0.715    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00787  |
|    learning_rate          | 0.001    |
|    n_updates              | 157      |
|    policy_objective       | 0.0563   |
|    value_loss             | 0.00134  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 323000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 158    |
|    time_elapsed    | 32980  |
|    total_timesteps | 323584 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 324000   |
| train/                    |          |
|    explained_variance     | 0.7      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00845  |
|    learning_rate          | 0.001    |
|    n_updates              | 158      |
|    policy_objective       | 0.0701   |
|    value_loss             | 0.00121  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 325000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 159    |
|    time_elapsed    | 33185  |
|    total_timesteps | 325632 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 326000   |
| train/                    |          |
|    explained_variance     | 0.642    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00517  |
|    learning_rate          | 0.001    |
|    n_updates              | 159      |
|    policy_objective       | 0.0616   |
|    value_loss             | 0.00123  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 327000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 160    |
|    time_elapsed    | 33389  |
|    total_timesteps | 327680 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 328000   |
| train/                    |          |
|    explained_variance     | 0.572    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00575  |
|    learning_rate          | 0.001    |
|    n_updates              | 160      |
|    policy_objective       | 0.0553   |
|    value_loss             | 0.00145  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 329000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 161    |
|    time_elapsed    | 33593  |
|    total_timesteps | 329728 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 330000   |
| train/                    |          |
|    explained_variance     | 0.579    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00607  |
|    learning_rate          | 0.001    |
|    n_updates              | 161      |
|    policy_objective       | 0.0534   |
|    value_loss             | 0.00145  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 331000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 162    |
|    time_elapsed    | 33798  |
|    total_timesteps | 331776 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 332000   |
| train/                    |          |
|    explained_variance     | 0.607    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00623  |
|    learning_rate          | 0.001    |
|    n_updates              | 162      |
|    policy_objective       | 0.0622   |
|    value_loss             | 0.00159  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 333000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 163    |
|    time_elapsed    | 34002  |
|    total_timesteps | 333824 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 334000   |
| train/                    |          |
|    explained_variance     | 0.672    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00604  |
|    learning_rate          | 0.001    |
|    n_updates              | 163      |
|    policy_objective       | 0.0591   |
|    value_loss             | 0.00147  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 335000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 164    |
|    time_elapsed    | 34206  |
|    total_timesteps | 335872 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 336000   |
| train/                    |          |
|    explained_variance     | 0.649    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00489  |
|    learning_rate          | 0.001    |
|    n_updates              | 164      |
|    policy_objective       | 0.0632   |
|    value_loss             | 0.00114  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 337000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 165    |
|    time_elapsed    | 34411  |
|    total_timesteps | 337920 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 338000   |
| train/                    |          |
|    explained_variance     | 0.671    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00696  |
|    learning_rate          | 0.001    |
|    n_updates              | 165      |
|    policy_objective       | 0.0603   |
|    value_loss             | 0.00134  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 339000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 166    |
|    time_elapsed    | 34615  |
|    total_timesteps | 339968 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 340000   |
| train/                    |          |
|    explained_variance     | 0.656    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00541  |
|    learning_rate          | 0.001    |
|    n_updates              | 166      |
|    policy_objective       | 0.0667   |
|    value_loss             | 0.00103  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 341000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 342000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 167    |
|    time_elapsed    | 34919  |
|    total_timesteps | 342016 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 343000   |
| train/                    |          |
|    explained_variance     | 0.404    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00525  |
|    learning_rate          | 0.001    |
|    n_updates              | 167      |
|    policy_objective       | 0.0809   |
|    value_loss             | 0.00158  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 344000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 168    |
|    time_elapsed    | 35123  |
|    total_timesteps | 344064 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 345000   |
| train/                    |          |
|    explained_variance     | 0.251    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00644  |
|    learning_rate          | 0.001    |
|    n_updates              | 168      |
|    policy_objective       | 0.0572   |
|    value_loss             | 0.00134  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 346000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 169    |
|    time_elapsed    | 35328  |
|    total_timesteps | 346112 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 347000   |
| train/                    |          |
|    explained_variance     | 0.549    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00757  |
|    learning_rate          | 0.001    |
|    n_updates              | 169      |
|    policy_objective       | 0.0444   |
|    value_loss             | 0.00141  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 348000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 170    |
|    time_elapsed    | 35532  |
|    total_timesteps | 348160 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 349000   |
| train/                    |          |
|    explained_variance     | 0.306    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00617  |
|    learning_rate          | 0.001    |
|    n_updates              | 170      |
|    policy_objective       | 0.0548   |
|    value_loss             | 0.00152  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 350000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 171    |
|    time_elapsed    | 35736  |
|    total_timesteps | 350208 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 351000   |
| train/                    |          |
|    explained_variance     | 0.592    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00625  |
|    learning_rate          | 0.001    |
|    n_updates              | 171      |
|    policy_objective       | 0.0603   |
|    value_loss             | 0.0016   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 352000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 172    |
|    time_elapsed    | 35941  |
|    total_timesteps | 352256 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 353000   |
| train/                    |          |
|    explained_variance     | 0.53     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00643  |
|    learning_rate          | 0.001    |
|    n_updates              | 172      |
|    policy_objective       | 0.0548   |
|    value_loss             | 0.00173  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 354000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 173    |
|    time_elapsed    | 36145  |
|    total_timesteps | 354304 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 355000   |
| train/                    |          |
|    explained_variance     | 0.644    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0075   |
|    learning_rate          | 0.001    |
|    n_updates              | 173      |
|    policy_objective       | 0.0619   |
|    value_loss             | 0.00155  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 356000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 174    |
|    time_elapsed    | 36349  |
|    total_timesteps | 356352 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 357000   |
| train/                    |          |
|    explained_variance     | 0.568    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00522  |
|    learning_rate          | 0.001    |
|    n_updates              | 174      |
|    policy_objective       | 0.0615   |
|    value_loss             | 0.00128  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 358000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 175    |
|    time_elapsed    | 36554  |
|    total_timesteps | 358400 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 359000   |
| train/                    |          |
|    explained_variance     | 0.334    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00639  |
|    learning_rate          | 0.001    |
|    n_updates              | 175      |
|    policy_objective       | 0.0657   |
|    value_loss             | 0.00191  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 360000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 176    |
|    time_elapsed    | 36758  |
|    total_timesteps | 360448 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 361000   |
| train/                    |          |
|    explained_variance     | 0.656    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00577  |
|    learning_rate          | 0.001    |
|    n_updates              | 176      |
|    policy_objective       | 0.051    |
|    value_loss             | 0.00125  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 362000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 177    |
|    time_elapsed    | 36962  |
|    total_timesteps | 362496 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 363000   |
| train/                    |          |
|    explained_variance     | 0.585    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00611  |
|    learning_rate          | 0.001    |
|    n_updates              | 177      |
|    policy_objective       | 0.0642   |
|    value_loss             | 0.00155  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 364000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 178    |
|    time_elapsed    | 37167  |
|    total_timesteps | 364544 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 365000   |
| train/                    |          |
|    explained_variance     | 0.459    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00711  |
|    learning_rate          | 0.001    |
|    n_updates              | 178      |
|    policy_objective       | 0.0617   |
|    value_loss             | 0.00169  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 366000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 179    |
|    time_elapsed    | 37371  |
|    total_timesteps | 366592 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 367000   |
| train/                    |          |
|    explained_variance     | 0.612    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00907  |
|    learning_rate          | 0.001    |
|    n_updates              | 179      |
|    policy_objective       | 0.0583   |
|    value_loss             | 0.00157  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 368000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 180    |
|    time_elapsed    | 37575  |
|    total_timesteps | 368640 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 369000   |
| train/                    |          |
|    explained_variance     | 0.583    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00512  |
|    learning_rate          | 0.001    |
|    n_updates              | 180      |
|    policy_objective       | 0.0543   |
|    value_loss             | 0.00164  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 370000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 181    |
|    time_elapsed    | 37780  |
|    total_timesteps | 370688 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 371000   |
| train/                    |          |
|    explained_variance     | 0.521    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00538  |
|    learning_rate          | 0.001    |
|    n_updates              | 181      |
|    policy_objective       | 0.0647   |
|    value_loss             | 0.00116  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 372000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 182    |
|    time_elapsed    | 37984  |
|    total_timesteps | 372736 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 373000   |
| train/                    |          |
|    explained_variance     | 0.322    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00733  |
|    learning_rate          | 0.001    |
|    n_updates              | 182      |
|    policy_objective       | 0.074    |
|    value_loss             | 0.00197  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 374000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 183    |
|    time_elapsed    | 38188  |
|    total_timesteps | 374784 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 375000   |
| train/                    |          |
|    explained_variance     | 0.52     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0053   |
|    learning_rate          | 0.001    |
|    n_updates              | 183      |
|    policy_objective       | 0.06     |
|    value_loss             | 0.00159  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 376000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 184    |
|    time_elapsed    | 38393  |
|    total_timesteps | 376832 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 377000   |
| train/                    |          |
|    explained_variance     | 0.509    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00858  |
|    learning_rate          | 0.001    |
|    n_updates              | 184      |
|    policy_objective       | 0.0535   |
|    value_loss             | 0.00136  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 378000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 185    |
|    time_elapsed    | 38597  |
|    total_timesteps | 378880 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 379000   |
| train/                    |          |
|    explained_variance     | 0.643    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00752  |
|    learning_rate          | 0.001    |
|    n_updates              | 185      |
|    policy_objective       | 0.0577   |
|    value_loss             | 0.00177  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 380000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 186    |
|    time_elapsed    | 38801  |
|    total_timesteps | 380928 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 381000   |
| train/                    |          |
|    explained_variance     | 0.563    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00565  |
|    learning_rate          | 0.001    |
|    n_updates              | 186      |
|    policy_objective       | 0.0629   |
|    value_loss             | 0.00145  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 382000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 187    |
|    time_elapsed    | 39006  |
|    total_timesteps | 382976 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 383000   |
| train/                    |          |
|    explained_variance     | 0.498    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0061   |
|    learning_rate          | 0.001    |
|    n_updates              | 187      |
|    policy_objective       | 0.0665   |
|    value_loss             | 0.00164  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 384000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 385000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 188    |
|    time_elapsed    | 39310  |
|    total_timesteps | 385024 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 386000   |
| train/                    |          |
|    explained_variance     | 0.473    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00646  |
|    learning_rate          | 0.001    |
|    n_updates              | 188      |
|    policy_objective       | 0.0609   |
|    value_loss             | 0.00166  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 387000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 189    |
|    time_elapsed    | 39514  |
|    total_timesteps | 387072 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 388000   |
| train/                    |          |
|    explained_variance     | 0.54     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00601  |
|    learning_rate          | 0.001    |
|    n_updates              | 189      |
|    policy_objective       | 0.0613   |
|    value_loss             | 0.00141  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 389000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 190    |
|    time_elapsed    | 39719  |
|    total_timesteps | 389120 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 390000   |
| train/                    |          |
|    explained_variance     | 0.661    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00589  |
|    learning_rate          | 0.001    |
|    n_updates              | 190      |
|    policy_objective       | 0.0622   |
|    value_loss             | 0.00106  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 391000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 191    |
|    time_elapsed    | 39923  |
|    total_timesteps | 391168 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 392000   |
| train/                    |          |
|    explained_variance     | 0.567    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00562  |
|    learning_rate          | 0.001    |
|    n_updates              | 191      |
|    policy_objective       | 0.0609   |
|    value_loss             | 0.00176  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 393000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 192    |
|    time_elapsed    | 40127  |
|    total_timesteps | 393216 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 394000   |
| train/                    |          |
|    explained_variance     | 0.542    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0061   |
|    learning_rate          | 0.001    |
|    n_updates              | 192      |
|    policy_objective       | 0.0591   |
|    value_loss             | 0.00231  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 395000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 193    |
|    time_elapsed    | 40332  |
|    total_timesteps | 395264 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 396000   |
| train/                    |          |
|    explained_variance     | 0.514    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0095   |
|    learning_rate          | 0.001    |
|    n_updates              | 193      |
|    policy_objective       | 0.0625   |
|    value_loss             | 0.00141  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 397000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 194    |
|    time_elapsed    | 40536  |
|    total_timesteps | 397312 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 398000   |
| train/                    |          |
|    explained_variance     | 0.605    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00878  |
|    learning_rate          | 0.001    |
|    n_updates              | 194      |
|    policy_objective       | 0.0645   |
|    value_loss             | 0.00192  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 399000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 195    |
|    time_elapsed    | 40740  |
|    total_timesteps | 399360 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 400000   |
| train/                    |          |
|    explained_variance     | 0.722    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00661  |
|    learning_rate          | 0.001    |
|    n_updates              | 195      |
|    policy_objective       | 0.048    |
|    value_loss             | 0.00211  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 401000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 196    |
|    time_elapsed    | 40945  |
|    total_timesteps | 401408 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 402000   |
| train/                    |          |
|    explained_variance     | 0.457    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00625  |
|    learning_rate          | 0.001    |
|    n_updates              | 196      |
|    policy_objective       | 0.0558   |
|    value_loss             | 0.00182  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 403000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 197    |
|    time_elapsed    | 41149  |
|    total_timesteps | 403456 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 404000   |
| train/                    |          |
|    explained_variance     | 0.656    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00712  |
|    learning_rate          | 0.001    |
|    n_updates              | 197      |
|    policy_objective       | 0.0558   |
|    value_loss             | 0.0022   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 405000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 198    |
|    time_elapsed    | 41354  |
|    total_timesteps | 405504 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 406000   |
| train/                    |          |
|    explained_variance     | 0.544    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00634  |
|    learning_rate          | 0.001    |
|    n_updates              | 198      |
|    policy_objective       | 0.0478   |
|    value_loss             | 0.00218  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 407000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 199    |
|    time_elapsed    | 41558  |
|    total_timesteps | 407552 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 408000   |
| train/                    |          |
|    explained_variance     | 0.462    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00692  |
|    learning_rate          | 0.001    |
|    n_updates              | 199      |
|    policy_objective       | 0.0491   |
|    value_loss             | 0.00237  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 409000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 200    |
|    time_elapsed    | 41762  |
|    total_timesteps | 409600 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 410000   |
| train/                    |          |
|    explained_variance     | 0.562    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00787  |
|    learning_rate          | 0.001    |
|    n_updates              | 200      |
|    policy_objective       | 0.0383   |
|    value_loss             | 0.00265  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 411000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 201    |
|    time_elapsed    | 41967  |
|    total_timesteps | 411648 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 412000   |
| train/                    |          |
|    explained_variance     | 0.544    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0062   |
|    learning_rate          | 0.001    |
|    n_updates              | 201      |
|    policy_objective       | 0.053    |
|    value_loss             | 0.0019   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 413000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 202    |
|    time_elapsed    | 42171  |
|    total_timesteps | 413696 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 414000   |
| train/                    |          |
|    explained_variance     | 0.495    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00634  |
|    learning_rate          | 0.001    |
|    n_updates              | 202      |
|    policy_objective       | 0.053    |
|    value_loss             | 0.00223  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 415000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 203    |
|    time_elapsed    | 42375  |
|    total_timesteps | 415744 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 416000   |
| train/                    |          |
|    explained_variance     | 0.506    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00745  |
|    learning_rate          | 0.001    |
|    n_updates              | 203      |
|    policy_objective       | 0.0532   |
|    value_loss             | 0.00219  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 417000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 204    |
|    time_elapsed    | 42580  |
|    total_timesteps | 417792 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 418000   |
| train/                    |          |
|    explained_variance     | 0.587    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00645  |
|    learning_rate          | 0.001    |
|    n_updates              | 204      |
|    policy_objective       | 0.0569   |
|    value_loss             | 0.00199  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 419000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 205    |
|    time_elapsed    | 42784  |
|    total_timesteps | 419840 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 420000   |
| train/                    |          |
|    explained_variance     | 0.406    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00632  |
|    learning_rate          | 0.001    |
|    n_updates              | 205      |
|    policy_objective       | 0.0591   |
|    value_loss             | 0.00296  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 421000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 206    |
|    time_elapsed    | 42988  |
|    total_timesteps | 421888 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 422000   |
| train/                    |          |
|    explained_variance     | 0.39     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00674  |
|    learning_rate          | 0.001    |
|    n_updates              | 206      |
|    policy_objective       | 0.0479   |
|    value_loss             | 0.00236  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 423000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 207    |
|    time_elapsed    | 43193  |
|    total_timesteps | 423936 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 424000   |
| train/                    |          |
|    explained_variance     | 0.467    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00629  |
|    learning_rate          | 0.001    |
|    n_updates              | 207      |
|    policy_objective       | 0.0552   |
|    value_loss             | 0.00231  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 425000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 208    |
|    time_elapsed    | 43397  |
|    total_timesteps | 425984 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 426000   |
| train/                    |          |
|    explained_variance     | 0.458    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00671  |
|    learning_rate          | 0.001    |
|    n_updates              | 208      |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.0027   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 427000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 428000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 209    |
|    time_elapsed    | 43701  |
|    total_timesteps | 428032 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 429000   |
| train/                    |          |
|    explained_variance     | 0.543    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00476  |
|    learning_rate          | 0.001    |
|    n_updates              | 209      |
|    policy_objective       | 0.0616   |
|    value_loss             | 0.00296  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 430000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 210    |
|    time_elapsed    | 43906  |
|    total_timesteps | 430080 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 431000   |
| train/                    |          |
|    explained_variance     | 0.835    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00734  |
|    learning_rate          | 0.001    |
|    n_updates              | 210      |
|    policy_objective       | 0.048    |
|    value_loss             | 0.00232  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 432000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 211    |
|    time_elapsed    | 44110  |
|    total_timesteps | 432128 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 433000   |
| train/                    |          |
|    explained_variance     | 0.649    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00695  |
|    learning_rate          | 0.001    |
|    n_updates              | 211      |
|    policy_objective       | 0.0643   |
|    value_loss             | 0.00144  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 434000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 212    |
|    time_elapsed    | 44314  |
|    total_timesteps | 434176 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 435000   |
| train/                    |          |
|    explained_variance     | 0.527    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00745  |
|    learning_rate          | 0.001    |
|    n_updates              | 212      |
|    policy_objective       | 0.0402   |
|    value_loss             | 0.00271  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 436000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 213    |
|    time_elapsed    | 44519  |
|    total_timesteps | 436224 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 437000   |
| train/                    |          |
|    explained_variance     | 0.51     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00595  |
|    learning_rate          | 0.001    |
|    n_updates              | 213      |
|    policy_objective       | 0.0477   |
|    value_loss             | 0.00237  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 438000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 214    |
|    time_elapsed    | 44723  |
|    total_timesteps | 438272 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 439000   |
| train/                    |          |
|    explained_variance     | 0.619    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00696  |
|    learning_rate          | 0.001    |
|    n_updates              | 214      |
|    policy_objective       | 0.0524   |
|    value_loss             | 0.00206  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 440000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 215    |
|    time_elapsed    | 44927  |
|    total_timesteps | 440320 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 441000   |
| train/                    |          |
|    explained_variance     | 0.64     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00671  |
|    learning_rate          | 0.001    |
|    n_updates              | 215      |
|    policy_objective       | 0.0556   |
|    value_loss             | 0.00228  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 442000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 216    |
|    time_elapsed    | 45132  |
|    total_timesteps | 442368 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 443000   |
| train/                    |          |
|    explained_variance     | 0.633    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00609  |
|    learning_rate          | 0.001    |
|    n_updates              | 216      |
|    policy_objective       | 0.0593   |
|    value_loss             | 0.00246  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 444000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 217    |
|    time_elapsed    | 45336  |
|    total_timesteps | 444416 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 445000   |
| train/                    |          |
|    explained_variance     | 0.641    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.009    |
|    learning_rate          | 0.001    |
|    n_updates              | 217      |
|    policy_objective       | 0.0493   |
|    value_loss             | 0.00202  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 446000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 218    |
|    time_elapsed    | 45540  |
|    total_timesteps | 446464 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 447000   |
| train/                    |          |
|    explained_variance     | 0.627    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00787  |
|    learning_rate          | 0.001    |
|    n_updates              | 218      |
|    policy_objective       | 0.0551   |
|    value_loss             | 0.00286  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 448000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 219    |
|    time_elapsed    | 45745  |
|    total_timesteps | 448512 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 449000   |
| train/                    |          |
|    explained_variance     | 0.621    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00697  |
|    learning_rate          | 0.001    |
|    n_updates              | 219      |
|    policy_objective       | 0.0642   |
|    value_loss             | 0.00237  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 450000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 220    |
|    time_elapsed    | 45949  |
|    total_timesteps | 450560 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 451000   |
| train/                    |          |
|    explained_variance     | 0.708    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00746  |
|    learning_rate          | 0.001    |
|    n_updates              | 220      |
|    policy_objective       | 0.0451   |
|    value_loss             | 0.0028   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 452000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 221    |
|    time_elapsed    | 46153  |
|    total_timesteps | 452608 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 453000   |
| train/                    |          |
|    explained_variance     | 0.653    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00685  |
|    learning_rate          | 0.001    |
|    n_updates              | 221      |
|    policy_objective       | 0.052    |
|    value_loss             | 0.00301  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 454000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 222    |
|    time_elapsed    | 46358  |
|    total_timesteps | 454656 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 455000   |
| train/                    |          |
|    explained_variance     | 0.576    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00642  |
|    learning_rate          | 0.001    |
|    n_updates              | 222      |
|    policy_objective       | 0.0437   |
|    value_loss             | 0.00315  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 456000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 223    |
|    time_elapsed    | 46562  |
|    total_timesteps | 456704 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 457000   |
| train/                    |          |
|    explained_variance     | 0.555    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00844  |
|    learning_rate          | 0.001    |
|    n_updates              | 223      |
|    policy_objective       | 0.0492   |
|    value_loss             | 0.00272  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 458000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 224    |
|    time_elapsed    | 46766  |
|    total_timesteps | 458752 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 459000   |
| train/                    |          |
|    explained_variance     | 0.667    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00619  |
|    learning_rate          | 0.001    |
|    n_updates              | 224      |
|    policy_objective       | 0.0469   |
|    value_loss             | 0.0026   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 460000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 225    |
|    time_elapsed    | 46971  |
|    total_timesteps | 460800 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 461000   |
| train/                    |          |
|    explained_variance     | 0.689    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00709  |
|    learning_rate          | 0.001    |
|    n_updates              | 225      |
|    policy_objective       | 0.0493   |
|    value_loss             | 0.00225  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 462000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 226    |
|    time_elapsed    | 47175  |
|    total_timesteps | 462848 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 463000   |
| train/                    |          |
|    explained_variance     | 0.434    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00706  |
|    learning_rate          | 0.001    |
|    n_updates              | 226      |
|    policy_objective       | 0.0481   |
|    value_loss             | 0.00338  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 464000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 227    |
|    time_elapsed    | 47379  |
|    total_timesteps | 464896 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 465000   |
| train/                    |          |
|    explained_variance     | 0.476    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00777  |
|    learning_rate          | 0.001    |
|    n_updates              | 227      |
|    policy_objective       | 0.054    |
|    value_loss             | 0.00332  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 466000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 228    |
|    time_elapsed    | 47584  |
|    total_timesteps | 466944 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 467000   |
| train/                    |          |
|    explained_variance     | 0.482    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00479  |
|    learning_rate          | 0.001    |
|    n_updates              | 228      |
|    policy_objective       | 0.0674   |
|    value_loss             | 0.0022   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 468000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 229    |
|    time_elapsed    | 47788  |
|    total_timesteps | 468992 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 469000   |
| train/                    |          |
|    explained_variance     | 0.773    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00589  |
|    learning_rate          | 0.001    |
|    n_updates              | 229      |
|    policy_objective       | 0.0742   |
|    value_loss             | 0.00256  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 470000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 471000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 230    |
|    time_elapsed    | 48092  |
|    total_timesteps | 471040 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 472000   |
| train/                    |          |
|    explained_variance     | 0.642    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00513  |
|    learning_rate          | 0.001    |
|    n_updates              | 230      |
|    policy_objective       | 0.0628   |
|    value_loss             | 0.0036   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 473000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 231    |
|    time_elapsed    | 48297  |
|    total_timesteps | 473088 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 474000   |
| train/                    |          |
|    explained_variance     | 0.726    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0066   |
|    learning_rate          | 0.001    |
|    n_updates              | 231      |
|    policy_objective       | 0.0445   |
|    value_loss             | 0.00281  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 475000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 232    |
|    time_elapsed    | 48501  |
|    total_timesteps | 475136 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 476000   |
| train/                    |          |
|    explained_variance     | 0.827    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00787  |
|    learning_rate          | 0.001    |
|    n_updates              | 232      |
|    policy_objective       | 0.0425   |
|    value_loss             | 0.0034   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 477000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 233    |
|    time_elapsed    | 48705  |
|    total_timesteps | 477184 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 478000   |
| train/                    |          |
|    explained_variance     | 0.664    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00904  |
|    learning_rate          | 0.001    |
|    n_updates              | 233      |
|    policy_objective       | 0.0485   |
|    value_loss             | 0.00293  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 479000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 234    |
|    time_elapsed    | 48910  |
|    total_timesteps | 479232 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 480000   |
| train/                    |          |
|    explained_variance     | 0.533    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00656  |
|    learning_rate          | 0.001    |
|    n_updates              | 234      |
|    policy_objective       | 0.0489   |
|    value_loss             | 0.00273  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 481000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 235    |
|    time_elapsed    | 49114  |
|    total_timesteps | 481280 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 482000   |
| train/                    |          |
|    explained_variance     | 0.443    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00708  |
|    learning_rate          | 0.001    |
|    n_updates              | 235      |
|    policy_objective       | 0.0543   |
|    value_loss             | 0.00262  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 483000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 236    |
|    time_elapsed    | 49318  |
|    total_timesteps | 483328 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 484000   |
| train/                    |          |
|    explained_variance     | 0.479    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00597  |
|    learning_rate          | 0.001    |
|    n_updates              | 236      |
|    policy_objective       | 0.0586   |
|    value_loss             | 0.00157  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 485000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 237    |
|    time_elapsed    | 49523  |
|    total_timesteps | 485376 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 486000   |
| train/                    |          |
|    explained_variance     | 0.305    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00661  |
|    learning_rate          | 0.001    |
|    n_updates              | 237      |
|    policy_objective       | 0.0497   |
|    value_loss             | 0.00234  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 487000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 238    |
|    time_elapsed    | 49727  |
|    total_timesteps | 487424 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 488000   |
| train/                    |          |
|    explained_variance     | 0.503    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00785  |
|    learning_rate          | 0.001    |
|    n_updates              | 238      |
|    policy_objective       | 0.0424   |
|    value_loss             | 0.0025   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 489000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 239    |
|    time_elapsed    | 49931  |
|    total_timesteps | 489472 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 490000   |
| train/                    |          |
|    explained_variance     | 0.454    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00821  |
|    learning_rate          | 0.001    |
|    n_updates              | 239      |
|    policy_objective       | 0.0469   |
|    value_loss             | 0.00292  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 491000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 240    |
|    time_elapsed    | 50136  |
|    total_timesteps | 491520 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 492000   |
| train/                    |          |
|    explained_variance     | 0.433    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0078   |
|    learning_rate          | 0.001    |
|    n_updates              | 240      |
|    policy_objective       | 0.0425   |
|    value_loss             | 0.00316  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 493000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 241    |
|    time_elapsed    | 50340  |
|    total_timesteps | 493568 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 494000   |
| train/                    |          |
|    explained_variance     | 0.506    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00487  |
|    learning_rate          | 0.001    |
|    n_updates              | 241      |
|    policy_objective       | 0.0277   |
|    value_loss             | 0.00345  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 495000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 242    |
|    time_elapsed    | 50544  |
|    total_timesteps | 495616 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 496000   |
| train/                    |          |
|    explained_variance     | 0.506    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00768  |
|    learning_rate          | 0.001    |
|    n_updates              | 242      |
|    policy_objective       | 0.0459   |
|    value_loss             | 0.00285  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 497000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 243    |
|    time_elapsed    | 50749  |
|    total_timesteps | 497664 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 498000   |
| train/                    |          |
|    explained_variance     | 0.412    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00701  |
|    learning_rate          | 0.001    |
|    n_updates              | 243      |
|    policy_objective       | 0.0572   |
|    value_loss             | 0.00348  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 499000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 244    |
|    time_elapsed    | 50953  |
|    total_timesteps | 499712 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 500000   |
| train/                    |          |
|    explained_variance     | 0.644    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0065   |
|    learning_rate          | 0.001    |
|    n_updates              | 244      |
|    policy_objective       | 0.0563   |
|    value_loss             | 0.00222  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 501000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 245    |
|    time_elapsed    | 51157  |
|    total_timesteps | 501760 |
-------------------------------
