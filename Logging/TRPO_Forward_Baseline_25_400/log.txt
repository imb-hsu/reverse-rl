Logging to ./Logging/TRPO_Forward_Baseline_25_400
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 1000     |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 2000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 1    |
|    time_elapsed    | 204  |
|    total_timesteps | 2048 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 3000     |
| train/                    |          |
|    explained_variance     | 0.843    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00509  |
|    learning_rate          | 0.001    |
|    n_updates              | 1        |
|    policy_objective       | 0.0609   |
|    value_loss             | 0.00868  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 4000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 2    |
|    time_elapsed    | 408  |
|    total_timesteps | 4096 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 5000     |
| train/                    |          |
|    explained_variance     | 0.846    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00452  |
|    learning_rate          | 0.001    |
|    n_updates              | 2        |
|    policy_objective       | 0.0485   |
|    value_loss             | 0.00444  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 6000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 3    |
|    time_elapsed    | 612  |
|    total_timesteps | 6144 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 7000     |
| train/                    |          |
|    explained_variance     | 0.88     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00674  |
|    learning_rate          | 0.001    |
|    n_updates              | 3        |
|    policy_objective       | 0.044    |
|    value_loss             | 0.0163   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 8000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 4    |
|    time_elapsed    | 817  |
|    total_timesteps | 8192 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 9000     |
| train/                    |          |
|    explained_variance     | 0.792    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00465  |
|    learning_rate          | 0.001    |
|    n_updates              | 4        |
|    policy_objective       | 0.0529   |
|    value_loss             | 0.00429  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 10000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 5     |
|    time_elapsed    | 1021  |
|    total_timesteps | 10240 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 11000    |
| train/                    |          |
|    explained_variance     | 0.763    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00308  |
|    learning_rate          | 0.001    |
|    n_updates              | 5        |
|    policy_objective       | 0.0539   |
|    value_loss             | 0.00363  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 12000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 6     |
|    time_elapsed    | 1225  |
|    total_timesteps | 12288 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 13000    |
| train/                    |          |
|    explained_variance     | 0.674    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00248  |
|    learning_rate          | 0.001    |
|    n_updates              | 6        |
|    policy_objective       | 0.1      |
|    value_loss             | 0.0025   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 14000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 7     |
|    time_elapsed    | 1430  |
|    total_timesteps | 14336 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 15000    |
| train/                    |          |
|    explained_variance     | 0.884    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00582  |
|    learning_rate          | 0.001    |
|    n_updates              | 7        |
|    policy_objective       | 0.0457   |
|    value_loss             | 0.00528  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 16000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 8     |
|    time_elapsed    | 1634  |
|    total_timesteps | 16384 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 17000    |
| train/                    |          |
|    explained_variance     | 0.828    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00553  |
|    learning_rate          | 0.001    |
|    n_updates              | 8        |
|    policy_objective       | 0.047    |
|    value_loss             | 0.00563  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 18000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 9     |
|    time_elapsed    | 1838  |
|    total_timesteps | 18432 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 19000    |
| train/                    |          |
|    explained_variance     | 0.879    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00535  |
|    learning_rate          | 0.001    |
|    n_updates              | 9        |
|    policy_objective       | 0.053    |
|    value_loss             | 0.00452  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 20000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 10    |
|    time_elapsed    | 2043  |
|    total_timesteps | 20480 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 21000    |
| train/                    |          |
|    explained_variance     | 0.804    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00606  |
|    learning_rate          | 0.001    |
|    n_updates              | 10       |
|    policy_objective       | 0.0463   |
|    value_loss             | 0.0028   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 22000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 11    |
|    time_elapsed    | 2247  |
|    total_timesteps | 22528 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 23000    |
| train/                    |          |
|    explained_variance     | 0.781    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0058   |
|    learning_rate          | 0.001    |
|    n_updates              | 11       |
|    policy_objective       | 0.0417   |
|    value_loss             | 0.0023   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 24000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 12    |
|    time_elapsed    | 2451  |
|    total_timesteps | 24576 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 25000    |
| train/                    |          |
|    explained_variance     | 0.825    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00565  |
|    learning_rate          | 0.001    |
|    n_updates              | 12       |
|    policy_objective       | 0.049    |
|    value_loss             | 0.00256  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 26000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 13    |
|    time_elapsed    | 2656  |
|    total_timesteps | 26624 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 27000    |
| train/                    |          |
|    explained_variance     | 0.71     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00481  |
|    learning_rate          | 0.001    |
|    n_updates              | 13       |
|    policy_objective       | 0.0531   |
|    value_loss             | 0.00244  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 28000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 14    |
|    time_elapsed    | 2860  |
|    total_timesteps | 28672 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 29000    |
| train/                    |          |
|    explained_variance     | 0.913    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 14       |
|    policy_objective       | 0.0565   |
|    value_loss             | 0.00236  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 30000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 15    |
|    time_elapsed    | 3064  |
|    total_timesteps | 30720 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 31000    |
| train/                    |          |
|    explained_variance     | 0.775    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0055   |
|    learning_rate          | 0.001    |
|    n_updates              | 15       |
|    policy_objective       | 0.0539   |
|    value_loss             | 0.00246  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 32000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 16    |
|    time_elapsed    | 3269  |
|    total_timesteps | 32768 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 33000    |
| train/                    |          |
|    explained_variance     | 0.831    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00573  |
|    learning_rate          | 0.001    |
|    n_updates              | 16       |
|    policy_objective       | 0.0571   |
|    value_loss             | 0.000957 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 34000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 17    |
|    time_elapsed    | 3473  |
|    total_timesteps | 34816 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 35000    |
| train/                    |          |
|    explained_variance     | 0.868    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00504  |
|    learning_rate          | 0.001    |
|    n_updates              | 17       |
|    policy_objective       | 0.0492   |
|    value_loss             | 0.00231  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 36000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 18    |
|    time_elapsed    | 3678  |
|    total_timesteps | 36864 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 37000    |
| train/                    |          |
|    explained_variance     | 0.847    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0064   |
|    learning_rate          | 0.001    |
|    n_updates              | 18       |
|    policy_objective       | 0.0484   |
|    value_loss             | 0.00377  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 38000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 19    |
|    time_elapsed    | 3882  |
|    total_timesteps | 38912 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 39000    |
| train/                    |          |
|    explained_variance     | 0.886    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00517  |
|    learning_rate          | 0.001    |
|    n_updates              | 19       |
|    policy_objective       | 0.0563   |
|    value_loss             | 0.000215 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 40000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 20    |
|    time_elapsed    | 4086  |
|    total_timesteps | 40960 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 41000    |
| train/                    |          |
|    explained_variance     | 0.905    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00493  |
|    learning_rate          | 0.001    |
|    n_updates              | 20       |
|    policy_objective       | 0.0627   |
|    value_loss             | 0.00292  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 42000    |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 43000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 21    |
|    time_elapsed    | 4391  |
|    total_timesteps | 43008 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 44000    |
| train/                    |          |
|    explained_variance     | 0.781    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00397  |
|    learning_rate          | 0.001    |
|    n_updates              | 21       |
|    policy_objective       | 0.0683   |
|    value_loss             | 0.00261  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 45000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 22    |
|    time_elapsed    | 4595  |
|    total_timesteps | 45056 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 46000    |
| train/                    |          |
|    explained_variance     | 0.885    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.001    |
|    n_updates              | 22       |
|    policy_objective       | 0.0482   |
|    value_loss             | 0.00239  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 47000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 23    |
|    time_elapsed    | 4799  |
|    total_timesteps | 47104 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 48000    |
| train/                    |          |
|    explained_variance     | 0.835    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00489  |
|    learning_rate          | 0.001    |
|    n_updates              | 23       |
|    policy_objective       | 0.0529   |
|    value_loss             | 0.00248  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 49000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 24    |
|    time_elapsed    | 5003  |
|    total_timesteps | 49152 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 50000    |
| train/                    |          |
|    explained_variance     | 0.829    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00487  |
|    learning_rate          | 0.001    |
|    n_updates              | 24       |
|    policy_objective       | 0.0575   |
|    value_loss             | 0.00118  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 51000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 25    |
|    time_elapsed    | 5208  |
|    total_timesteps | 51200 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 52000    |
| train/                    |          |
|    explained_variance     | 0.87     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00428  |
|    learning_rate          | 0.001    |
|    n_updates              | 25       |
|    policy_objective       | 0.054    |
|    value_loss             | 0.00268  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 53000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 26    |
|    time_elapsed    | 5412  |
|    total_timesteps | 53248 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 54000    |
| train/                    |          |
|    explained_variance     | 0.768    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00616  |
|    learning_rate          | 0.001    |
|    n_updates              | 26       |
|    policy_objective       | 0.042    |
|    value_loss             | 0.00212  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 55000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 27    |
|    time_elapsed    | 5616  |
|    total_timesteps | 55296 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 56000    |
| train/                    |          |
|    explained_variance     | 0.717    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00429  |
|    learning_rate          | 0.001    |
|    n_updates              | 27       |
|    policy_objective       | 0.0665   |
|    value_loss             | 0.00142  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 57000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 28    |
|    time_elapsed    | 5821  |
|    total_timesteps | 57344 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 58000    |
| train/                    |          |
|    explained_variance     | 0.8      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00569  |
|    learning_rate          | 0.001    |
|    n_updates              | 28       |
|    policy_objective       | 0.0453   |
|    value_loss             | 0.0013   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 59000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 29    |
|    time_elapsed    | 6025  |
|    total_timesteps | 59392 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 60000    |
| train/                    |          |
|    explained_variance     | 0.804    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00445  |
|    learning_rate          | 0.001    |
|    n_updates              | 29       |
|    policy_objective       | 0.0565   |
|    value_loss             | 0.00117  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 61000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 30    |
|    time_elapsed    | 6229  |
|    total_timesteps | 61440 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 62000    |
| train/                    |          |
|    explained_variance     | 0.715    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00485  |
|    learning_rate          | 0.001    |
|    n_updates              | 30       |
|    policy_objective       | 0.0636   |
|    value_loss             | 0.000558 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 63000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 31    |
|    time_elapsed    | 6434  |
|    total_timesteps | 63488 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 64000    |
| train/                    |          |
|    explained_variance     | 0.854    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00519  |
|    learning_rate          | 0.001    |
|    n_updates              | 31       |
|    policy_objective       | 0.058    |
|    value_loss             | 0.00217  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 65000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 32    |
|    time_elapsed    | 6638  |
|    total_timesteps | 65536 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 66000    |
| train/                    |          |
|    explained_variance     | 0.829    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00455  |
|    learning_rate          | 0.001    |
|    n_updates              | 32       |
|    policy_objective       | 0.0572   |
|    value_loss             | 0.00164  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 67000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 33    |
|    time_elapsed    | 6842  |
|    total_timesteps | 67584 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 68000    |
| train/                    |          |
|    explained_variance     | 0.9      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00656  |
|    learning_rate          | 0.001    |
|    n_updates              | 33       |
|    policy_objective       | 0.0456   |
|    value_loss             | 0.00151  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 69000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 34    |
|    time_elapsed    | 7047  |
|    total_timesteps | 69632 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 70000    |
| train/                    |          |
|    explained_variance     | 0.763    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00465  |
|    learning_rate          | 0.001    |
|    n_updates              | 34       |
|    policy_objective       | 0.0563   |
|    value_loss             | 0.0018   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 71000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 35    |
|    time_elapsed    | 7251  |
|    total_timesteps | 71680 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 72000    |
| train/                    |          |
|    explained_variance     | 0.899    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00549  |
|    learning_rate          | 0.001    |
|    n_updates              | 35       |
|    policy_objective       | 0.051    |
|    value_loss             | 0.00126  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 73000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 36    |
|    time_elapsed    | 7455  |
|    total_timesteps | 73728 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 74000    |
| train/                    |          |
|    explained_variance     | 0.806    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00495  |
|    learning_rate          | 0.001    |
|    n_updates              | 36       |
|    policy_objective       | 0.0562   |
|    value_loss             | 0.00139  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 75000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 37    |
|    time_elapsed    | 7660  |
|    total_timesteps | 75776 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 76000    |
| train/                    |          |
|    explained_variance     | 0.872    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00598  |
|    learning_rate          | 0.001    |
|    n_updates              | 37       |
|    policy_objective       | 0.0516   |
|    value_loss             | 0.0012   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 77000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 38    |
|    time_elapsed    | 7864  |
|    total_timesteps | 77824 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 78000    |
| train/                    |          |
|    explained_variance     | 0.875    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00575  |
|    learning_rate          | 0.001    |
|    n_updates              | 38       |
|    policy_objective       | 0.0509   |
|    value_loss             | 0.00118  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 79000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 39    |
|    time_elapsed    | 8068  |
|    total_timesteps | 79872 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 80000    |
| train/                    |          |
|    explained_variance     | 0.764    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00501  |
|    learning_rate          | 0.001    |
|    n_updates              | 39       |
|    policy_objective       | 0.0539   |
|    value_loss             | 0.00236  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 81000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 40    |
|    time_elapsed    | 8273  |
|    total_timesteps | 81920 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 82000    |
| train/                    |          |
|    explained_variance     | 0.853    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00521  |
|    learning_rate          | 0.001    |
|    n_updates              | 40       |
|    policy_objective       | 0.058    |
|    value_loss             | 0.00125  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 83000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 41    |
|    time_elapsed    | 8477  |
|    total_timesteps | 83968 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 84000    |
| train/                    |          |
|    explained_variance     | 0.713    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00478  |
|    learning_rate          | 0.001    |
|    n_updates              | 41       |
|    policy_objective       | 0.0664   |
|    value_loss             | 0.00114  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 85000    |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 86000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 42    |
|    time_elapsed    | 8781  |
|    total_timesteps | 86016 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 87000    |
| train/                    |          |
|    explained_variance     | 0.566    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00487  |
|    learning_rate          | 0.001    |
|    n_updates              | 42       |
|    policy_objective       | 0.0624   |
|    value_loss             | 0.000825 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 88000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 43    |
|    time_elapsed    | 8986  |
|    total_timesteps | 88064 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 89000    |
| train/                    |          |
|    explained_variance     | 0.674    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00425  |
|    learning_rate          | 0.001    |
|    n_updates              | 43       |
|    policy_objective       | 0.0708   |
|    value_loss             | 0.00154  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 90000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 44    |
|    time_elapsed    | 9190  |
|    total_timesteps | 90112 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 91000    |
| train/                    |          |
|    explained_variance     | 0.56     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00358  |
|    learning_rate          | 0.001    |
|    n_updates              | 44       |
|    policy_objective       | 0.0849   |
|    value_loss             | 0.000571 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 92000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 45    |
|    time_elapsed    | 9394  |
|    total_timesteps | 92160 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 93000    |
| train/                    |          |
|    explained_variance     | 0.796    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00435  |
|    learning_rate          | 0.001    |
|    n_updates              | 45       |
|    policy_objective       | 0.059    |
|    value_loss             | 0.00139  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 94000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 46    |
|    time_elapsed    | 9599  |
|    total_timesteps | 94208 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 95000    |
| train/                    |          |
|    explained_variance     | 0.671    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00413  |
|    learning_rate          | 0.001    |
|    n_updates              | 46       |
|    policy_objective       | 0.054    |
|    value_loss             | 0.000812 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 96000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 47    |
|    time_elapsed    | 9803  |
|    total_timesteps | 96256 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 97000    |
| train/                    |          |
|    explained_variance     | 0.833    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00558  |
|    learning_rate          | 0.001    |
|    n_updates              | 47       |
|    policy_objective       | 0.0606   |
|    value_loss             | 0.000863 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 98000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 48    |
|    time_elapsed    | 10007 |
|    total_timesteps | 98304 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 99000    |
| train/                    |          |
|    explained_variance     | 0.607    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00374  |
|    learning_rate          | 0.001    |
|    n_updates              | 48       |
|    policy_objective       | 0.0762   |
|    value_loss             | 0.000654 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 100000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 49     |
|    time_elapsed    | 10212  |
|    total_timesteps | 100352 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 101000   |
| train/                    |          |
|    explained_variance     | 0.793    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 49       |
|    policy_objective       | 0.0667   |
|    value_loss             | 0.00115  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 102000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 50     |
|    time_elapsed    | 10416  |
|    total_timesteps | 102400 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 103000   |
| train/                    |          |
|    explained_variance     | 0.749    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0053   |
|    learning_rate          | 0.001    |
|    n_updates              | 50       |
|    policy_objective       | 0.0611   |
|    value_loss             | 0.00114  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 104000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 51     |
|    time_elapsed    | 10620  |
|    total_timesteps | 104448 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 105000   |
| train/                    |          |
|    explained_variance     | 0.705    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0054   |
|    learning_rate          | 0.001    |
|    n_updates              | 51       |
|    policy_objective       | 0.0595   |
|    value_loss             | 0.0016   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 106000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 52     |
|    time_elapsed    | 10825  |
|    total_timesteps | 106496 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 107000   |
| train/                    |          |
|    explained_variance     | 0.91     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00546  |
|    learning_rate          | 0.001    |
|    n_updates              | 52       |
|    policy_objective       | 0.0553   |
|    value_loss             | 0.000527 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 108000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 53     |
|    time_elapsed    | 11029  |
|    total_timesteps | 108544 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 109000   |
| train/                    |          |
|    explained_variance     | 0.86     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00665  |
|    learning_rate          | 0.001    |
|    n_updates              | 53       |
|    policy_objective       | 0.0609   |
|    value_loss             | 0.000843 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 110000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 54     |
|    time_elapsed    | 11233  |
|    total_timesteps | 110592 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 111000   |
| train/                    |          |
|    explained_variance     | 0.667    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00449  |
|    learning_rate          | 0.001    |
|    n_updates              | 54       |
|    policy_objective       | 0.0713   |
|    value_loss             | 0.000796 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 112000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 55     |
|    time_elapsed    | 11438  |
|    total_timesteps | 112640 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 113000   |
| train/                    |          |
|    explained_variance     | 0.756    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00375  |
|    learning_rate          | 0.001    |
|    n_updates              | 55       |
|    policy_objective       | 0.0657   |
|    value_loss             | 0.000624 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 114000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 56     |
|    time_elapsed    | 11642  |
|    total_timesteps | 114688 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 115000   |
| train/                    |          |
|    explained_variance     | 0.912    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00519  |
|    learning_rate          | 0.001    |
|    n_updates              | 56       |
|    policy_objective       | 0.0505   |
|    value_loss             | 0.000705 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 116000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 57     |
|    time_elapsed    | 11846  |
|    total_timesteps | 116736 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 117000   |
| train/                    |          |
|    explained_variance     | 0.54     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00351  |
|    learning_rate          | 0.001    |
|    n_updates              | 57       |
|    policy_objective       | 0.0749   |
|    value_loss             | 0.000597 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 118000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 58     |
|    time_elapsed    | 12051  |
|    total_timesteps | 118784 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 119000   |
| train/                    |          |
|    explained_variance     | 0.698    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00538  |
|    learning_rate          | 0.001    |
|    n_updates              | 58       |
|    policy_objective       | 0.0556   |
|    value_loss             | 0.00108  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 120000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 59     |
|    time_elapsed    | 12255  |
|    total_timesteps | 120832 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 121000   |
| train/                    |          |
|    explained_variance     | 0.464    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00452  |
|    learning_rate          | 0.001    |
|    n_updates              | 59       |
|    policy_objective       | 0.0676   |
|    value_loss             | 0.000686 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 122000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 60     |
|    time_elapsed    | 12459  |
|    total_timesteps | 122880 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 123000   |
| train/                    |          |
|    explained_variance     | 0.822    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00451  |
|    learning_rate          | 0.001    |
|    n_updates              | 60       |
|    policy_objective       | 0.0636   |
|    value_loss             | 0.000835 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 124000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 61     |
|    time_elapsed    | 12664  |
|    total_timesteps | 124928 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 125000   |
| train/                    |          |
|    explained_variance     | 0.82     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00563  |
|    learning_rate          | 0.001    |
|    n_updates              | 61       |
|    policy_objective       | 0.0541   |
|    value_loss             | 0.000707 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 126000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 62     |
|    time_elapsed    | 12868  |
|    total_timesteps | 126976 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 127000   |
| train/                    |          |
|    explained_variance     | 0.751    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00484  |
|    learning_rate          | 0.001    |
|    n_updates              | 62       |
|    policy_objective       | 0.0588   |
|    value_loss             | 0.000426 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 128000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 129000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 63     |
|    time_elapsed    | 13172  |
|    total_timesteps | 129024 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 130000   |
| train/                    |          |
|    explained_variance     | 0.851    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00663  |
|    learning_rate          | 0.001    |
|    n_updates              | 63       |
|    policy_objective       | 0.053    |
|    value_loss             | 0.000937 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 131000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 64     |
|    time_elapsed    | 13377  |
|    total_timesteps | 131072 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 132000   |
| train/                    |          |
|    explained_variance     | 0.798    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00583  |
|    learning_rate          | 0.001    |
|    n_updates              | 64       |
|    policy_objective       | 0.054    |
|    value_loss             | 0.000297 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 133000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 65     |
|    time_elapsed    | 13581  |
|    total_timesteps | 133120 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 134000   |
| train/                    |          |
|    explained_variance     | 0.737    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00485  |
|    learning_rate          | 0.001    |
|    n_updates              | 65       |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.00151  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 135000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 66     |
|    time_elapsed    | 13785  |
|    total_timesteps | 135168 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 136000   |
| train/                    |          |
|    explained_variance     | 0.475    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00475  |
|    learning_rate          | 0.001    |
|    n_updates              | 66       |
|    policy_objective       | 0.0595   |
|    value_loss             | 0.000948 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 137000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 67     |
|    time_elapsed    | 13990  |
|    total_timesteps | 137216 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 138000   |
| train/                    |          |
|    explained_variance     | 0.869    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00577  |
|    learning_rate          | 0.001    |
|    n_updates              | 67       |
|    policy_objective       | 0.0549   |
|    value_loss             | 0.00102  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 139000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 68     |
|    time_elapsed    | 14194  |
|    total_timesteps | 139264 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 140000   |
| train/                    |          |
|    explained_variance     | 0.685    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00538  |
|    learning_rate          | 0.001    |
|    n_updates              | 68       |
|    policy_objective       | 0.0657   |
|    value_loss             | 0.000566 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 141000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 69     |
|    time_elapsed    | 14398  |
|    total_timesteps | 141312 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 142000   |
| train/                    |          |
|    explained_variance     | 0.897    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00569  |
|    learning_rate          | 0.001    |
|    n_updates              | 69       |
|    policy_objective       | 0.0537   |
|    value_loss             | 0.00145  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 143000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 70     |
|    time_elapsed    | 14603  |
|    total_timesteps | 143360 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 144000   |
| train/                    |          |
|    explained_variance     | 0.87     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0055   |
|    learning_rate          | 0.001    |
|    n_updates              | 70       |
|    policy_objective       | 0.05     |
|    value_loss             | 0.000737 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 145000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 71     |
|    time_elapsed    | 14807  |
|    total_timesteps | 145408 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 146000   |
| train/                    |          |
|    explained_variance     | 0.675    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.005    |
|    learning_rate          | 0.001    |
|    n_updates              | 71       |
|    policy_objective       | 0.0544   |
|    value_loss             | 0.000922 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 147000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 72     |
|    time_elapsed    | 15011  |
|    total_timesteps | 147456 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 148000   |
| train/                    |          |
|    explained_variance     | 0.756    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00431  |
|    learning_rate          | 0.001    |
|    n_updates              | 72       |
|    policy_objective       | 0.0658   |
|    value_loss             | 0.00067  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 149000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 73     |
|    time_elapsed    | 15215  |
|    total_timesteps | 149504 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 150000   |
| train/                    |          |
|    explained_variance     | 0.905    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00552  |
|    learning_rate          | 0.001    |
|    n_updates              | 73       |
|    policy_objective       | 0.0493   |
|    value_loss             | 0.00034  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 151000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 74     |
|    time_elapsed    | 15420  |
|    total_timesteps | 151552 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 152000   |
| train/                    |          |
|    explained_variance     | 0.727    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00588  |
|    learning_rate          | 0.001    |
|    n_updates              | 74       |
|    policy_objective       | 0.0542   |
|    value_loss             | 0.00085  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 153000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 75     |
|    time_elapsed    | 15624  |
|    total_timesteps | 153600 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 154000   |
| train/                    |          |
|    explained_variance     | 0.876    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0055   |
|    learning_rate          | 0.001    |
|    n_updates              | 75       |
|    policy_objective       | 0.0476   |
|    value_loss             | 0.00089  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 155000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 76     |
|    time_elapsed    | 15828  |
|    total_timesteps | 155648 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 156000   |
| train/                    |          |
|    explained_variance     | 0.747    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00528  |
|    learning_rate          | 0.001    |
|    n_updates              | 76       |
|    policy_objective       | 0.0549   |
|    value_loss             | 0.00113  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 157000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 77     |
|    time_elapsed    | 16033  |
|    total_timesteps | 157696 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 158000   |
| train/                    |          |
|    explained_variance     | 0.736    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0047   |
|    learning_rate          | 0.001    |
|    n_updates              | 77       |
|    policy_objective       | 0.0596   |
|    value_loss             | 0.000753 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 159000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 78     |
|    time_elapsed    | 16237  |
|    total_timesteps | 159744 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 160000   |
| train/                    |          |
|    explained_variance     | 0.797    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00673  |
|    learning_rate          | 0.001    |
|    n_updates              | 78       |
|    policy_objective       | 0.0565   |
|    value_loss             | 0.000718 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 161000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 79     |
|    time_elapsed    | 16442  |
|    total_timesteps | 161792 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 162000   |
| train/                    |          |
|    explained_variance     | 0.72     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00578  |
|    learning_rate          | 0.001    |
|    n_updates              | 79       |
|    policy_objective       | 0.0598   |
|    value_loss             | 0.000255 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 163000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 80     |
|    time_elapsed    | 16646  |
|    total_timesteps | 163840 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 164000   |
| train/                    |          |
|    explained_variance     | 0.854    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00611  |
|    learning_rate          | 0.001    |
|    n_updates              | 80       |
|    policy_objective       | 0.0502   |
|    value_loss             | 0.000514 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 165000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 81     |
|    time_elapsed    | 16850  |
|    total_timesteps | 165888 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 166000   |
| train/                    |          |
|    explained_variance     | 0.658    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00453  |
|    learning_rate          | 0.001    |
|    n_updates              | 81       |
|    policy_objective       | 0.0625   |
|    value_loss             | 0.000697 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 167000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 82     |
|    time_elapsed    | 17055  |
|    total_timesteps | 167936 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 168000   |
| train/                    |          |
|    explained_variance     | 0.51     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0053   |
|    learning_rate          | 0.001    |
|    n_updates              | 82       |
|    policy_objective       | 0.0603   |
|    value_loss             | 0.000495 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 169000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 83     |
|    time_elapsed    | 17259  |
|    total_timesteps | 169984 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 170000   |
| train/                    |          |
|    explained_variance     | 0.72     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00474  |
|    learning_rate          | 0.001    |
|    n_updates              | 83       |
|    policy_objective       | 0.061    |
|    value_loss             | 0.000625 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 171000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 172000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 84     |
|    time_elapsed    | 17563  |
|    total_timesteps | 172032 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 173000   |
| train/                    |          |
|    explained_variance     | 0.804    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00506  |
|    learning_rate          | 0.001    |
|    n_updates              | 84       |
|    policy_objective       | 0.065    |
|    value_loss             | 0.000848 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 174000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 85     |
|    time_elapsed    | 17768  |
|    total_timesteps | 174080 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 175000   |
| train/                    |          |
|    explained_variance     | 0.74     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00629  |
|    learning_rate          | 0.001    |
|    n_updates              | 85       |
|    policy_objective       | 0.0602   |
|    value_loss             | 0.000437 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 176000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 86     |
|    time_elapsed    | 17972  |
|    total_timesteps | 176128 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 177000   |
| train/                    |          |
|    explained_variance     | 0.269    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00494  |
|    learning_rate          | 0.001    |
|    n_updates              | 86       |
|    policy_objective       | 0.0628   |
|    value_loss             | 0.000824 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 178000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 87     |
|    time_elapsed    | 18176  |
|    total_timesteps | 178176 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 179000   |
| train/                    |          |
|    explained_variance     | 0.286    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00523  |
|    learning_rate          | 0.001    |
|    n_updates              | 87       |
|    policy_objective       | 0.0575   |
|    value_loss             | 0.000542 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 180000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 88     |
|    time_elapsed    | 18381  |
|    total_timesteps | 180224 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 181000   |
| train/                    |          |
|    explained_variance     | 0.754    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00528  |
|    learning_rate          | 0.001    |
|    n_updates              | 88       |
|    policy_objective       | 0.0661   |
|    value_loss             | 0.000655 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 182000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 89     |
|    time_elapsed    | 18585  |
|    total_timesteps | 182272 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 183000   |
| train/                    |          |
|    explained_variance     | 0.63     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00591  |
|    learning_rate          | 0.001    |
|    n_updates              | 89       |
|    policy_objective       | 0.0591   |
|    value_loss             | 0.000582 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 184000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 90     |
|    time_elapsed    | 18789  |
|    total_timesteps | 184320 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 185000   |
| train/                    |          |
|    explained_variance     | 0.693    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00504  |
|    learning_rate          | 0.001    |
|    n_updates              | 90       |
|    policy_objective       | 0.069    |
|    value_loss             | 0.00061  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 186000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 91     |
|    time_elapsed    | 18994  |
|    total_timesteps | 186368 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 187000   |
| train/                    |          |
|    explained_variance     | 0.778    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00552  |
|    learning_rate          | 0.001    |
|    n_updates              | 91       |
|    policy_objective       | 0.0645   |
|    value_loss             | 0.000842 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 188000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 92     |
|    time_elapsed    | 19198  |
|    total_timesteps | 188416 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 189000   |
| train/                    |          |
|    explained_variance     | 0.568    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00507  |
|    learning_rate          | 0.001    |
|    n_updates              | 92       |
|    policy_objective       | 0.0549   |
|    value_loss             | 0.000789 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 190000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 93     |
|    time_elapsed    | 19402  |
|    total_timesteps | 190464 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 191000   |
| train/                    |          |
|    explained_variance     | 0.547    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00531  |
|    learning_rate          | 0.001    |
|    n_updates              | 93       |
|    policy_objective       | 0.06     |
|    value_loss             | 0.000593 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 192000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 94     |
|    time_elapsed    | 19607  |
|    total_timesteps | 192512 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 193000   |
| train/                    |          |
|    explained_variance     | 0.788    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00556  |
|    learning_rate          | 0.001    |
|    n_updates              | 94       |
|    policy_objective       | 0.0572   |
|    value_loss             | 0.000801 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 194000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 95     |
|    time_elapsed    | 19811  |
|    total_timesteps | 194560 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 195000   |
| train/                    |          |
|    explained_variance     | 0.19     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00574  |
|    learning_rate          | 0.001    |
|    n_updates              | 95       |
|    policy_objective       | 0.0616   |
|    value_loss             | 0.000568 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 196000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 96     |
|    time_elapsed    | 20015  |
|    total_timesteps | 196608 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 197000   |
| train/                    |          |
|    explained_variance     | 0.567    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00532  |
|    learning_rate          | 0.001    |
|    n_updates              | 96       |
|    policy_objective       | 0.0585   |
|    value_loss             | 0.000837 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 198000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 97     |
|    time_elapsed    | 20220  |
|    total_timesteps | 198656 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 199000   |
| train/                    |          |
|    explained_variance     | 0.666    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00549  |
|    learning_rate          | 0.001    |
|    n_updates              | 97       |
|    policy_objective       | 0.0583   |
|    value_loss             | 0.000616 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 200000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 98     |
|    time_elapsed    | 20424  |
|    total_timesteps | 200704 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 201000   |
| train/                    |          |
|    explained_variance     | 0.6      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00491  |
|    learning_rate          | 0.001    |
|    n_updates              | 98       |
|    policy_objective       | 0.0568   |
|    value_loss             | 0.000731 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 202000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 99     |
|    time_elapsed    | 20628  |
|    total_timesteps | 202752 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 203000   |
| train/                    |          |
|    explained_variance     | 0.631    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00537  |
|    learning_rate          | 0.001    |
|    n_updates              | 99       |
|    policy_objective       | 0.0537   |
|    value_loss             | 0.000897 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 204000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 100    |
|    time_elapsed    | 20833  |
|    total_timesteps | 204800 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 205000   |
| train/                    |          |
|    explained_variance     | 0.49     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00458  |
|    learning_rate          | 0.001    |
|    n_updates              | 100      |
|    policy_objective       | 0.0552   |
|    value_loss             | 0.000998 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 206000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 101    |
|    time_elapsed    | 21037  |
|    total_timesteps | 206848 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 207000   |
| train/                    |          |
|    explained_variance     | 0.486    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00529  |
|    learning_rate          | 0.001    |
|    n_updates              | 101      |
|    policy_objective       | 0.0577   |
|    value_loss             | 0.000742 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 208000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 102    |
|    time_elapsed    | 21241  |
|    total_timesteps | 208896 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 209000   |
| train/                    |          |
|    explained_variance     | 0.702    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00529  |
|    learning_rate          | 0.001    |
|    n_updates              | 102      |
|    policy_objective       | 0.0633   |
|    value_loss             | 0.000786 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 210000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 103    |
|    time_elapsed    | 21446  |
|    total_timesteps | 210944 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 211000   |
| train/                    |          |
|    explained_variance     | 0.469    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00499  |
|    learning_rate          | 0.001    |
|    n_updates              | 103      |
|    policy_objective       | 0.063    |
|    value_loss             | 0.000753 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 212000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 104    |
|    time_elapsed    | 21650  |
|    total_timesteps | 212992 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 213000   |
| train/                    |          |
|    explained_variance     | 0.697    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00499  |
|    learning_rate          | 0.001    |
|    n_updates              | 104      |
|    policy_objective       | 0.0673   |
|    value_loss             | 0.000738 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 214000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 215000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 105    |
|    time_elapsed    | 21954  |
|    total_timesteps | 215040 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 216000   |
| train/                    |          |
|    explained_variance     | 0.638    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00385  |
|    learning_rate          | 0.001    |
|    n_updates              | 105      |
|    policy_objective       | 0.0696   |
|    value_loss             | 0.000784 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 217000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 106    |
|    time_elapsed    | 22159  |
|    total_timesteps | 217088 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 218000   |
| train/                    |          |
|    explained_variance     | 0.628    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00491  |
|    learning_rate          | 0.001    |
|    n_updates              | 106      |
|    policy_objective       | 0.0498   |
|    value_loss             | 0.000747 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 219000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 107    |
|    time_elapsed    | 22363  |
|    total_timesteps | 219136 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 220000   |
| train/                    |          |
|    explained_variance     | 0.518    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0063   |
|    learning_rate          | 0.001    |
|    n_updates              | 107      |
|    policy_objective       | 0.0569   |
|    value_loss             | 0.000754 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 221000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 108    |
|    time_elapsed    | 22567  |
|    total_timesteps | 221184 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 222000   |
| train/                    |          |
|    explained_variance     | 0.687    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00584  |
|    learning_rate          | 0.001    |
|    n_updates              | 108      |
|    policy_objective       | 0.0492   |
|    value_loss             | 0.000787 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 223000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 109    |
|    time_elapsed    | 22772  |
|    total_timesteps | 223232 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 224000   |
| train/                    |          |
|    explained_variance     | 0.652    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00486  |
|    learning_rate          | 0.001    |
|    n_updates              | 109      |
|    policy_objective       | 0.0635   |
|    value_loss             | 0.000821 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 225000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 110    |
|    time_elapsed    | 22976  |
|    total_timesteps | 225280 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 226000   |
| train/                    |          |
|    explained_variance     | 0.273    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00485  |
|    learning_rate          | 0.001    |
|    n_updates              | 110      |
|    policy_objective       | 0.0664   |
|    value_loss             | 0.00067  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 227000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 111    |
|    time_elapsed    | 23180  |
|    total_timesteps | 227328 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 228000   |
| train/                    |          |
|    explained_variance     | 0.604    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00433  |
|    learning_rate          | 0.001    |
|    n_updates              | 111      |
|    policy_objective       | 0.0557   |
|    value_loss             | 0.000926 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 229000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 112    |
|    time_elapsed    | 23385  |
|    total_timesteps | 229376 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 230000   |
| train/                    |          |
|    explained_variance     | 0.807    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00437  |
|    learning_rate          | 0.001    |
|    n_updates              | 112      |
|    policy_objective       | 0.0644   |
|    value_loss             | 0.00103  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 231000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 113    |
|    time_elapsed    | 23589  |
|    total_timesteps | 231424 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 232000   |
| train/                    |          |
|    explained_variance     | 0.492    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00497  |
|    learning_rate          | 0.001    |
|    n_updates              | 113      |
|    policy_objective       | 0.0585   |
|    value_loss             | 0.000841 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 233000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 114    |
|    time_elapsed    | 23793  |
|    total_timesteps | 233472 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 234000   |
| train/                    |          |
|    explained_variance     | 0.491    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00638  |
|    learning_rate          | 0.001    |
|    n_updates              | 114      |
|    policy_objective       | 0.0469   |
|    value_loss             | 0.000927 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 235000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 115    |
|    time_elapsed    | 23998  |
|    total_timesteps | 235520 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 236000   |
| train/                    |          |
|    explained_variance     | 0.536    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00552  |
|    learning_rate          | 0.001    |
|    n_updates              | 115      |
|    policy_objective       | 0.0581   |
|    value_loss             | 0.00111  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 237000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 116    |
|    time_elapsed    | 24202  |
|    total_timesteps | 237568 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 238000   |
| train/                    |          |
|    explained_variance     | 0.502    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00481  |
|    learning_rate          | 0.001    |
|    n_updates              | 116      |
|    policy_objective       | 0.0524   |
|    value_loss             | 0.00109  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 239000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 117    |
|    time_elapsed    | 24406  |
|    total_timesteps | 239616 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 240000   |
| train/                    |          |
|    explained_variance     | 0.51     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00506  |
|    learning_rate          | 0.001    |
|    n_updates              | 117      |
|    policy_objective       | 0.0599   |
|    value_loss             | 0.000842 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 241000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 118    |
|    time_elapsed    | 24611  |
|    total_timesteps | 241664 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 242000   |
| train/                    |          |
|    explained_variance     | 0.638    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00509  |
|    learning_rate          | 0.001    |
|    n_updates              | 118      |
|    policy_objective       | 0.0651   |
|    value_loss             | 0.000966 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 243000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 119    |
|    time_elapsed    | 24815  |
|    total_timesteps | 243712 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 244000   |
| train/                    |          |
|    explained_variance     | 0.504    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00571  |
|    learning_rate          | 0.001    |
|    n_updates              | 119      |
|    policy_objective       | 0.0623   |
|    value_loss             | 0.000798 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 245000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 120    |
|    time_elapsed    | 25019  |
|    total_timesteps | 245760 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 246000   |
| train/                    |          |
|    explained_variance     | 0.533    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 120      |
|    policy_objective       | 0.0601   |
|    value_loss             | 0.000822 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 247000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 121    |
|    time_elapsed    | 25224  |
|    total_timesteps | 247808 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 248000   |
| train/                    |          |
|    explained_variance     | 0.77     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00653  |
|    learning_rate          | 0.001    |
|    n_updates              | 121      |
|    policy_objective       | 0.0589   |
|    value_loss             | 0.0012   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 249000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 122    |
|    time_elapsed    | 25428  |
|    total_timesteps | 249856 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 250000   |
| train/                    |          |
|    explained_variance     | 0.59     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00507  |
|    learning_rate          | 0.001    |
|    n_updates              | 122      |
|    policy_objective       | 0.0549   |
|    value_loss             | 0.00122  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 251000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 123    |
|    time_elapsed    | 25632  |
|    total_timesteps | 251904 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 252000   |
| train/                    |          |
|    explained_variance     | 0.709    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00757  |
|    learning_rate          | 0.001    |
|    n_updates              | 123      |
|    policy_objective       | 0.0736   |
|    value_loss             | 0.00108  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 253000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 124    |
|    time_elapsed    | 25837  |
|    total_timesteps | 253952 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 254000   |
| train/                    |          |
|    explained_variance     | 0.653    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00485  |
|    learning_rate          | 0.001    |
|    n_updates              | 124      |
|    policy_objective       | 0.055    |
|    value_loss             | 0.000975 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 255000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 256000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 125    |
|    time_elapsed    | 26141  |
|    total_timesteps | 256000 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 257000   |
| train/                    |          |
|    explained_variance     | 0.631    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00419  |
|    learning_rate          | 0.001    |
|    n_updates              | 125      |
|    policy_objective       | 0.057    |
|    value_loss             | 0.000787 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 258000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 126    |
|    time_elapsed    | 26345  |
|    total_timesteps | 258048 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 259000   |
| train/                    |          |
|    explained_variance     | 0.57     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00458  |
|    learning_rate          | 0.001    |
|    n_updates              | 126      |
|    policy_objective       | 0.0567   |
|    value_loss             | 0.00089  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 260000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 127    |
|    time_elapsed    | 26550  |
|    total_timesteps | 260096 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 261000   |
| train/                    |          |
|    explained_variance     | 0.462    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00567  |
|    learning_rate          | 0.001    |
|    n_updates              | 127      |
|    policy_objective       | 0.0623   |
|    value_loss             | 0.000807 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 262000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 128    |
|    time_elapsed    | 26754  |
|    total_timesteps | 262144 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 263000   |
| train/                    |          |
|    explained_variance     | 0.313    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00621  |
|    learning_rate          | 0.001    |
|    n_updates              | 128      |
|    policy_objective       | 0.0543   |
|    value_loss             | 0.000965 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 264000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 129    |
|    time_elapsed    | 26958  |
|    total_timesteps | 264192 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 265000   |
| train/                    |          |
|    explained_variance     | 0.243    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00507  |
|    learning_rate          | 0.001    |
|    n_updates              | 129      |
|    policy_objective       | 0.0598   |
|    value_loss             | 0.000967 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 266000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 130    |
|    time_elapsed    | 27163  |
|    total_timesteps | 266240 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 267000   |
| train/                    |          |
|    explained_variance     | 0.417    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00562  |
|    learning_rate          | 0.001    |
|    n_updates              | 130      |
|    policy_objective       | 0.0495   |
|    value_loss             | 0.00111  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 268000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 131    |
|    time_elapsed    | 27367  |
|    total_timesteps | 268288 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 269000   |
| train/                    |          |
|    explained_variance     | 0.708    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00582  |
|    learning_rate          | 0.001    |
|    n_updates              | 131      |
|    policy_objective       | 0.0555   |
|    value_loss             | 0.00125  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 270000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 132    |
|    time_elapsed    | 27571  |
|    total_timesteps | 270336 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 271000   |
| train/                    |          |
|    explained_variance     | 0.594    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00565  |
|    learning_rate          | 0.001    |
|    n_updates              | 132      |
|    policy_objective       | 0.0496   |
|    value_loss             | 0.00112  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 272000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 133    |
|    time_elapsed    | 27776  |
|    total_timesteps | 272384 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 273000   |
| train/                    |          |
|    explained_variance     | 0.722    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00687  |
|    learning_rate          | 0.001    |
|    n_updates              | 133      |
|    policy_objective       | 0.0585   |
|    value_loss             | 0.00114  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 274000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 134    |
|    time_elapsed    | 27980  |
|    total_timesteps | 274432 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 275000   |
| train/                    |          |
|    explained_variance     | 0.424    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00596  |
|    learning_rate          | 0.001    |
|    n_updates              | 134      |
|    policy_objective       | 0.0552   |
|    value_loss             | 0.000944 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 276000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 135    |
|    time_elapsed    | 28184  |
|    total_timesteps | 276480 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 277000   |
| train/                    |          |
|    explained_variance     | 0.524    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00571  |
|    learning_rate          | 0.001    |
|    n_updates              | 135      |
|    policy_objective       | 0.0634   |
|    value_loss             | 0.00112  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 278000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 136    |
|    time_elapsed    | 28389  |
|    total_timesteps | 278528 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 279000   |
| train/                    |          |
|    explained_variance     | 0.584    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0057   |
|    learning_rate          | 0.001    |
|    n_updates              | 136      |
|    policy_objective       | 0.0482   |
|    value_loss             | 0.00116  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 280000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 137    |
|    time_elapsed    | 28593  |
|    total_timesteps | 280576 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 281000   |
| train/                    |          |
|    explained_variance     | 0.568    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00513  |
|    learning_rate          | 0.001    |
|    n_updates              | 137      |
|    policy_objective       | 0.0588   |
|    value_loss             | 0.00135  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 282000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 138    |
|    time_elapsed    | 28797  |
|    total_timesteps | 282624 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 283000   |
| train/                    |          |
|    explained_variance     | 0.722    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00494  |
|    learning_rate          | 0.001    |
|    n_updates              | 138      |
|    policy_objective       | 0.0613   |
|    value_loss             | 0.00095  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 284000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 139    |
|    time_elapsed    | 29002  |
|    total_timesteps | 284672 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 285000   |
| train/                    |          |
|    explained_variance     | 0.541    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00761  |
|    learning_rate          | 0.001    |
|    n_updates              | 139      |
|    policy_objective       | 0.0539   |
|    value_loss             | 0.00157  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 286000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 140    |
|    time_elapsed    | 29206  |
|    total_timesteps | 286720 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 287000   |
| train/                    |          |
|    explained_variance     | 0.368    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00584  |
|    learning_rate          | 0.001    |
|    n_updates              | 140      |
|    policy_objective       | 0.0595   |
|    value_loss             | 0.00193  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 288000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 141    |
|    time_elapsed    | 29410  |
|    total_timesteps | 288768 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 289000   |
| train/                    |          |
|    explained_variance     | 0.72     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00547  |
|    learning_rate          | 0.001    |
|    n_updates              | 141      |
|    policy_objective       | 0.0687   |
|    value_loss             | 0.00147  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 290000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 142    |
|    time_elapsed    | 29615  |
|    total_timesteps | 290816 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 291000   |
| train/                    |          |
|    explained_variance     | 0.578    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00615  |
|    learning_rate          | 0.001    |
|    n_updates              | 142      |
|    policy_objective       | 0.0578   |
|    value_loss             | 0.00166  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 292000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 143    |
|    time_elapsed    | 29819  |
|    total_timesteps | 292864 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 293000   |
| train/                    |          |
|    explained_variance     | 0.434    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00588  |
|    learning_rate          | 0.001    |
|    n_updates              | 143      |
|    policy_objective       | 0.053    |
|    value_loss             | 0.00138  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 294000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 144    |
|    time_elapsed    | 30023  |
|    total_timesteps | 294912 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 295000   |
| train/                    |          |
|    explained_variance     | 0.516    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 144      |
|    policy_objective       | 0.0532   |
|    value_loss             | 0.00111  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 296000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 145    |
|    time_elapsed    | 30228  |
|    total_timesteps | 296960 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 297000   |
| train/                    |          |
|    explained_variance     | 0.731    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00609  |
|    learning_rate          | 0.001    |
|    n_updates              | 145      |
|    policy_objective       | 0.0537   |
|    value_loss             | 0.00122  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 298000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 299000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 146    |
|    time_elapsed    | 30532  |
|    total_timesteps | 299008 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 300000   |
| train/                    |          |
|    explained_variance     | 0.495    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00481  |
|    learning_rate          | 0.001    |
|    n_updates              | 146      |
|    policy_objective       | 0.051    |
|    value_loss             | 0.00137  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 301000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 147    |
|    time_elapsed    | 30736  |
|    total_timesteps | 301056 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 302000   |
| train/                    |          |
|    explained_variance     | 0.547    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00587  |
|    learning_rate          | 0.001    |
|    n_updates              | 147      |
|    policy_objective       | 0.0496   |
|    value_loss             | 0.00178  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 303000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 148    |
|    time_elapsed    | 30941  |
|    total_timesteps | 303104 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 304000   |
| train/                    |          |
|    explained_variance     | 0.377    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00653  |
|    learning_rate          | 0.001    |
|    n_updates              | 148      |
|    policy_objective       | 0.0494   |
|    value_loss             | 0.00152  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 305000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 149    |
|    time_elapsed    | 31145  |
|    total_timesteps | 305152 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 306000   |
| train/                    |          |
|    explained_variance     | 0.398    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00597  |
|    learning_rate          | 0.001    |
|    n_updates              | 149      |
|    policy_objective       | 0.0464   |
|    value_loss             | 0.00147  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 307000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 150    |
|    time_elapsed    | 31349  |
|    total_timesteps | 307200 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 308000   |
| train/                    |          |
|    explained_variance     | 0.383    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00475  |
|    learning_rate          | 0.001    |
|    n_updates              | 150      |
|    policy_objective       | 0.0541   |
|    value_loss             | 0.00123  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 309000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 151    |
|    time_elapsed    | 31554  |
|    total_timesteps | 309248 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 310000   |
| train/                    |          |
|    explained_variance     | 0.408    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00454  |
|    learning_rate          | 0.001    |
|    n_updates              | 151      |
|    policy_objective       | 0.0601   |
|    value_loss             | 0.00114  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 311000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 152    |
|    time_elapsed    | 31758  |
|    total_timesteps | 311296 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 312000   |
| train/                    |          |
|    explained_variance     | 0.663    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0058   |
|    learning_rate          | 0.001    |
|    n_updates              | 152      |
|    policy_objective       | 0.0506   |
|    value_loss             | 0.00166  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 313000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 153    |
|    time_elapsed    | 31962  |
|    total_timesteps | 313344 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 314000   |
| train/                    |          |
|    explained_variance     | 0.496    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00578  |
|    learning_rate          | 0.001    |
|    n_updates              | 153      |
|    policy_objective       | 0.0507   |
|    value_loss             | 0.00179  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 315000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 154    |
|    time_elapsed    | 32167  |
|    total_timesteps | 315392 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 316000   |
| train/                    |          |
|    explained_variance     | 0.456    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00702  |
|    learning_rate          | 0.001    |
|    n_updates              | 154      |
|    policy_objective       | 0.0511   |
|    value_loss             | 0.0024   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 317000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 155    |
|    time_elapsed    | 32371  |
|    total_timesteps | 317440 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 318000   |
| train/                    |          |
|    explained_variance     | 0.591    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00528  |
|    learning_rate          | 0.001    |
|    n_updates              | 155      |
|    policy_objective       | 0.0458   |
|    value_loss             | 0.00209  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 319000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 156    |
|    time_elapsed    | 32575  |
|    total_timesteps | 319488 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 320000   |
| train/                    |          |
|    explained_variance     | 0.627    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00619  |
|    learning_rate          | 0.001    |
|    n_updates              | 156      |
|    policy_objective       | 0.0467   |
|    value_loss             | 0.00223  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 321000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 157    |
|    time_elapsed    | 32780  |
|    total_timesteps | 321536 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 322000   |
| train/                    |          |
|    explained_variance     | 0.548    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00567  |
|    learning_rate          | 0.001    |
|    n_updates              | 157      |
|    policy_objective       | 0.0569   |
|    value_loss             | 0.00204  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 323000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 158    |
|    time_elapsed    | 32984  |
|    total_timesteps | 323584 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 324000   |
| train/                    |          |
|    explained_variance     | 0.551    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00819  |
|    learning_rate          | 0.001    |
|    n_updates              | 158      |
|    policy_objective       | 0.0594   |
|    value_loss             | 0.00232  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 325000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 159    |
|    time_elapsed    | 33188  |
|    total_timesteps | 325632 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 326000   |
| train/                    |          |
|    explained_variance     | 0.551    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0054   |
|    learning_rate          | 0.001    |
|    n_updates              | 159      |
|    policy_objective       | 0.0445   |
|    value_loss             | 0.00219  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 327000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 160    |
|    time_elapsed    | 33393  |
|    total_timesteps | 327680 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 328000   |
| train/                    |          |
|    explained_variance     | 0.446    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0069   |
|    learning_rate          | 0.001    |
|    n_updates              | 160      |
|    policy_objective       | 0.0528   |
|    value_loss             | 0.00242  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 329000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 161    |
|    time_elapsed    | 33597  |
|    total_timesteps | 329728 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 330000   |
| train/                    |          |
|    explained_variance     | 0.525    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00444  |
|    learning_rate          | 0.001    |
|    n_updates              | 161      |
|    policy_objective       | 0.054    |
|    value_loss             | 0.00134  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 331000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 162    |
|    time_elapsed    | 33801  |
|    total_timesteps | 331776 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 332000   |
| train/                    |          |
|    explained_variance     | 0.397    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00766  |
|    learning_rate          | 0.001    |
|    n_updates              | 162      |
|    policy_objective       | 0.0539   |
|    value_loss             | 0.00233  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 333000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 163    |
|    time_elapsed    | 34006  |
|    total_timesteps | 333824 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 334000   |
| train/                    |          |
|    explained_variance     | 0.544    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00627  |
|    learning_rate          | 0.001    |
|    n_updates              | 163      |
|    policy_objective       | 0.0503   |
|    value_loss             | 0.0019   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 335000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 164    |
|    time_elapsed    | 34210  |
|    total_timesteps | 335872 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 336000   |
| train/                    |          |
|    explained_variance     | 0.514    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00559  |
|    learning_rate          | 0.001    |
|    n_updates              | 164      |
|    policy_objective       | 0.0596   |
|    value_loss             | 0.00176  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 337000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 165    |
|    time_elapsed    | 34414  |
|    total_timesteps | 337920 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 338000   |
| train/                    |          |
|    explained_variance     | 0.641    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00691  |
|    learning_rate          | 0.001    |
|    n_updates              | 165      |
|    policy_objective       | 0.0574   |
|    value_loss             | 0.00199  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 339000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 166    |
|    time_elapsed    | 34618  |
|    total_timesteps | 339968 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 340000   |
| train/                    |          |
|    explained_variance     | 0.669    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00456  |
|    learning_rate          | 0.001    |
|    n_updates              | 166      |
|    policy_objective       | 0.0565   |
|    value_loss             | 0.00144  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 341000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 342000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 167    |
|    time_elapsed    | 34923  |
|    total_timesteps | 342016 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 343000   |
| train/                    |          |
|    explained_variance     | 0.568    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00571  |
|    learning_rate          | 0.001    |
|    n_updates              | 167      |
|    policy_objective       | 0.0491   |
|    value_loss             | 0.00277  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 344000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 168    |
|    time_elapsed    | 35127  |
|    total_timesteps | 344064 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 345000   |
| train/                    |          |
|    explained_variance     | 0.611    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00587  |
|    learning_rate          | 0.001    |
|    n_updates              | 168      |
|    policy_objective       | 0.049    |
|    value_loss             | 0.00226  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 346000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 169    |
|    time_elapsed    | 35332  |
|    total_timesteps | 346112 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 347000   |
| train/                    |          |
|    explained_variance     | 0.592    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00573  |
|    learning_rate          | 0.001    |
|    n_updates              | 169      |
|    policy_objective       | 0.0463   |
|    value_loss             | 0.00209  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 348000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 170    |
|    time_elapsed    | 35536  |
|    total_timesteps | 348160 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 349000   |
| train/                    |          |
|    explained_variance     | 0.549    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00775  |
|    learning_rate          | 0.001    |
|    n_updates              | 170      |
|    policy_objective       | 0.0443   |
|    value_loss             | 0.00248  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 350000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 171    |
|    time_elapsed    | 35740  |
|    total_timesteps | 350208 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 351000   |
| train/                    |          |
|    explained_variance     | 0.611    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0061   |
|    learning_rate          | 0.001    |
|    n_updates              | 171      |
|    policy_objective       | 0.0484   |
|    value_loss             | 0.00218  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 352000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 172    |
|    time_elapsed    | 35945  |
|    total_timesteps | 352256 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 353000   |
| train/                    |          |
|    explained_variance     | 0.628    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00742  |
|    learning_rate          | 0.001    |
|    n_updates              | 172      |
|    policy_objective       | 0.0558   |
|    value_loss             | 0.00159  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 354000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 173    |
|    time_elapsed    | 36149  |
|    total_timesteps | 354304 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 355000   |
| train/                    |          |
|    explained_variance     | 0.679    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00568  |
|    learning_rate          | 0.001    |
|    n_updates              | 173      |
|    policy_objective       | 0.0501   |
|    value_loss             | 0.00228  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 356000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 174    |
|    time_elapsed    | 36354  |
|    total_timesteps | 356352 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 357000   |
| train/                    |          |
|    explained_variance     | 0.637    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00583  |
|    learning_rate          | 0.001    |
|    n_updates              | 174      |
|    policy_objective       | 0.0439   |
|    value_loss             | 0.00214  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 358000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 175    |
|    time_elapsed    | 36558  |
|    total_timesteps | 358400 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 359000   |
| train/                    |          |
|    explained_variance     | 0.624    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00643  |
|    learning_rate          | 0.001    |
|    n_updates              | 175      |
|    policy_objective       | 0.0427   |
|    value_loss             | 0.00221  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 360000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 176    |
|    time_elapsed    | 36763  |
|    total_timesteps | 360448 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 361000   |
| train/                    |          |
|    explained_variance     | 0.736    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00543  |
|    learning_rate          | 0.001    |
|    n_updates              | 176      |
|    policy_objective       | 0.0654   |
|    value_loss             | 0.00176  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 362000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 177    |
|    time_elapsed    | 36967  |
|    total_timesteps | 362496 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 363000   |
| train/                    |          |
|    explained_variance     | 0.757    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00693  |
|    learning_rate          | 0.001    |
|    n_updates              | 177      |
|    policy_objective       | 0.0517   |
|    value_loss             | 0.00189  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 364000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 178    |
|    time_elapsed    | 37171  |
|    total_timesteps | 364544 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 365000   |
| train/                    |          |
|    explained_variance     | 0.74     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00573  |
|    learning_rate          | 0.001    |
|    n_updates              | 178      |
|    policy_objective       | 0.0698   |
|    value_loss             | 0.00158  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 366000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 179    |
|    time_elapsed    | 37376  |
|    total_timesteps | 366592 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 367000   |
| train/                    |          |
|    explained_variance     | 0.674    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0054   |
|    learning_rate          | 0.001    |
|    n_updates              | 179      |
|    policy_objective       | 0.0519   |
|    value_loss             | 0.00144  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 368000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 180    |
|    time_elapsed    | 37580  |
|    total_timesteps | 368640 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 369000   |
| train/                    |          |
|    explained_variance     | 0.54     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 180      |
|    policy_objective       | 0.0482   |
|    value_loss             | 0.00225  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 370000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 181    |
|    time_elapsed    | 37784  |
|    total_timesteps | 370688 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 371000   |
| train/                    |          |
|    explained_variance     | 0.368    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00587  |
|    learning_rate          | 0.001    |
|    n_updates              | 181      |
|    policy_objective       | 0.0513   |
|    value_loss             | 0.00231  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 372000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 182    |
|    time_elapsed    | 37989  |
|    total_timesteps | 372736 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 373000   |
| train/                    |          |
|    explained_variance     | 0.59     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00706  |
|    learning_rate          | 0.001    |
|    n_updates              | 182      |
|    policy_objective       | 0.0491   |
|    value_loss             | 0.00279  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 374000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 183    |
|    time_elapsed    | 38193  |
|    total_timesteps | 374784 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 375000   |
| train/                    |          |
|    explained_variance     | 0.553    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00706  |
|    learning_rate          | 0.001    |
|    n_updates              | 183      |
|    policy_objective       | 0.0461   |
|    value_loss             | 0.00321  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 376000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 184    |
|    time_elapsed    | 38397  |
|    total_timesteps | 376832 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 377000   |
| train/                    |          |
|    explained_variance     | 0.555    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00538  |
|    learning_rate          | 0.001    |
|    n_updates              | 184      |
|    policy_objective       | 0.0643   |
|    value_loss             | 0.00241  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 378000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 185    |
|    time_elapsed    | 38602  |
|    total_timesteps | 378880 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 379000   |
| train/                    |          |
|    explained_variance     | 0.62     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00611  |
|    learning_rate          | 0.001    |
|    n_updates              | 185      |
|    policy_objective       | 0.0495   |
|    value_loss             | 0.00244  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 380000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 186    |
|    time_elapsed    | 38806  |
|    total_timesteps | 380928 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 381000   |
| train/                    |          |
|    explained_variance     | 0.51     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00589  |
|    learning_rate          | 0.001    |
|    n_updates              | 186      |
|    policy_objective       | 0.0555   |
|    value_loss             | 0.00264  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 382000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 187    |
|    time_elapsed    | 39011  |
|    total_timesteps | 382976 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 383000   |
| train/                    |          |
|    explained_variance     | 0.463    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00588  |
|    learning_rate          | 0.001    |
|    n_updates              | 187      |
|    policy_objective       | 0.0548   |
|    value_loss             | 0.00273  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 384000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 385000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 188    |
|    time_elapsed    | 39315  |
|    total_timesteps | 385024 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 386000   |
| train/                    |          |
|    explained_variance     | 0.513    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00586  |
|    learning_rate          | 0.001    |
|    n_updates              | 188      |
|    policy_objective       | 0.0652   |
|    value_loss             | 0.00287  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 387000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 189    |
|    time_elapsed    | 39519  |
|    total_timesteps | 387072 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 388000   |
| train/                    |          |
|    explained_variance     | 0.428    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00728  |
|    learning_rate          | 0.001    |
|    n_updates              | 189      |
|    policy_objective       | 0.0453   |
|    value_loss             | 0.00335  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 389000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 190    |
|    time_elapsed    | 39724  |
|    total_timesteps | 389120 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 390000   |
| train/                    |          |
|    explained_variance     | 0.525    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0059   |
|    learning_rate          | 0.001    |
|    n_updates              | 190      |
|    policy_objective       | 0.0467   |
|    value_loss             | 0.00183  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 391000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 191    |
|    time_elapsed    | 39928  |
|    total_timesteps | 391168 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 392000   |
| train/                    |          |
|    explained_variance     | 0.447    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00804  |
|    learning_rate          | 0.001    |
|    n_updates              | 191      |
|    policy_objective       | 0.0393   |
|    value_loss             | 0.00211  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 393000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 192    |
|    time_elapsed    | 40133  |
|    total_timesteps | 393216 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 394000   |
| train/                    |          |
|    explained_variance     | 0.642    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00666  |
|    learning_rate          | 0.001    |
|    n_updates              | 192      |
|    policy_objective       | 0.0477   |
|    value_loss             | 0.0027   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 395000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 193    |
|    time_elapsed    | 40337  |
|    total_timesteps | 395264 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 396000   |
| train/                    |          |
|    explained_variance     | 0.729    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00801  |
|    learning_rate          | 0.001    |
|    n_updates              | 193      |
|    policy_objective       | 0.0583   |
|    value_loss             | 0.00238  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 397000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 194    |
|    time_elapsed    | 40541  |
|    total_timesteps | 397312 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 398000   |
| train/                    |          |
|    explained_variance     | 0.491    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00654  |
|    learning_rate          | 0.001    |
|    n_updates              | 194      |
|    policy_objective       | 0.0445   |
|    value_loss             | 0.00298  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 399000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 195    |
|    time_elapsed    | 40746  |
|    total_timesteps | 399360 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 400000   |
| train/                    |          |
|    explained_variance     | 0.551    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00639  |
|    learning_rate          | 0.001    |
|    n_updates              | 195      |
|    policy_objective       | 0.0446   |
|    value_loss             | 0.00254  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 401000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 196    |
|    time_elapsed    | 40950  |
|    total_timesteps | 401408 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 402000   |
| train/                    |          |
|    explained_variance     | 0.62     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0061   |
|    learning_rate          | 0.001    |
|    n_updates              | 196      |
|    policy_objective       | 0.0449   |
|    value_loss             | 0.00246  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 403000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 197    |
|    time_elapsed    | 41155  |
|    total_timesteps | 403456 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 404000   |
| train/                    |          |
|    explained_variance     | 0.462    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00683  |
|    learning_rate          | 0.001    |
|    n_updates              | 197      |
|    policy_objective       | 0.0464   |
|    value_loss             | 0.00267  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 405000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 198    |
|    time_elapsed    | 41359  |
|    total_timesteps | 405504 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 406000   |
| train/                    |          |
|    explained_variance     | 0.337    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0053   |
|    learning_rate          | 0.001    |
|    n_updates              | 198      |
|    policy_objective       | 0.0607   |
|    value_loss             | 0.00195  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 407000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 199    |
|    time_elapsed    | 41563  |
|    total_timesteps | 407552 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 408000   |
| train/                    |          |
|    explained_variance     | 0.41     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0099   |
|    learning_rate          | 0.001    |
|    n_updates              | 199      |
|    policy_objective       | 0.0614   |
|    value_loss             | 0.00281  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 409000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 200    |
|    time_elapsed    | 41768  |
|    total_timesteps | 409600 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 410000   |
| train/                    |          |
|    explained_variance     | 0.574    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00684  |
|    learning_rate          | 0.001    |
|    n_updates              | 200      |
|    policy_objective       | 0.0478   |
|    value_loss             | 0.00229  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 411000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 201    |
|    time_elapsed    | 41972  |
|    total_timesteps | 411648 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 412000   |
| train/                    |          |
|    explained_variance     | 0.436    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0077   |
|    learning_rate          | 0.001    |
|    n_updates              | 201      |
|    policy_objective       | 0.043    |
|    value_loss             | 0.00303  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 413000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 202    |
|    time_elapsed    | 42177  |
|    total_timesteps | 413696 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 414000   |
| train/                    |          |
|    explained_variance     | 0.652    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00898  |
|    learning_rate          | 0.001    |
|    n_updates              | 202      |
|    policy_objective       | 0.038    |
|    value_loss             | 0.00293  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 415000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 203    |
|    time_elapsed    | 42381  |
|    total_timesteps | 415744 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 416000   |
| train/                    |          |
|    explained_variance     | 0.571    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00855  |
|    learning_rate          | 0.001    |
|    n_updates              | 203      |
|    policy_objective       | 0.0486   |
|    value_loss             | 0.00271  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 417000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 204    |
|    time_elapsed    | 42585  |
|    total_timesteps | 417792 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 418000   |
| train/                    |          |
|    explained_variance     | 0.475    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00732  |
|    learning_rate          | 0.001    |
|    n_updates              | 204      |
|    policy_objective       | 0.0461   |
|    value_loss             | 0.00321  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 419000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 205    |
|    time_elapsed    | 42790  |
|    total_timesteps | 419840 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 420000   |
| train/                    |          |
|    explained_variance     | 0.536    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00622  |
|    learning_rate          | 0.001    |
|    n_updates              | 205      |
|    policy_objective       | 0.044    |
|    value_loss             | 0.00321  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 421000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 206    |
|    time_elapsed    | 42994  |
|    total_timesteps | 421888 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 422000   |
| train/                    |          |
|    explained_variance     | 0.35     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00705  |
|    learning_rate          | 0.001    |
|    n_updates              | 206      |
|    policy_objective       | 0.0456   |
|    value_loss             | 0.00343  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 423000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 207    |
|    time_elapsed    | 43199  |
|    total_timesteps | 423936 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 424000   |
| train/                    |          |
|    explained_variance     | 0.444    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00626  |
|    learning_rate          | 0.001    |
|    n_updates              | 207      |
|    policy_objective       | 0.058    |
|    value_loss             | 0.00363  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 425000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 208    |
|    time_elapsed    | 43403  |
|    total_timesteps | 425984 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 426000   |
| train/                    |          |
|    explained_variance     | 0.502    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00489  |
|    learning_rate          | 0.001    |
|    n_updates              | 208      |
|    policy_objective       | 0.0406   |
|    value_loss             | 0.00369  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 427000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 428000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 209    |
|    time_elapsed    | 43708  |
|    total_timesteps | 428032 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 429000   |
| train/                    |          |
|    explained_variance     | 0.3      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00699  |
|    learning_rate          | 0.001    |
|    n_updates              | 209      |
|    policy_objective       | 0.0651   |
|    value_loss             | 0.00363  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 430000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 210    |
|    time_elapsed    | 43912  |
|    total_timesteps | 430080 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 431000   |
| train/                    |          |
|    explained_variance     | 0.364    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00592  |
|    learning_rate          | 0.001    |
|    n_updates              | 210      |
|    policy_objective       | 0.0416   |
|    value_loss             | 0.0033   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 432000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 211    |
|    time_elapsed    | 44116  |
|    total_timesteps | 432128 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 433000   |
| train/                    |          |
|    explained_variance     | 0.499    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00786  |
|    learning_rate          | 0.001    |
|    n_updates              | 211      |
|    policy_objective       | 0.055    |
|    value_loss             | 0.00254  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 434000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 212    |
|    time_elapsed    | 44321  |
|    total_timesteps | 434176 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 435000   |
| train/                    |          |
|    explained_variance     | 0.51     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0074   |
|    learning_rate          | 0.001    |
|    n_updates              | 212      |
|    policy_objective       | 0.043    |
|    value_loss             | 0.00374  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 436000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 213    |
|    time_elapsed    | 44525  |
|    total_timesteps | 436224 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 437000   |
| train/                    |          |
|    explained_variance     | 0.566    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00748  |
|    learning_rate          | 0.001    |
|    n_updates              | 213      |
|    policy_objective       | 0.0385   |
|    value_loss             | 0.00363  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 438000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 214    |
|    time_elapsed    | 44729  |
|    total_timesteps | 438272 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 439000   |
| train/                    |          |
|    explained_variance     | 0.495    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00667  |
|    learning_rate          | 0.001    |
|    n_updates              | 214      |
|    policy_objective       | 0.0421   |
|    value_loss             | 0.00356  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 440000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 215    |
|    time_elapsed    | 44934  |
|    total_timesteps | 440320 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 441000   |
| train/                    |          |
|    explained_variance     | 0.556    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00838  |
|    learning_rate          | 0.001    |
|    n_updates              | 215      |
|    policy_objective       | 0.0431   |
|    value_loss             | 0.00368  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 442000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 216    |
|    time_elapsed    | 45138  |
|    total_timesteps | 442368 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 443000   |
| train/                    |          |
|    explained_variance     | 0.58     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0066   |
|    learning_rate          | 0.001    |
|    n_updates              | 216      |
|    policy_objective       | 0.0439   |
|    value_loss             | 0.00343  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 444000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 217    |
|    time_elapsed    | 45342  |
|    total_timesteps | 444416 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 445000   |
| train/                    |          |
|    explained_variance     | 0.556    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00699  |
|    learning_rate          | 0.001    |
|    n_updates              | 217      |
|    policy_objective       | 0.0385   |
|    value_loss             | 0.00417  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 446000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 218    |
|    time_elapsed    | 45547  |
|    total_timesteps | 446464 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 447000   |
| train/                    |          |
|    explained_variance     | 0.564    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00765  |
|    learning_rate          | 0.001    |
|    n_updates              | 218      |
|    policy_objective       | 0.0302   |
|    value_loss             | 0.00292  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 448000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 219    |
|    time_elapsed    | 45751  |
|    total_timesteps | 448512 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 449000   |
| train/                    |          |
|    explained_variance     | 0.568    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00797  |
|    learning_rate          | 0.001    |
|    n_updates              | 219      |
|    policy_objective       | 0.0474   |
|    value_loss             | 0.00211  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 450000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 220    |
|    time_elapsed    | 45956  |
|    total_timesteps | 450560 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.9      |
| time/                     |          |
|    total_timesteps        | 451000   |
| train/                    |          |
|    explained_variance     | 0.624    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00746  |
|    learning_rate          | 0.001    |
|    n_updates              | 220      |
|    policy_objective       | 0.0495   |
|    value_loss             | 0.00403  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.9      |
| time/              |          |
|    total_timesteps | 452000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 221    |
|    time_elapsed    | 46160  |
|    total_timesteps | 452608 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 453000   |
| train/                    |          |
|    explained_variance     | 0.677    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00673  |
|    learning_rate          | 0.001    |
|    n_updates              | 221      |
|    policy_objective       | 0.0518   |
|    value_loss             | 0.00332  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 454000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 222    |
|    time_elapsed    | 46364  |
|    total_timesteps | 454656 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 455000   |
| train/                    |          |
|    explained_variance     | 0.632    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00716  |
|    learning_rate          | 0.001    |
|    n_updates              | 222      |
|    policy_objective       | 0.046    |
|    value_loss             | 0.00386  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 456000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 223    |
|    time_elapsed    | 46568  |
|    total_timesteps | 456704 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 457000   |
| train/                    |          |
|    explained_variance     | 0.56     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0066   |
|    learning_rate          | 0.001    |
|    n_updates              | 223      |
|    policy_objective       | 0.0392   |
|    value_loss             | 0.00341  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 458000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 224    |
|    time_elapsed    | 46773  |
|    total_timesteps | 458752 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 459000   |
| train/                    |          |
|    explained_variance     | 0.485    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00741  |
|    learning_rate          | 0.001    |
|    n_updates              | 224      |
|    policy_objective       | 0.0521   |
|    value_loss             | 0.00499  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 460000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 225    |
|    time_elapsed    | 46977  |
|    total_timesteps | 460800 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 461000   |
| train/                    |          |
|    explained_variance     | 0.513    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00802  |
|    learning_rate          | 0.001    |
|    n_updates              | 225      |
|    policy_objective       | 0.0423   |
|    value_loss             | 0.00483  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 462000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 226    |
|    time_elapsed    | 47182  |
|    total_timesteps | 462848 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 463000   |
| train/                    |          |
|    explained_variance     | 0.462    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00711  |
|    learning_rate          | 0.001    |
|    n_updates              | 226      |
|    policy_objective       | 0.0385   |
|    value_loss             | 0.0048   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 464000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 227    |
|    time_elapsed    | 47386  |
|    total_timesteps | 464896 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 465000   |
| train/                    |          |
|    explained_variance     | 0.569    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00585  |
|    learning_rate          | 0.001    |
|    n_updates              | 227      |
|    policy_objective       | 0.0467   |
|    value_loss             | 0.00444  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 466000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 228    |
|    time_elapsed    | 47590  |
|    total_timesteps | 466944 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 467000   |
| train/                    |          |
|    explained_variance     | 0.428    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00736  |
|    learning_rate          | 0.001    |
|    n_updates              | 228      |
|    policy_objective       | 0.0472   |
|    value_loss             | 0.00442  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 468000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 229    |
|    time_elapsed    | 47795  |
|    total_timesteps | 468992 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 469000   |
| train/                    |          |
|    explained_variance     | 0.49     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00677  |
|    learning_rate          | 0.001    |
|    n_updates              | 229      |
|    policy_objective       | 0.0425   |
|    value_loss             | 0.00354  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 470000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 471000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 230    |
|    time_elapsed    | 48099  |
|    total_timesteps | 471040 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 472000   |
| train/                    |          |
|    explained_variance     | 0.486    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00532  |
|    learning_rate          | 0.001    |
|    n_updates              | 230      |
|    policy_objective       | 0.0448   |
|    value_loss             | 0.00463  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 473000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 231    |
|    time_elapsed    | 48304  |
|    total_timesteps | 473088 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 474000   |
| train/                    |          |
|    explained_variance     | 0.617    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00678  |
|    learning_rate          | 0.001    |
|    n_updates              | 231      |
|    policy_objective       | 0.0327   |
|    value_loss             | 0.00329  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 475000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 232    |
|    time_elapsed    | 48508  |
|    total_timesteps | 475136 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 476000   |
| train/                    |          |
|    explained_variance     | 0.631    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00825  |
|    learning_rate          | 0.001    |
|    n_updates              | 232      |
|    policy_objective       | 0.0403   |
|    value_loss             | 0.00225  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 477000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 233    |
|    time_elapsed    | 48712  |
|    total_timesteps | 477184 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 478000   |
| train/                    |          |
|    explained_variance     | 0.622    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00629  |
|    learning_rate          | 0.001    |
|    n_updates              | 233      |
|    policy_objective       | 0.0414   |
|    value_loss             | 0.00309  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 479000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 234    |
|    time_elapsed    | 48917  |
|    total_timesteps | 479232 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 480000   |
| train/                    |          |
|    explained_variance     | 0.654    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00743  |
|    learning_rate          | 0.001    |
|    n_updates              | 234      |
|    policy_objective       | 0.0428   |
|    value_loss             | 0.00389  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 481000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 235    |
|    time_elapsed    | 49121  |
|    total_timesteps | 481280 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 482000   |
| train/                    |          |
|    explained_variance     | 0.705    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00685  |
|    learning_rate          | 0.001    |
|    n_updates              | 235      |
|    policy_objective       | 0.0498   |
|    value_loss             | 0.00232  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 483000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 236    |
|    time_elapsed    | 49325  |
|    total_timesteps | 483328 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 484000   |
| train/                    |          |
|    explained_variance     | 0.581    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00696  |
|    learning_rate          | 0.001    |
|    n_updates              | 236      |
|    policy_objective       | 0.041    |
|    value_loss             | 0.00368  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 485000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 237    |
|    time_elapsed    | 49530  |
|    total_timesteps | 485376 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 486000   |
| train/                    |          |
|    explained_variance     | 0.749    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00756  |
|    learning_rate          | 0.001    |
|    n_updates              | 237      |
|    policy_objective       | 0.0467   |
|    value_loss             | 0.00306  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 487000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 238    |
|    time_elapsed    | 49734  |
|    total_timesteps | 487424 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 488000   |
| train/                    |          |
|    explained_variance     | 0.701    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00729  |
|    learning_rate          | 0.001    |
|    n_updates              | 238      |
|    policy_objective       | 0.0413   |
|    value_loss             | 0.00369  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 489000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 239    |
|    time_elapsed    | 49938  |
|    total_timesteps | 489472 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 490000   |
| train/                    |          |
|    explained_variance     | 0.803    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00731  |
|    learning_rate          | 0.001    |
|    n_updates              | 239      |
|    policy_objective       | 0.0492   |
|    value_loss             | 0.00204  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 491000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 240    |
|    time_elapsed    | 50143  |
|    total_timesteps | 491520 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 492000   |
| train/                    |          |
|    explained_variance     | 0.357    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00644  |
|    learning_rate          | 0.001    |
|    n_updates              | 240      |
|    policy_objective       | 0.053    |
|    value_loss             | 0.00224  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 493000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 241    |
|    time_elapsed    | 50347  |
|    total_timesteps | 493568 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 494000   |
| train/                    |          |
|    explained_variance     | 0.761    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00722  |
|    learning_rate          | 0.001    |
|    n_updates              | 241      |
|    policy_objective       | 0.0429   |
|    value_loss             | 0.00256  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 495000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 242    |
|    time_elapsed    | 50552  |
|    total_timesteps | 495616 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 496000   |
| train/                    |          |
|    explained_variance     | 0.466    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00663  |
|    learning_rate          | 0.001    |
|    n_updates              | 242      |
|    policy_objective       | 0.0368   |
|    value_loss             | 0.00391  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 497000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 243    |
|    time_elapsed    | 50756  |
|    total_timesteps | 497664 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 498000   |
| train/                    |          |
|    explained_variance     | 0.513    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00698  |
|    learning_rate          | 0.001    |
|    n_updates              | 243      |
|    policy_objective       | 0.0348   |
|    value_loss             | 0.00394  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 499000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 244    |
|    time_elapsed    | 50961  |
|    total_timesteps | 499712 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 500000   |
| train/                    |          |
|    explained_variance     | 0.469    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00828  |
|    learning_rate          | 0.001    |
|    n_updates              | 244      |
|    policy_objective       | 0.0497   |
|    value_loss             | 0.00439  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 501000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 245    |
|    time_elapsed    | 51165  |
|    total_timesteps | 501760 |
-------------------------------
