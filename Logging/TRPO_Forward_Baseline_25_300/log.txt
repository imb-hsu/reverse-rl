Logging to ./Logging/TRPO_Forward_Baseline_25_300
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 1000     |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 2000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 1    |
|    time_elapsed    | 204  |
|    total_timesteps | 2048 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 3000     |
| train/                    |          |
|    explained_variance     | 0.909    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00599  |
|    learning_rate          | 0.001    |
|    n_updates              | 1        |
|    policy_objective       | 0.0457   |
|    value_loss             | 0.00432  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 4000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 2    |
|    time_elapsed    | 408  |
|    total_timesteps | 4096 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 5000     |
| train/                    |          |
|    explained_variance     | 0.765    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00475  |
|    learning_rate          | 0.001    |
|    n_updates              | 2        |
|    policy_objective       | 0.0504   |
|    value_loss             | 0.00504  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 6000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 3    |
|    time_elapsed    | 612  |
|    total_timesteps | 6144 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 7000     |
| train/                    |          |
|    explained_variance     | 0.881    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00619  |
|    learning_rate          | 0.001    |
|    n_updates              | 3        |
|    policy_objective       | 0.0521   |
|    value_loss             | 0.0186   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 8000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 4    |
|    time_elapsed    | 817  |
|    total_timesteps | 8192 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 9000     |
| train/                    |          |
|    explained_variance     | 0.689    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00399  |
|    learning_rate          | 0.001    |
|    n_updates              | 4        |
|    policy_objective       | 0.0576   |
|    value_loss             | 0.00951  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 10000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 5     |
|    time_elapsed    | 1021  |
|    total_timesteps | 10240 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 11000    |
| train/                    |          |
|    explained_variance     | 0.838    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00547  |
|    learning_rate          | 0.001    |
|    n_updates              | 5        |
|    policy_objective       | 0.0448   |
|    value_loss             | 0.0185   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 12000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 6     |
|    time_elapsed    | 1225  |
|    total_timesteps | 12288 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 13000    |
| train/                    |          |
|    explained_variance     | 0.911    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00547  |
|    learning_rate          | 0.001    |
|    n_updates              | 6        |
|    policy_objective       | 0.0569   |
|    value_loss             | 0.00617  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 14000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 7     |
|    time_elapsed    | 1429  |
|    total_timesteps | 14336 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 15000    |
| train/                    |          |
|    explained_variance     | 0.887    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.001    |
|    n_updates              | 7        |
|    policy_objective       | 0.0489   |
|    value_loss             | 0.00259  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 16000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 8     |
|    time_elapsed    | 1634  |
|    total_timesteps | 16384 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 17000    |
| train/                    |          |
|    explained_variance     | 0.763    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00425  |
|    learning_rate          | 0.001    |
|    n_updates              | 8        |
|    policy_objective       | 0.0526   |
|    value_loss             | 0.00306  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 18000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 9     |
|    time_elapsed    | 1838  |
|    total_timesteps | 18432 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 19000    |
| train/                    |          |
|    explained_variance     | 0.916    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00598  |
|    learning_rate          | 0.001    |
|    n_updates              | 9        |
|    policy_objective       | 0.055    |
|    value_loss             | 0.00366  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 20000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 10    |
|    time_elapsed    | 2042  |
|    total_timesteps | 20480 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 21000    |
| train/                    |          |
|    explained_variance     | 0.862    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.006    |
|    learning_rate          | 0.001    |
|    n_updates              | 10       |
|    policy_objective       | 0.0561   |
|    value_loss             | 0.00201  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 22000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 11    |
|    time_elapsed    | 2247  |
|    total_timesteps | 22528 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 23000    |
| train/                    |          |
|    explained_variance     | 0.896    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00521  |
|    learning_rate          | 0.001    |
|    n_updates              | 11       |
|    policy_objective       | 0.049    |
|    value_loss             | 0.00557  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 24000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 12    |
|    time_elapsed    | 2451  |
|    total_timesteps | 24576 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 25000    |
| train/                    |          |
|    explained_variance     | 0.901    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00506  |
|    learning_rate          | 0.001    |
|    n_updates              | 12       |
|    policy_objective       | 0.0538   |
|    value_loss             | 0.0024   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 26000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 13    |
|    time_elapsed    | 2655  |
|    total_timesteps | 26624 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 27000    |
| train/                    |          |
|    explained_variance     | 0.773    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00452  |
|    learning_rate          | 0.001    |
|    n_updates              | 13       |
|    policy_objective       | 0.0542   |
|    value_loss             | 0.00371  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 28000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 14    |
|    time_elapsed    | 2860  |
|    total_timesteps | 28672 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 29000    |
| train/                    |          |
|    explained_variance     | 0.866    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.001    |
|    n_updates              | 14       |
|    policy_objective       | 0.052    |
|    value_loss             | 0.00214  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 30000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 15    |
|    time_elapsed    | 3064  |
|    total_timesteps | 30720 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 31000    |
| train/                    |          |
|    explained_variance     | 0.86     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00593  |
|    learning_rate          | 0.001    |
|    n_updates              | 15       |
|    policy_objective       | 0.0507   |
|    value_loss             | 0.00276  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 32000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 16    |
|    time_elapsed    | 3268  |
|    total_timesteps | 32768 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 33000    |
| train/                    |          |
|    explained_variance     | 0.893    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00614  |
|    learning_rate          | 0.001    |
|    n_updates              | 16       |
|    policy_objective       | 0.0437   |
|    value_loss             | 0.00318  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 34000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 17    |
|    time_elapsed    | 3473  |
|    total_timesteps | 34816 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 35000    |
| train/                    |          |
|    explained_variance     | 0.83     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00575  |
|    learning_rate          | 0.001    |
|    n_updates              | 17       |
|    policy_objective       | 0.0589   |
|    value_loss             | 0.00106  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 36000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 18    |
|    time_elapsed    | 3677  |
|    total_timesteps | 36864 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 37000    |
| train/                    |          |
|    explained_variance     | 0.845    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00505  |
|    learning_rate          | 0.001    |
|    n_updates              | 18       |
|    policy_objective       | 0.0541   |
|    value_loss             | 0.00284  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 38000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 19    |
|    time_elapsed    | 3881  |
|    total_timesteps | 38912 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 39000    |
| train/                    |          |
|    explained_variance     | 0.864    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00584  |
|    learning_rate          | 0.001    |
|    n_updates              | 19       |
|    policy_objective       | 0.0456   |
|    value_loss             | 0.00375  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 40000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 20    |
|    time_elapsed    | 4086  |
|    total_timesteps | 40960 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 41000    |
| train/                    |          |
|    explained_variance     | 0.834    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0048   |
|    learning_rate          | 0.001    |
|    n_updates              | 20       |
|    policy_objective       | 0.0589   |
|    value_loss             | 0.0014   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 42000    |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 43000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 21    |
|    time_elapsed    | 4390  |
|    total_timesteps | 43008 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 44000    |
| train/                    |          |
|    explained_variance     | 0.829    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00579  |
|    learning_rate          | 0.001    |
|    n_updates              | 21       |
|    policy_objective       | 0.049    |
|    value_loss             | 0.00226  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 45000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 22    |
|    time_elapsed    | 4594  |
|    total_timesteps | 45056 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 46000    |
| train/                    |          |
|    explained_variance     | 0.904    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00518  |
|    learning_rate          | 0.001    |
|    n_updates              | 22       |
|    policy_objective       | 0.0531   |
|    value_loss             | 0.00156  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 47000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 23    |
|    time_elapsed    | 4798  |
|    total_timesteps | 47104 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 48000    |
| train/                    |          |
|    explained_variance     | 0.768    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00586  |
|    learning_rate          | 0.001    |
|    n_updates              | 23       |
|    policy_objective       | 0.0643   |
|    value_loss             | 0.00104  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 49000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 24    |
|    time_elapsed    | 5003  |
|    total_timesteps | 49152 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 50000    |
| train/                    |          |
|    explained_variance     | 0.858    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00583  |
|    learning_rate          | 0.001    |
|    n_updates              | 24       |
|    policy_objective       | 0.0551   |
|    value_loss             | 0.00306  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 51000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 25    |
|    time_elapsed    | 5207  |
|    total_timesteps | 51200 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 52000    |
| train/                    |          |
|    explained_variance     | 0.836    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0062   |
|    learning_rate          | 0.001    |
|    n_updates              | 25       |
|    policy_objective       | 0.0471   |
|    value_loss             | 0.00164  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 53000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 26    |
|    time_elapsed    | 5411  |
|    total_timesteps | 53248 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 54000    |
| train/                    |          |
|    explained_variance     | 0.86     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0048   |
|    learning_rate          | 0.001    |
|    n_updates              | 26       |
|    policy_objective       | 0.0512   |
|    value_loss             | 0.00178  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 55000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 27    |
|    time_elapsed    | 5616  |
|    total_timesteps | 55296 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 56000    |
| train/                    |          |
|    explained_variance     | 0.748    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00557  |
|    learning_rate          | 0.001    |
|    n_updates              | 27       |
|    policy_objective       | 0.0552   |
|    value_loss             | 0.00157  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 57000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 28    |
|    time_elapsed    | 5820  |
|    total_timesteps | 57344 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 58000    |
| train/                    |          |
|    explained_variance     | 0.846    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00414  |
|    learning_rate          | 0.001    |
|    n_updates              | 28       |
|    policy_objective       | 0.0674   |
|    value_loss             | 0.000734 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 59000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 29    |
|    time_elapsed    | 6024  |
|    total_timesteps | 59392 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 60000    |
| train/                    |          |
|    explained_variance     | 0.888    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00523  |
|    learning_rate          | 0.001    |
|    n_updates              | 29       |
|    policy_objective       | 0.07     |
|    value_loss             | 0.00114  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 61000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 30    |
|    time_elapsed    | 6229  |
|    total_timesteps | 61440 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 62000    |
| train/                    |          |
|    explained_variance     | 0.754    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00511  |
|    learning_rate          | 0.001    |
|    n_updates              | 30       |
|    policy_objective       | 0.0636   |
|    value_loss             | 0.00248  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 63000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 31    |
|    time_elapsed    | 6433  |
|    total_timesteps | 63488 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 64000    |
| train/                    |          |
|    explained_variance     | 0.778    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0042   |
|    learning_rate          | 0.001    |
|    n_updates              | 31       |
|    policy_objective       | 0.0543   |
|    value_loss             | 0.00162  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 65000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 32    |
|    time_elapsed    | 6637  |
|    total_timesteps | 65536 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 66000    |
| train/                    |          |
|    explained_variance     | 0.891    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0046   |
|    learning_rate          | 0.001    |
|    n_updates              | 32       |
|    policy_objective       | 0.0549   |
|    value_loss             | 0.00147  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 67000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 33    |
|    time_elapsed    | 6842  |
|    total_timesteps | 67584 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 68000    |
| train/                    |          |
|    explained_variance     | 0.832    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 33       |
|    policy_objective       | 0.0585   |
|    value_loss             | 0.00236  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 69000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 34    |
|    time_elapsed    | 7046  |
|    total_timesteps | 69632 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 70000    |
| train/                    |          |
|    explained_variance     | 0.823    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00589  |
|    learning_rate          | 0.001    |
|    n_updates              | 34       |
|    policy_objective       | 0.0575   |
|    value_loss             | 0.00123  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 71000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 35    |
|    time_elapsed    | 7250  |
|    total_timesteps | 71680 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 72000    |
| train/                    |          |
|    explained_variance     | 0.809    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00529  |
|    learning_rate          | 0.001    |
|    n_updates              | 35       |
|    policy_objective       | 0.0493   |
|    value_loss             | 0.00132  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 73000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 36    |
|    time_elapsed    | 7455  |
|    total_timesteps | 73728 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 74000    |
| train/                    |          |
|    explained_variance     | 0.703    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00458  |
|    learning_rate          | 0.001    |
|    n_updates              | 36       |
|    policy_objective       | 0.0601   |
|    value_loss             | 0.00104  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 75000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 37    |
|    time_elapsed    | 7659  |
|    total_timesteps | 75776 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 76000    |
| train/                    |          |
|    explained_variance     | 0.79     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00491  |
|    learning_rate          | 0.001    |
|    n_updates              | 37       |
|    policy_objective       | 0.0638   |
|    value_loss             | 0.000872 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 77000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 38    |
|    time_elapsed    | 7863  |
|    total_timesteps | 77824 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 78000    |
| train/                    |          |
|    explained_variance     | 0.705    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 38       |
|    policy_objective       | 0.0477   |
|    value_loss             | 0.000735 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 79000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 39    |
|    time_elapsed    | 8067  |
|    total_timesteps | 79872 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 80000    |
| train/                    |          |
|    explained_variance     | 0.863    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00486  |
|    learning_rate          | 0.001    |
|    n_updates              | 39       |
|    policy_objective       | 0.0521   |
|    value_loss             | 0.000739 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 81000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 40    |
|    time_elapsed    | 8272  |
|    total_timesteps | 81920 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 82000    |
| train/                    |          |
|    explained_variance     | 0.9      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00531  |
|    learning_rate          | 0.001    |
|    n_updates              | 40       |
|    policy_objective       | 0.0475   |
|    value_loss             | 0.00105  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 83000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 41    |
|    time_elapsed    | 8476  |
|    total_timesteps | 83968 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 84000    |
| train/                    |          |
|    explained_variance     | 0.607    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00469  |
|    learning_rate          | 0.001    |
|    n_updates              | 41       |
|    policy_objective       | 0.0549   |
|    value_loss             | 0.000774 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 85000    |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 86000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 42    |
|    time_elapsed    | 8780  |
|    total_timesteps | 86016 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 87000    |
| train/                    |          |
|    explained_variance     | 0.671    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00393  |
|    learning_rate          | 0.001    |
|    n_updates              | 42       |
|    policy_objective       | 0.0619   |
|    value_loss             | 0.00123  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 88000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 43    |
|    time_elapsed    | 8985  |
|    total_timesteps | 88064 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 89000    |
| train/                    |          |
|    explained_variance     | 0.786    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00485  |
|    learning_rate          | 0.001    |
|    n_updates              | 43       |
|    policy_objective       | 0.0602   |
|    value_loss             | 0.000416 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 90000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 44    |
|    time_elapsed    | 9189  |
|    total_timesteps | 90112 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 91000    |
| train/                    |          |
|    explained_variance     | 0.783    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00649  |
|    learning_rate          | 0.001    |
|    n_updates              | 44       |
|    policy_objective       | 0.0496   |
|    value_loss             | 0.00109  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 92000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 45    |
|    time_elapsed    | 9393  |
|    total_timesteps | 92160 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 93000    |
| train/                    |          |
|    explained_variance     | 0.89     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00494  |
|    learning_rate          | 0.001    |
|    n_updates              | 45       |
|    policy_objective       | 0.0526   |
|    value_loss             | 0.00104  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 94000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 46    |
|    time_elapsed    | 9598  |
|    total_timesteps | 94208 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 95000    |
| train/                    |          |
|    explained_variance     | 0.814    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00579  |
|    learning_rate          | 0.001    |
|    n_updates              | 46       |
|    policy_objective       | 0.0498   |
|    value_loss             | 0.00118  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 96000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 47    |
|    time_elapsed    | 9802  |
|    total_timesteps | 96256 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 97000    |
| train/                    |          |
|    explained_variance     | 0.857    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00441  |
|    learning_rate          | 0.001    |
|    n_updates              | 47       |
|    policy_objective       | 0.0666   |
|    value_loss             | 0.00111  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 98000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 48    |
|    time_elapsed    | 10006 |
|    total_timesteps | 98304 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 99000    |
| train/                    |          |
|    explained_variance     | 0.909    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00651  |
|    learning_rate          | 0.001    |
|    n_updates              | 48       |
|    policy_objective       | 0.0451   |
|    value_loss             | 0.00119  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 100000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 49     |
|    time_elapsed    | 10211  |
|    total_timesteps | 100352 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 101000   |
| train/                    |          |
|    explained_variance     | 0.815    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00499  |
|    learning_rate          | 0.001    |
|    n_updates              | 49       |
|    policy_objective       | 0.0565   |
|    value_loss             | 0.000725 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 102000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 50     |
|    time_elapsed    | 10415  |
|    total_timesteps | 102400 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 103000   |
| train/                    |          |
|    explained_variance     | 0.842    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00567  |
|    learning_rate          | 0.001    |
|    n_updates              | 50       |
|    policy_objective       | 0.0529   |
|    value_loss             | 0.00138  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 104000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 51     |
|    time_elapsed    | 10619  |
|    total_timesteps | 104448 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 105000   |
| train/                    |          |
|    explained_variance     | 0.886    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00535  |
|    learning_rate          | 0.001    |
|    n_updates              | 51       |
|    policy_objective       | 0.0636   |
|    value_loss             | 0.000899 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 106000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 52     |
|    time_elapsed    | 10824  |
|    total_timesteps | 106496 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 107000   |
| train/                    |          |
|    explained_variance     | 0.907    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00493  |
|    learning_rate          | 0.001    |
|    n_updates              | 52       |
|    policy_objective       | 0.0579   |
|    value_loss             | 0.000594 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 108000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 53     |
|    time_elapsed    | 11028  |
|    total_timesteps | 108544 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 109000   |
| train/                    |          |
|    explained_variance     | 0.762    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00478  |
|    learning_rate          | 0.001    |
|    n_updates              | 53       |
|    policy_objective       | 0.0468   |
|    value_loss             | 0.00116  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 110000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 54     |
|    time_elapsed    | 11232  |
|    total_timesteps | 110592 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 111000   |
| train/                    |          |
|    explained_variance     | 0.855    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00477  |
|    learning_rate          | 0.001    |
|    n_updates              | 54       |
|    policy_objective       | 0.05     |
|    value_loss             | 0.00091  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 112000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 55     |
|    time_elapsed    | 11437  |
|    total_timesteps | 112640 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 113000   |
| train/                    |          |
|    explained_variance     | 0.751    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00452  |
|    learning_rate          | 0.001    |
|    n_updates              | 55       |
|    policy_objective       | 0.0583   |
|    value_loss             | 0.000667 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 114000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 56     |
|    time_elapsed    | 11641  |
|    total_timesteps | 114688 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 115000   |
| train/                    |          |
|    explained_variance     | 0.803    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00448  |
|    learning_rate          | 0.001    |
|    n_updates              | 56       |
|    policy_objective       | 0.0695   |
|    value_loss             | 0.000817 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 116000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 57     |
|    time_elapsed    | 11845  |
|    total_timesteps | 116736 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 117000   |
| train/                    |          |
|    explained_variance     | 0.866    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00629  |
|    learning_rate          | 0.001    |
|    n_updates              | 57       |
|    policy_objective       | 0.0502   |
|    value_loss             | 0.000692 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 118000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 58     |
|    time_elapsed    | 12050  |
|    total_timesteps | 118784 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 119000   |
| train/                    |          |
|    explained_variance     | 0.747    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00493  |
|    learning_rate          | 0.001    |
|    n_updates              | 58       |
|    policy_objective       | 0.061    |
|    value_loss             | 0.00104  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 120000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 59     |
|    time_elapsed    | 12254  |
|    total_timesteps | 120832 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 121000   |
| train/                    |          |
|    explained_variance     | 0.603    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00498  |
|    learning_rate          | 0.001    |
|    n_updates              | 59       |
|    policy_objective       | 0.0565   |
|    value_loss             | 0.000773 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 122000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 60     |
|    time_elapsed    | 12458  |
|    total_timesteps | 122880 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 123000   |
| train/                    |          |
|    explained_variance     | 0.615    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00494  |
|    learning_rate          | 0.001    |
|    n_updates              | 60       |
|    policy_objective       | 0.0614   |
|    value_loss             | 0.00215  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 124000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 61     |
|    time_elapsed    | 12663  |
|    total_timesteps | 124928 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 125000   |
| train/                    |          |
|    explained_variance     | 0.834    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0052   |
|    learning_rate          | 0.001    |
|    n_updates              | 61       |
|    policy_objective       | 0.0688   |
|    value_loss             | 0.000689 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 126000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 62     |
|    time_elapsed    | 12867  |
|    total_timesteps | 126976 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 127000   |
| train/                    |          |
|    explained_variance     | 0.773    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00458  |
|    learning_rate          | 0.001    |
|    n_updates              | 62       |
|    policy_objective       | 0.064    |
|    value_loss             | 0.00044  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 128000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 129000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 63     |
|    time_elapsed    | 13171  |
|    total_timesteps | 129024 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 130000   |
| train/                    |          |
|    explained_variance     | 0.894    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00562  |
|    learning_rate          | 0.001    |
|    n_updates              | 63       |
|    policy_objective       | 0.053    |
|    value_loss             | 0.000604 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 131000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 64     |
|    time_elapsed    | 13376  |
|    total_timesteps | 131072 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 132000   |
| train/                    |          |
|    explained_variance     | 0.865    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00663  |
|    learning_rate          | 0.001    |
|    n_updates              | 64       |
|    policy_objective       | 0.0525   |
|    value_loss             | 0.000998 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 133000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 65     |
|    time_elapsed    | 13580  |
|    total_timesteps | 133120 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 134000   |
| train/                    |          |
|    explained_variance     | 0.633    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00542  |
|    learning_rate          | 0.001    |
|    n_updates              | 65       |
|    policy_objective       | 0.0604   |
|    value_loss             | 0.00104  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 135000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 66     |
|    time_elapsed    | 13784  |
|    total_timesteps | 135168 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 136000   |
| train/                    |          |
|    explained_variance     | 0.831    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00593  |
|    learning_rate          | 0.001    |
|    n_updates              | 66       |
|    policy_objective       | 0.0485   |
|    value_loss             | 0.000905 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 137000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 67     |
|    time_elapsed    | 13988  |
|    total_timesteps | 137216 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 138000   |
| train/                    |          |
|    explained_variance     | 0.791    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00609  |
|    learning_rate          | 0.001    |
|    n_updates              | 67       |
|    policy_objective       | 0.0526   |
|    value_loss             | 0.000524 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 139000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 68     |
|    time_elapsed    | 14193  |
|    total_timesteps | 139264 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 140000   |
| train/                    |          |
|    explained_variance     | 0.749    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00447  |
|    learning_rate          | 0.001    |
|    n_updates              | 68       |
|    policy_objective       | 0.0792   |
|    value_loss             | 0.000347 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 141000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 69     |
|    time_elapsed    | 14397  |
|    total_timesteps | 141312 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 142000   |
| train/                    |          |
|    explained_variance     | 0.864    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00493  |
|    learning_rate          | 0.001    |
|    n_updates              | 69       |
|    policy_objective       | 0.0637   |
|    value_loss             | 0.000745 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 143000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 70     |
|    time_elapsed    | 14601  |
|    total_timesteps | 143360 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 144000   |
| train/                    |          |
|    explained_variance     | 0.794    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00488  |
|    learning_rate          | 0.001    |
|    n_updates              | 70       |
|    policy_objective       | 0.0579   |
|    value_loss             | 0.000941 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 145000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 71     |
|    time_elapsed    | 14806  |
|    total_timesteps | 145408 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 146000   |
| train/                    |          |
|    explained_variance     | 0.705    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.001    |
|    n_updates              | 71       |
|    policy_objective       | 0.0558   |
|    value_loss             | 0.000715 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 147000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 72     |
|    time_elapsed    | 15010  |
|    total_timesteps | 147456 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 148000   |
| train/                    |          |
|    explained_variance     | 0.848    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00572  |
|    learning_rate          | 0.001    |
|    n_updates              | 72       |
|    policy_objective       | 0.0575   |
|    value_loss             | 0.000761 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 149000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 73     |
|    time_elapsed    | 15214  |
|    total_timesteps | 149504 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 150000   |
| train/                    |          |
|    explained_variance     | 0.798    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00556  |
|    learning_rate          | 0.001    |
|    n_updates              | 73       |
|    policy_objective       | 0.0513   |
|    value_loss             | 0.00106  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 151000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 74     |
|    time_elapsed    | 15419  |
|    total_timesteps | 151552 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 152000   |
| train/                    |          |
|    explained_variance     | 0.822    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.001    |
|    n_updates              | 74       |
|    policy_objective       | 0.0545   |
|    value_loss             | 0.000638 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 153000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 75     |
|    time_elapsed    | 15623  |
|    total_timesteps | 153600 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 154000   |
| train/                    |          |
|    explained_variance     | 0.577    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00592  |
|    learning_rate          | 0.001    |
|    n_updates              | 75       |
|    policy_objective       | 0.0596   |
|    value_loss             | 0.000685 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 155000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 76     |
|    time_elapsed    | 15827  |
|    total_timesteps | 155648 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 156000   |
| train/                    |          |
|    explained_variance     | 0.491    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00516  |
|    learning_rate          | 0.001    |
|    n_updates              | 76       |
|    policy_objective       | 0.0577   |
|    value_loss             | 0.000531 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 157000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 77     |
|    time_elapsed    | 16032  |
|    total_timesteps | 157696 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 158000   |
| train/                    |          |
|    explained_variance     | 0.838    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00505  |
|    learning_rate          | 0.001    |
|    n_updates              | 77       |
|    policy_objective       | 0.0522   |
|    value_loss             | 0.000771 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 159000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 78     |
|    time_elapsed    | 16236  |
|    total_timesteps | 159744 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 160000   |
| train/                    |          |
|    explained_variance     | 0.726    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.006    |
|    learning_rate          | 0.001    |
|    n_updates              | 78       |
|    policy_objective       | 0.0515   |
|    value_loss             | 0.000829 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 161000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 79     |
|    time_elapsed    | 16440  |
|    total_timesteps | 161792 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 162000   |
| train/                    |          |
|    explained_variance     | 0.792    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00528  |
|    learning_rate          | 0.001    |
|    n_updates              | 79       |
|    policy_objective       | 0.0583   |
|    value_loss             | 0.00106  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 163000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 80     |
|    time_elapsed    | 16645  |
|    total_timesteps | 163840 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 164000   |
| train/                    |          |
|    explained_variance     | 0.597    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00522  |
|    learning_rate          | 0.001    |
|    n_updates              | 80       |
|    policy_objective       | 0.0655   |
|    value_loss             | 0.00056  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 165000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 81     |
|    time_elapsed    | 16849  |
|    total_timesteps | 165888 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 166000   |
| train/                    |          |
|    explained_variance     | 0.555    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00518  |
|    learning_rate          | 0.001    |
|    n_updates              | 81       |
|    policy_objective       | 0.0648   |
|    value_loss             | 0.000994 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 167000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 82     |
|    time_elapsed    | 17053  |
|    total_timesteps | 167936 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 168000   |
| train/                    |          |
|    explained_variance     | 0.924    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00718  |
|    learning_rate          | 0.001    |
|    n_updates              | 82       |
|    policy_objective       | 0.0439   |
|    value_loss             | 0.00174  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 169000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 83     |
|    time_elapsed    | 17258  |
|    total_timesteps | 169984 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 170000   |
| train/                    |          |
|    explained_variance     | 0.617    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00495  |
|    learning_rate          | 0.001    |
|    n_updates              | 83       |
|    policy_objective       | 0.0584   |
|    value_loss             | 0.000761 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 171000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 172000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 84     |
|    time_elapsed    | 17562  |
|    total_timesteps | 172032 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 173000   |
| train/                    |          |
|    explained_variance     | 0.864    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00604  |
|    learning_rate          | 0.001    |
|    n_updates              | 84       |
|    policy_objective       | 0.0522   |
|    value_loss             | 0.00147  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 174000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 85     |
|    time_elapsed    | 17766  |
|    total_timesteps | 174080 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 175000   |
| train/                    |          |
|    explained_variance     | 0.683    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00601  |
|    learning_rate          | 0.001    |
|    n_updates              | 85       |
|    policy_objective       | 0.0523   |
|    value_loss             | 0.000753 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 176000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 86     |
|    time_elapsed    | 17971  |
|    total_timesteps | 176128 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 177000   |
| train/                    |          |
|    explained_variance     | 0.684    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00571  |
|    learning_rate          | 0.001    |
|    n_updates              | 86       |
|    policy_objective       | 0.0538   |
|    value_loss             | 0.000855 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 178000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 87     |
|    time_elapsed    | 18175  |
|    total_timesteps | 178176 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 179000   |
| train/                    |          |
|    explained_variance     | 0.67     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.005    |
|    learning_rate          | 0.001    |
|    n_updates              | 87       |
|    policy_objective       | 0.0558   |
|    value_loss             | 0.00154  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 180000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 88     |
|    time_elapsed    | 18379  |
|    total_timesteps | 180224 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 181000   |
| train/                    |          |
|    explained_variance     | 0.847    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00524  |
|    learning_rate          | 0.001    |
|    n_updates              | 88       |
|    policy_objective       | 0.0489   |
|    value_loss             | 0.00067  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 182000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 89     |
|    time_elapsed    | 18584  |
|    total_timesteps | 182272 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 183000   |
| train/                    |          |
|    explained_variance     | 0.658    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00578  |
|    learning_rate          | 0.001    |
|    n_updates              | 89       |
|    policy_objective       | 0.0593   |
|    value_loss             | 0.00121  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 184000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 90     |
|    time_elapsed    | 18788  |
|    total_timesteps | 184320 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 185000   |
| train/                    |          |
|    explained_variance     | 0.758    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 90       |
|    policy_objective       | 0.0564   |
|    value_loss             | 0.000978 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 186000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 91     |
|    time_elapsed    | 18992  |
|    total_timesteps | 186368 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 187000   |
| train/                    |          |
|    explained_variance     | 0.627    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00594  |
|    learning_rate          | 0.001    |
|    n_updates              | 91       |
|    policy_objective       | 0.0603   |
|    value_loss             | 0.00088  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 188000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 92     |
|    time_elapsed    | 19197  |
|    total_timesteps | 188416 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 189000   |
| train/                    |          |
|    explained_variance     | 0.519    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00385  |
|    learning_rate          | 0.001    |
|    n_updates              | 92       |
|    policy_objective       | 0.0581   |
|    value_loss             | 0.000786 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 190000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 93     |
|    time_elapsed    | 19401  |
|    total_timesteps | 190464 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 191000   |
| train/                    |          |
|    explained_variance     | 0.566    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00476  |
|    learning_rate          | 0.001    |
|    n_updates              | 93       |
|    policy_objective       | 0.0626   |
|    value_loss             | 0.000672 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 192000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 94     |
|    time_elapsed    | 19605  |
|    total_timesteps | 192512 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 193000   |
| train/                    |          |
|    explained_variance     | 0.784    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00505  |
|    learning_rate          | 0.001    |
|    n_updates              | 94       |
|    policy_objective       | 0.0483   |
|    value_loss             | 0.000701 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 194000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 95     |
|    time_elapsed    | 19810  |
|    total_timesteps | 194560 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 195000   |
| train/                    |          |
|    explained_variance     | 0.787    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00599  |
|    learning_rate          | 0.001    |
|    n_updates              | 95       |
|    policy_objective       | 0.0504   |
|    value_loss             | 0.000698 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 196000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 96     |
|    time_elapsed    | 20014  |
|    total_timesteps | 196608 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 197000   |
| train/                    |          |
|    explained_variance     | 0.692    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0052   |
|    learning_rate          | 0.001    |
|    n_updates              | 96       |
|    policy_objective       | 0.0552   |
|    value_loss             | 0.00105  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 198000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 97     |
|    time_elapsed    | 20219  |
|    total_timesteps | 198656 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 199000   |
| train/                    |          |
|    explained_variance     | 0.768    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00596  |
|    learning_rate          | 0.001    |
|    n_updates              | 97       |
|    policy_objective       | 0.0544   |
|    value_loss             | 0.00099  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 200000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 98     |
|    time_elapsed    | 20423  |
|    total_timesteps | 200704 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 201000   |
| train/                    |          |
|    explained_variance     | 0.885    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00511  |
|    learning_rate          | 0.001    |
|    n_updates              | 98       |
|    policy_objective       | 0.0547   |
|    value_loss             | 0.00057  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 202000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 99     |
|    time_elapsed    | 20627  |
|    total_timesteps | 202752 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 203000   |
| train/                    |          |
|    explained_variance     | 0.789    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00625  |
|    learning_rate          | 0.001    |
|    n_updates              | 99       |
|    policy_objective       | 0.0541   |
|    value_loss             | 0.000971 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 204000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 100    |
|    time_elapsed    | 20831  |
|    total_timesteps | 204800 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 205000   |
| train/                    |          |
|    explained_variance     | 0.68     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00505  |
|    learning_rate          | 0.001    |
|    n_updates              | 100      |
|    policy_objective       | 0.051    |
|    value_loss             | 0.0011   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 206000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 101    |
|    time_elapsed    | 21036  |
|    total_timesteps | 206848 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 207000   |
| train/                    |          |
|    explained_variance     | 0.709    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00461  |
|    learning_rate          | 0.001    |
|    n_updates              | 101      |
|    policy_objective       | 0.0594   |
|    value_loss             | 0.000733 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 208000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 102    |
|    time_elapsed    | 21240  |
|    total_timesteps | 208896 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 209000   |
| train/                    |          |
|    explained_variance     | 0.744    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00523  |
|    learning_rate          | 0.001    |
|    n_updates              | 102      |
|    policy_objective       | 0.0627   |
|    value_loss             | 0.00118  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 210000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 103    |
|    time_elapsed    | 21444  |
|    total_timesteps | 210944 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 211000   |
| train/                    |          |
|    explained_variance     | 0.326    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00525  |
|    learning_rate          | 0.001    |
|    n_updates              | 103      |
|    policy_objective       | 0.0573   |
|    value_loss             | 0.000674 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 212000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 104    |
|    time_elapsed    | 21649  |
|    total_timesteps | 212992 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 213000   |
| train/                    |          |
|    explained_variance     | 0.765    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00456  |
|    learning_rate          | 0.001    |
|    n_updates              | 104      |
|    policy_objective       | 0.0664   |
|    value_loss             | 0.000507 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 214000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 215000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 105    |
|    time_elapsed    | 21953  |
|    total_timesteps | 215040 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 216000   |
| train/                    |          |
|    explained_variance     | 0.41     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00285  |
|    learning_rate          | 0.001    |
|    n_updates              | 105      |
|    policy_objective       | 0.112    |
|    value_loss             | 0.000849 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 217000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 106    |
|    time_elapsed    | 22157  |
|    total_timesteps | 217088 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 218000   |
| train/                    |          |
|    explained_variance     | 0.511    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00463  |
|    learning_rate          | 0.001    |
|    n_updates              | 106      |
|    policy_objective       | 0.0541   |
|    value_loss             | 0.000678 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 219000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 107    |
|    time_elapsed    | 22362  |
|    total_timesteps | 219136 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 220000   |
| train/                    |          |
|    explained_variance     | 0.671    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00447  |
|    learning_rate          | 0.001    |
|    n_updates              | 107      |
|    policy_objective       | 0.0618   |
|    value_loss             | 0.000779 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 221000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 108    |
|    time_elapsed    | 22566  |
|    total_timesteps | 221184 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 222000   |
| train/                    |          |
|    explained_variance     | 0.545    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00501  |
|    learning_rate          | 0.001    |
|    n_updates              | 108      |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.000558 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 223000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 109    |
|    time_elapsed    | 22770  |
|    total_timesteps | 223232 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 224000   |
| train/                    |          |
|    explained_variance     | 0.699    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00587  |
|    learning_rate          | 0.001    |
|    n_updates              | 109      |
|    policy_objective       | 0.0562   |
|    value_loss             | 0.000632 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 225000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 110    |
|    time_elapsed    | 22975  |
|    total_timesteps | 225280 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 226000   |
| train/                    |          |
|    explained_variance     | 0.665    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00505  |
|    learning_rate          | 0.001    |
|    n_updates              | 110      |
|    policy_objective       | 0.0656   |
|    value_loss             | 0.000975 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 227000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 111    |
|    time_elapsed    | 23179  |
|    total_timesteps | 227328 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 228000   |
| train/                    |          |
|    explained_variance     | 0.486    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 111      |
|    policy_objective       | 0.0692   |
|    value_loss             | 0.000674 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 229000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 112    |
|    time_elapsed    | 23383  |
|    total_timesteps | 229376 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 230000   |
| train/                    |          |
|    explained_variance     | 0.751    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00518  |
|    learning_rate          | 0.001    |
|    n_updates              | 112      |
|    policy_objective       | 0.0603   |
|    value_loss             | 0.00091  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 231000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 113    |
|    time_elapsed    | 23588  |
|    total_timesteps | 231424 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 232000   |
| train/                    |          |
|    explained_variance     | 0.547    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00487  |
|    learning_rate          | 0.001    |
|    n_updates              | 113      |
|    policy_objective       | 0.0696   |
|    value_loss             | 0.000758 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 233000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 114    |
|    time_elapsed    | 23792  |
|    total_timesteps | 233472 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 234000   |
| train/                    |          |
|    explained_variance     | 0.521    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00509  |
|    learning_rate          | 0.001    |
|    n_updates              | 114      |
|    policy_objective       | 0.0542   |
|    value_loss             | 0.000876 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 235000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 115    |
|    time_elapsed    | 23997  |
|    total_timesteps | 235520 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 236000   |
| train/                    |          |
|    explained_variance     | 0.685    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00423  |
|    learning_rate          | 0.001    |
|    n_updates              | 115      |
|    policy_objective       | 0.0695   |
|    value_loss             | 0.00087  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 237000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 116    |
|    time_elapsed    | 24201  |
|    total_timesteps | 237568 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 238000   |
| train/                    |          |
|    explained_variance     | 0.61     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00497  |
|    learning_rate          | 0.001    |
|    n_updates              | 116      |
|    policy_objective       | 0.0558   |
|    value_loss             | 0.00133  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 239000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 117    |
|    time_elapsed    | 24405  |
|    total_timesteps | 239616 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 240000   |
| train/                    |          |
|    explained_variance     | 0.806    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00616  |
|    learning_rate          | 0.001    |
|    n_updates              | 117      |
|    policy_objective       | 0.0512   |
|    value_loss             | 0.000797 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 241000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 118    |
|    time_elapsed    | 24610  |
|    total_timesteps | 241664 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 242000   |
| train/                    |          |
|    explained_variance     | 0.419    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00591  |
|    learning_rate          | 0.001    |
|    n_updates              | 118      |
|    policy_objective       | 0.062    |
|    value_loss             | 0.000909 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 243000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 119    |
|    time_elapsed    | 24814  |
|    total_timesteps | 243712 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 244000   |
| train/                    |          |
|    explained_variance     | 0.804    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00731  |
|    learning_rate          | 0.001    |
|    n_updates              | 119      |
|    policy_objective       | 0.0556   |
|    value_loss             | 0.00154  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 245000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 120    |
|    time_elapsed    | 25018  |
|    total_timesteps | 245760 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 246000   |
| train/                    |          |
|    explained_variance     | 0.705    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00594  |
|    learning_rate          | 0.001    |
|    n_updates              | 120      |
|    policy_objective       | 0.0701   |
|    value_loss             | 0.00112  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 247000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 121    |
|    time_elapsed    | 25223  |
|    total_timesteps | 247808 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 248000   |
| train/                    |          |
|    explained_variance     | 0.634    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 121      |
|    policy_objective       | 0.0615   |
|    value_loss             | 0.00146  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 249000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 122    |
|    time_elapsed    | 25427  |
|    total_timesteps | 249856 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 250000   |
| train/                    |          |
|    explained_variance     | 0.628    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00546  |
|    learning_rate          | 0.001    |
|    n_updates              | 122      |
|    policy_objective       | 0.0547   |
|    value_loss             | 0.00134  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 251000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 123    |
|    time_elapsed    | 25631  |
|    total_timesteps | 251904 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 252000   |
| train/                    |          |
|    explained_variance     | 0.84     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00547  |
|    learning_rate          | 0.001    |
|    n_updates              | 123      |
|    policy_objective       | 0.0621   |
|    value_loss             | 0.00109  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 253000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 124    |
|    time_elapsed    | 25836  |
|    total_timesteps | 253952 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 254000   |
| train/                    |          |
|    explained_variance     | 0.407    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00504  |
|    learning_rate          | 0.001    |
|    n_updates              | 124      |
|    policy_objective       | 0.0753   |
|    value_loss             | 0.00131  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 255000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 256000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 125    |
|    time_elapsed    | 26140  |
|    total_timesteps | 256000 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 257000   |
| train/                    |          |
|    explained_variance     | 0.503    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00472  |
|    learning_rate          | 0.001    |
|    n_updates              | 125      |
|    policy_objective       | 0.0581   |
|    value_loss             | 0.000799 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 258000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 126    |
|    time_elapsed    | 26344  |
|    total_timesteps | 258048 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 259000   |
| train/                    |          |
|    explained_variance     | 0.661    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00459  |
|    learning_rate          | 0.001    |
|    n_updates              | 126      |
|    policy_objective       | 0.0653   |
|    value_loss             | 0.000875 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 260000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 127    |
|    time_elapsed    | 26549  |
|    total_timesteps | 260096 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 261000   |
| train/                    |          |
|    explained_variance     | 0.545    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00509  |
|    learning_rate          | 0.001    |
|    n_updates              | 127      |
|    policy_objective       | 0.0575   |
|    value_loss             | 0.000998 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 262000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 128    |
|    time_elapsed    | 26753  |
|    total_timesteps | 262144 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 263000   |
| train/                    |          |
|    explained_variance     | 0.497    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00482  |
|    learning_rate          | 0.001    |
|    n_updates              | 128      |
|    policy_objective       | 0.0575   |
|    value_loss             | 0.00143  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 264000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 129    |
|    time_elapsed    | 26957  |
|    total_timesteps | 264192 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 265000   |
| train/                    |          |
|    explained_variance     | 0.495    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00553  |
|    learning_rate          | 0.001    |
|    n_updates              | 129      |
|    policy_objective       | 0.0544   |
|    value_loss             | 0.00104  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 266000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 130    |
|    time_elapsed    | 27162  |
|    total_timesteps | 266240 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 267000   |
| train/                    |          |
|    explained_variance     | 0.504    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00527  |
|    learning_rate          | 0.001    |
|    n_updates              | 130      |
|    policy_objective       | 0.0669   |
|    value_loss             | 0.00106  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 268000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 131    |
|    time_elapsed    | 27366  |
|    total_timesteps | 268288 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 269000   |
| train/                    |          |
|    explained_variance     | 0.398    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00528  |
|    learning_rate          | 0.001    |
|    n_updates              | 131      |
|    policy_objective       | 0.054    |
|    value_loss             | 0.00116  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 270000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 132    |
|    time_elapsed    | 27570  |
|    total_timesteps | 270336 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 271000   |
| train/                    |          |
|    explained_variance     | 0.447    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00501  |
|    learning_rate          | 0.001    |
|    n_updates              | 132      |
|    policy_objective       | 0.0711   |
|    value_loss             | 0.000838 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 272000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 133    |
|    time_elapsed    | 27775  |
|    total_timesteps | 272384 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 273000   |
| train/                    |          |
|    explained_variance     | 0.533    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00532  |
|    learning_rate          | 0.001    |
|    n_updates              | 133      |
|    policy_objective       | 0.0589   |
|    value_loss             | 0.00112  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 274000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 134    |
|    time_elapsed    | 27979  |
|    total_timesteps | 274432 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 275000   |
| train/                    |          |
|    explained_variance     | 0.615    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00551  |
|    learning_rate          | 0.001    |
|    n_updates              | 134      |
|    policy_objective       | 0.0547   |
|    value_loss             | 0.00123  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 276000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 135    |
|    time_elapsed    | 28183  |
|    total_timesteps | 276480 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 277000   |
| train/                    |          |
|    explained_variance     | 0.65     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00469  |
|    learning_rate          | 0.001    |
|    n_updates              | 135      |
|    policy_objective       | 0.0518   |
|    value_loss             | 0.00119  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 278000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 136    |
|    time_elapsed    | 28388  |
|    total_timesteps | 278528 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.6      |
| time/                     |          |
|    total_timesteps        | 279000   |
| train/                    |          |
|    explained_variance     | 0.743    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00534  |
|    learning_rate          | 0.001    |
|    n_updates              | 136      |
|    policy_objective       | 0.0598   |
|    value_loss             | 0.00107  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 280000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 137    |
|    time_elapsed    | 28592  |
|    total_timesteps | 280576 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 281000   |
| train/                    |          |
|    explained_variance     | 0.545    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00528  |
|    learning_rate          | 0.001    |
|    n_updates              | 137      |
|    policy_objective       | 0.0612   |
|    value_loss             | 0.00141  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 282000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 138    |
|    time_elapsed    | 28796  |
|    total_timesteps | 282624 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.6      |
| time/                     |          |
|    total_timesteps        | 283000   |
| train/                    |          |
|    explained_variance     | 0.677    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00516  |
|    learning_rate          | 0.001    |
|    n_updates              | 138      |
|    policy_objective       | 0.0592   |
|    value_loss             | 0.0011   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 284000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 139    |
|    time_elapsed    | 29001  |
|    total_timesteps | 284672 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 285000   |
| train/                    |          |
|    explained_variance     | 0.613    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0058   |
|    learning_rate          | 0.001    |
|    n_updates              | 139      |
|    policy_objective       | 0.0559   |
|    value_loss             | 0.00161  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 286000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 140    |
|    time_elapsed    | 29205  |
|    total_timesteps | 286720 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 287000   |
| train/                    |          |
|    explained_variance     | 0.374    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00392  |
|    learning_rate          | 0.001    |
|    n_updates              | 140      |
|    policy_objective       | 0.0672   |
|    value_loss             | 0.00113  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 288000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 141    |
|    time_elapsed    | 29409  |
|    total_timesteps | 288768 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 289000   |
| train/                    |          |
|    explained_variance     | 0.677    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00614  |
|    learning_rate          | 0.001    |
|    n_updates              | 141      |
|    policy_objective       | 0.0795   |
|    value_loss             | 0.00101  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 290000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 142    |
|    time_elapsed    | 29614  |
|    total_timesteps | 290816 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 291000   |
| train/                    |          |
|    explained_variance     | 0.576    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00576  |
|    learning_rate          | 0.001    |
|    n_updates              | 142      |
|    policy_objective       | 0.0575   |
|    value_loss             | 0.00159  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 292000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 143    |
|    time_elapsed    | 29818  |
|    total_timesteps | 292864 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 293000   |
| train/                    |          |
|    explained_variance     | 0.53     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00482  |
|    learning_rate          | 0.001    |
|    n_updates              | 143      |
|    policy_objective       | 0.0603   |
|    value_loss             | 0.00137  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 294000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 144    |
|    time_elapsed    | 30022  |
|    total_timesteps | 294912 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.6      |
| time/                     |          |
|    total_timesteps        | 295000   |
| train/                    |          |
|    explained_variance     | 0.619    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00631  |
|    learning_rate          | 0.001    |
|    n_updates              | 144      |
|    policy_objective       | 0.0679   |
|    value_loss             | 0.00125  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 296000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 145    |
|    time_elapsed    | 30227  |
|    total_timesteps | 296960 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.6      |
| time/                     |          |
|    total_timesteps        | 297000   |
| train/                    |          |
|    explained_variance     | 0.449    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00473  |
|    learning_rate          | 0.001    |
|    n_updates              | 145      |
|    policy_objective       | 0.0499   |
|    value_loss             | 0.00154  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 298000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 299000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 146    |
|    time_elapsed    | 30531  |
|    total_timesteps | 299008 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 300000   |
| train/                    |          |
|    explained_variance     | 0.451    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00523  |
|    learning_rate          | 0.001    |
|    n_updates              | 146      |
|    policy_objective       | 0.053    |
|    value_loss             | 0.00229  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 301000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 147    |
|    time_elapsed    | 30735  |
|    total_timesteps | 301056 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 302000   |
| train/                    |          |
|    explained_variance     | 0.48     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00543  |
|    learning_rate          | 0.001    |
|    n_updates              | 147      |
|    policy_objective       | 0.0506   |
|    value_loss             | 0.00155  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 303000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 148    |
|    time_elapsed    | 30940  |
|    total_timesteps | 303104 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 304000   |
| train/                    |          |
|    explained_variance     | 0.513    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00552  |
|    learning_rate          | 0.001    |
|    n_updates              | 148      |
|    policy_objective       | 0.0555   |
|    value_loss             | 0.00137  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 305000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 149    |
|    time_elapsed    | 31144  |
|    total_timesteps | 305152 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 306000   |
| train/                    |          |
|    explained_variance     | 0.586    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00555  |
|    learning_rate          | 0.001    |
|    n_updates              | 149      |
|    policy_objective       | 0.0659   |
|    value_loss             | 0.00112  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 307000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 150    |
|    time_elapsed    | 31349  |
|    total_timesteps | 307200 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 308000   |
| train/                    |          |
|    explained_variance     | 0.607    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00611  |
|    learning_rate          | 0.001    |
|    n_updates              | 150      |
|    policy_objective       | 0.0504   |
|    value_loss             | 0.00148  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 309000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 151    |
|    time_elapsed    | 31553  |
|    total_timesteps | 309248 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 310000   |
| train/                    |          |
|    explained_variance     | 0.468    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.005    |
|    learning_rate          | 0.001    |
|    n_updates              | 151      |
|    policy_objective       | 0.0628   |
|    value_loss             | 0.00159  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 311000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 152    |
|    time_elapsed    | 31757  |
|    total_timesteps | 311296 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 312000   |
| train/                    |          |
|    explained_variance     | 0.55     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00498  |
|    learning_rate          | 0.001    |
|    n_updates              | 152      |
|    policy_objective       | 0.0521   |
|    value_loss             | 0.00106  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 313000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 153    |
|    time_elapsed    | 31961  |
|    total_timesteps | 313344 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 314000   |
| train/                    |          |
|    explained_variance     | 0.559    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00611  |
|    learning_rate          | 0.001    |
|    n_updates              | 153      |
|    policy_objective       | 0.0622   |
|    value_loss             | 0.00163  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 315000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 154    |
|    time_elapsed    | 32166  |
|    total_timesteps | 315392 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 316000   |
| train/                    |          |
|    explained_variance     | 0.508    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00498  |
|    learning_rate          | 0.001    |
|    n_updates              | 154      |
|    policy_objective       | 0.0659   |
|    value_loss             | 0.00133  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 317000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 155    |
|    time_elapsed    | 32370  |
|    total_timesteps | 317440 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 318000   |
| train/                    |          |
|    explained_variance     | 0.648    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00545  |
|    learning_rate          | 0.001    |
|    n_updates              | 155      |
|    policy_objective       | 0.0506   |
|    value_loss             | 0.00154  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 319000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 156    |
|    time_elapsed    | 32574  |
|    total_timesteps | 319488 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.6      |
| time/                     |          |
|    total_timesteps        | 320000   |
| train/                    |          |
|    explained_variance     | 0.383    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00512  |
|    learning_rate          | 0.001    |
|    n_updates              | 156      |
|    policy_objective       | 0.0559   |
|    value_loss             | 0.00161  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 321000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 157    |
|    time_elapsed    | 32779  |
|    total_timesteps | 321536 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.6      |
| time/                     |          |
|    total_timesteps        | 322000   |
| train/                    |          |
|    explained_variance     | 0.48     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00577  |
|    learning_rate          | 0.001    |
|    n_updates              | 157      |
|    policy_objective       | 0.0561   |
|    value_loss             | 0.0015   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 323000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 158    |
|    time_elapsed    | 32983  |
|    total_timesteps | 323584 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 324000   |
| train/                    |          |
|    explained_variance     | 0.531    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00622  |
|    learning_rate          | 0.001    |
|    n_updates              | 158      |
|    policy_objective       | 0.0553   |
|    value_loss             | 0.00202  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 325000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 159    |
|    time_elapsed    | 33187  |
|    total_timesteps | 325632 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 326000   |
| train/                    |          |
|    explained_variance     | 0.569    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00591  |
|    learning_rate          | 0.001    |
|    n_updates              | 159      |
|    policy_objective       | 0.0606   |
|    value_loss             | 0.00174  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 327000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 160    |
|    time_elapsed    | 33392  |
|    total_timesteps | 327680 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 328000   |
| train/                    |          |
|    explained_variance     | 0.564    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00614  |
|    learning_rate          | 0.001    |
|    n_updates              | 160      |
|    policy_objective       | 0.0505   |
|    value_loss             | 0.00201  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 329000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 161    |
|    time_elapsed    | 33596  |
|    total_timesteps | 329728 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 330000   |
| train/                    |          |
|    explained_variance     | 0.524    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00653  |
|    learning_rate          | 0.001    |
|    n_updates              | 161      |
|    policy_objective       | 0.0546   |
|    value_loss             | 0.00167  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 331000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 162    |
|    time_elapsed    | 33800  |
|    total_timesteps | 331776 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 332000   |
| train/                    |          |
|    explained_variance     | 0.563    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00581  |
|    learning_rate          | 0.001    |
|    n_updates              | 162      |
|    policy_objective       | 0.0556   |
|    value_loss             | 0.00166  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 333000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 163    |
|    time_elapsed    | 34005  |
|    total_timesteps | 333824 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 334000   |
| train/                    |          |
|    explained_variance     | 0.458    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.001    |
|    n_updates              | 163      |
|    policy_objective       | 0.0569   |
|    value_loss             | 0.00174  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 335000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 164    |
|    time_elapsed    | 34209  |
|    total_timesteps | 335872 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 336000   |
| train/                    |          |
|    explained_variance     | 0.467    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00562  |
|    learning_rate          | 0.001    |
|    n_updates              | 164      |
|    policy_objective       | 0.0497   |
|    value_loss             | 0.00181  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 337000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 165    |
|    time_elapsed    | 34413  |
|    total_timesteps | 337920 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 338000   |
| train/                    |          |
|    explained_variance     | 0.574    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00669  |
|    learning_rate          | 0.001    |
|    n_updates              | 165      |
|    policy_objective       | 0.0603   |
|    value_loss             | 0.0016   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 339000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 166    |
|    time_elapsed    | 34618  |
|    total_timesteps | 339968 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 340000   |
| train/                    |          |
|    explained_variance     | 0.614    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00651  |
|    learning_rate          | 0.001    |
|    n_updates              | 166      |
|    policy_objective       | 0.0535   |
|    value_loss             | 0.00183  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 341000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 342000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 167    |
|    time_elapsed    | 34922  |
|    total_timesteps | 342016 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 343000   |
| train/                    |          |
|    explained_variance     | 0.381    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00589  |
|    learning_rate          | 0.001    |
|    n_updates              | 167      |
|    policy_objective       | 0.0591   |
|    value_loss             | 0.0026   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 344000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 168    |
|    time_elapsed    | 35126  |
|    total_timesteps | 344064 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 345000   |
| train/                    |          |
|    explained_variance     | 0.75     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00526  |
|    learning_rate          | 0.001    |
|    n_updates              | 168      |
|    policy_objective       | 0.054    |
|    value_loss             | 0.0015   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 346000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 169    |
|    time_elapsed    | 35331  |
|    total_timesteps | 346112 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 347000   |
| train/                    |          |
|    explained_variance     | 0.694    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00626  |
|    learning_rate          | 0.001    |
|    n_updates              | 169      |
|    policy_objective       | 0.0582   |
|    value_loss             | 0.00199  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 348000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 170    |
|    time_elapsed    | 35535  |
|    total_timesteps | 348160 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 349000   |
| train/                    |          |
|    explained_variance     | 0.421    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00644  |
|    learning_rate          | 0.001    |
|    n_updates              | 170      |
|    policy_objective       | 0.0603   |
|    value_loss             | 0.00191  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 350000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 171    |
|    time_elapsed    | 35739  |
|    total_timesteps | 350208 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 351000   |
| train/                    |          |
|    explained_variance     | 0.536    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00632  |
|    learning_rate          | 0.001    |
|    n_updates              | 171      |
|    policy_objective       | 0.053    |
|    value_loss             | 0.00208  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 352000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 172    |
|    time_elapsed    | 35944  |
|    total_timesteps | 352256 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 353000   |
| train/                    |          |
|    explained_variance     | 0.572    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00608  |
|    learning_rate          | 0.001    |
|    n_updates              | 172      |
|    policy_objective       | 0.0443   |
|    value_loss             | 0.00236  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 354000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 173    |
|    time_elapsed    | 36148  |
|    total_timesteps | 354304 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 355000   |
| train/                    |          |
|    explained_variance     | 0.501    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00751  |
|    learning_rate          | 0.001    |
|    n_updates              | 173      |
|    policy_objective       | 0.056    |
|    value_loss             | 0.00192  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 356000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 174    |
|    time_elapsed    | 36352  |
|    total_timesteps | 356352 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 357000   |
| train/                    |          |
|    explained_variance     | 0.566    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00599  |
|    learning_rate          | 0.001    |
|    n_updates              | 174      |
|    policy_objective       | 0.0424   |
|    value_loss             | 0.00199  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 358000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 175    |
|    time_elapsed    | 36557  |
|    total_timesteps | 358400 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 359000   |
| train/                    |          |
|    explained_variance     | 0.538    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00681  |
|    learning_rate          | 0.001    |
|    n_updates              | 175      |
|    policy_objective       | 0.0514   |
|    value_loss             | 0.00166  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 360000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 176    |
|    time_elapsed    | 36761  |
|    total_timesteps | 360448 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 361000   |
| train/                    |          |
|    explained_variance     | 0.608    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00526  |
|    learning_rate          | 0.001    |
|    n_updates              | 176      |
|    policy_objective       | 0.0462   |
|    value_loss             | 0.00194  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 362000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 177    |
|    time_elapsed    | 36965  |
|    total_timesteps | 362496 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 363000   |
| train/                    |          |
|    explained_variance     | 0.414    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00557  |
|    learning_rate          | 0.001    |
|    n_updates              | 177      |
|    policy_objective       | 0.0483   |
|    value_loss             | 0.00237  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 364000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 178    |
|    time_elapsed    | 37169  |
|    total_timesteps | 364544 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 365000   |
| train/                    |          |
|    explained_variance     | 0.617    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00648  |
|    learning_rate          | 0.001    |
|    n_updates              | 178      |
|    policy_objective       | 0.05     |
|    value_loss             | 0.00224  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 366000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 179    |
|    time_elapsed    | 37374  |
|    total_timesteps | 366592 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 367000   |
| train/                    |          |
|    explained_variance     | 0.62     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00841  |
|    learning_rate          | 0.001    |
|    n_updates              | 179      |
|    policy_objective       | 0.0485   |
|    value_loss             | 0.00235  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 368000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 180    |
|    time_elapsed    | 37578  |
|    total_timesteps | 368640 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 369000   |
| train/                    |          |
|    explained_variance     | 0.673    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00617  |
|    learning_rate          | 0.001    |
|    n_updates              | 180      |
|    policy_objective       | 0.0418   |
|    value_loss             | 0.00306  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 370000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 181    |
|    time_elapsed    | 37782  |
|    total_timesteps | 370688 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 371000   |
| train/                    |          |
|    explained_variance     | 0.664    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00549  |
|    learning_rate          | 0.001    |
|    n_updates              | 181      |
|    policy_objective       | 0.0462   |
|    value_loss             | 0.00274  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 372000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 182    |
|    time_elapsed    | 37987  |
|    total_timesteps | 372736 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 373000   |
| train/                    |          |
|    explained_variance     | 0.672    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00669  |
|    learning_rate          | 0.001    |
|    n_updates              | 182      |
|    policy_objective       | 0.0534   |
|    value_loss             | 0.00383  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 374000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 183    |
|    time_elapsed    | 38191  |
|    total_timesteps | 374784 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 375000   |
| train/                    |          |
|    explained_variance     | 0.652    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00335  |
|    learning_rate          | 0.001    |
|    n_updates              | 183      |
|    policy_objective       | 0.0252   |
|    value_loss             | 0.00325  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 376000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 184    |
|    time_elapsed    | 38395  |
|    total_timesteps | 376832 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 377000   |
| train/                    |          |
|    explained_variance     | 0.719    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00629  |
|    learning_rate          | 0.001    |
|    n_updates              | 184      |
|    policy_objective       | 0.0546   |
|    value_loss             | 0.00225  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 378000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 185    |
|    time_elapsed    | 38600  |
|    total_timesteps | 378880 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 379000   |
| train/                    |          |
|    explained_variance     | 0.813    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00704  |
|    learning_rate          | 0.001    |
|    n_updates              | 185      |
|    policy_objective       | 0.0644   |
|    value_loss             | 0.00208  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 380000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 186    |
|    time_elapsed    | 38804  |
|    total_timesteps | 380928 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 381000   |
| train/                    |          |
|    explained_variance     | 0.693    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00707  |
|    learning_rate          | 0.001    |
|    n_updates              | 186      |
|    policy_objective       | 0.0501   |
|    value_loss             | 0.00252  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 382000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 187    |
|    time_elapsed    | 39009  |
|    total_timesteps | 382976 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 383000   |
| train/                    |          |
|    explained_variance     | 0.803    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00624  |
|    learning_rate          | 0.001    |
|    n_updates              | 187      |
|    policy_objective       | 0.0588   |
|    value_loss             | 0.0024   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 384000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 385000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 188    |
|    time_elapsed    | 39313  |
|    total_timesteps | 385024 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 386000   |
| train/                    |          |
|    explained_variance     | 0.631    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.007    |
|    learning_rate          | 0.001    |
|    n_updates              | 188      |
|    policy_objective       | 0.0506   |
|    value_loss             | 0.0037   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 387000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 189    |
|    time_elapsed    | 39517  |
|    total_timesteps | 387072 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 388000   |
| train/                    |          |
|    explained_variance     | 0.657    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00608  |
|    learning_rate          | 0.001    |
|    n_updates              | 189      |
|    policy_objective       | 0.0441   |
|    value_loss             | 0.00247  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 389000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 190    |
|    time_elapsed    | 39721  |
|    total_timesteps | 389120 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 390000   |
| train/                    |          |
|    explained_variance     | 0.67     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00684  |
|    learning_rate          | 0.001    |
|    n_updates              | 190      |
|    policy_objective       | 0.0433   |
|    value_loss             | 0.00252  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 391000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 191    |
|    time_elapsed    | 39926  |
|    total_timesteps | 391168 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 392000   |
| train/                    |          |
|    explained_variance     | 0.616    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00536  |
|    learning_rate          | 0.001    |
|    n_updates              | 191      |
|    policy_objective       | 0.0689   |
|    value_loss             | 0.00267  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 393000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 192    |
|    time_elapsed    | 40130  |
|    total_timesteps | 393216 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 394000   |
| train/                    |          |
|    explained_variance     | 0.726    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00537  |
|    learning_rate          | 0.001    |
|    n_updates              | 192      |
|    policy_objective       | 0.0578   |
|    value_loss             | 0.00206  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 395000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 193    |
|    time_elapsed    | 40335  |
|    total_timesteps | 395264 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 396000   |
| train/                    |          |
|    explained_variance     | 0.639    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00661  |
|    learning_rate          | 0.001    |
|    n_updates              | 193      |
|    policy_objective       | 0.0512   |
|    value_loss             | 0.00245  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 397000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 194    |
|    time_elapsed    | 40539  |
|    total_timesteps | 397312 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 398000   |
| train/                    |          |
|    explained_variance     | 0.601    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00606  |
|    learning_rate          | 0.001    |
|    n_updates              | 194      |
|    policy_objective       | 0.0459   |
|    value_loss             | 0.00289  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 399000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 195    |
|    time_elapsed    | 40743  |
|    total_timesteps | 399360 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 400000   |
| train/                    |          |
|    explained_variance     | 0.677    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00725  |
|    learning_rate          | 0.001    |
|    n_updates              | 195      |
|    policy_objective       | 0.046    |
|    value_loss             | 0.00253  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 401000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 196    |
|    time_elapsed    | 40948  |
|    total_timesteps | 401408 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 402000   |
| train/                    |          |
|    explained_variance     | 0.728    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00623  |
|    learning_rate          | 0.001    |
|    n_updates              | 196      |
|    policy_objective       | 0.0427   |
|    value_loss             | 0.00349  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 403000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 197    |
|    time_elapsed    | 41152  |
|    total_timesteps | 403456 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 404000   |
| train/                    |          |
|    explained_variance     | 0.597    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00645  |
|    learning_rate          | 0.001    |
|    n_updates              | 197      |
|    policy_objective       | 0.0516   |
|    value_loss             | 0.00284  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 405000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 198    |
|    time_elapsed    | 41356  |
|    total_timesteps | 405504 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 406000   |
| train/                    |          |
|    explained_variance     | 0.605    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00686  |
|    learning_rate          | 0.001    |
|    n_updates              | 198      |
|    policy_objective       | 0.0489   |
|    value_loss             | 0.00291  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 407000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 199    |
|    time_elapsed    | 41561  |
|    total_timesteps | 407552 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 408000   |
| train/                    |          |
|    explained_variance     | 0.702    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00729  |
|    learning_rate          | 0.001    |
|    n_updates              | 199      |
|    policy_objective       | 0.051    |
|    value_loss             | 0.00312  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 409000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 200    |
|    time_elapsed    | 41765  |
|    total_timesteps | 409600 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 410000   |
| train/                    |          |
|    explained_variance     | 0.659    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00616  |
|    learning_rate          | 0.001    |
|    n_updates              | 200      |
|    policy_objective       | 0.0348   |
|    value_loss             | 0.00348  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 411000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 201    |
|    time_elapsed    | 41969  |
|    total_timesteps | 411648 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 412000   |
| train/                    |          |
|    explained_variance     | 0.694    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00686  |
|    learning_rate          | 0.001    |
|    n_updates              | 201      |
|    policy_objective       | 0.0425   |
|    value_loss             | 0.00366  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 413000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 202    |
|    time_elapsed    | 42174  |
|    total_timesteps | 413696 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 414000   |
| train/                    |          |
|    explained_variance     | 0.676    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00677  |
|    learning_rate          | 0.001    |
|    n_updates              | 202      |
|    policy_objective       | 0.0474   |
|    value_loss             | 0.0041   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 415000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 203    |
|    time_elapsed    | 42378  |
|    total_timesteps | 415744 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 416000   |
| train/                    |          |
|    explained_variance     | 0.698    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00768  |
|    learning_rate          | 0.001    |
|    n_updates              | 203      |
|    policy_objective       | 0.0412   |
|    value_loss             | 0.00424  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 417000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 204    |
|    time_elapsed    | 42583  |
|    total_timesteps | 417792 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 418000   |
| train/                    |          |
|    explained_variance     | 0.682    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00673  |
|    learning_rate          | 0.001    |
|    n_updates              | 204      |
|    policy_objective       | 0.0417   |
|    value_loss             | 0.00389  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 419000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 205    |
|    time_elapsed    | 42787  |
|    total_timesteps | 419840 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 420000   |
| train/                    |          |
|    explained_variance     | 0.659    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00649  |
|    learning_rate          | 0.001    |
|    n_updates              | 205      |
|    policy_objective       | 0.0358   |
|    value_loss             | 0.00385  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 421000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 206    |
|    time_elapsed    | 42991  |
|    total_timesteps | 421888 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 422000   |
| train/                    |          |
|    explained_variance     | 0.673    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00676  |
|    learning_rate          | 0.001    |
|    n_updates              | 206      |
|    policy_objective       | 0.0412   |
|    value_loss             | 0.00395  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 423000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 207    |
|    time_elapsed    | 43196  |
|    total_timesteps | 423936 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 424000   |
| train/                    |          |
|    explained_variance     | 0.607    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00534  |
|    learning_rate          | 0.001    |
|    n_updates              | 207      |
|    policy_objective       | 0.0557   |
|    value_loss             | 0.00393  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 425000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 208    |
|    time_elapsed    | 43400  |
|    total_timesteps | 425984 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 426000   |
| train/                    |          |
|    explained_variance     | 0.591    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00842  |
|    learning_rate          | 0.001    |
|    n_updates              | 208      |
|    policy_objective       | 0.0424   |
|    value_loss             | 0.00502  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 427000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 428000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 209    |
|    time_elapsed    | 43704  |
|    total_timesteps | 428032 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.8      |
| time/                     |          |
|    total_timesteps        | 429000   |
| train/                    |          |
|    explained_variance     | 0.64     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00729  |
|    learning_rate          | 0.001    |
|    n_updates              | 209      |
|    policy_objective       | 0.0379   |
|    value_loss             | 0.0066   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 430000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 210    |
|    time_elapsed    | 43909  |
|    total_timesteps | 430080 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 431000   |
| train/                    |          |
|    explained_variance     | 0.737    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00659  |
|    learning_rate          | 0.001    |
|    n_updates              | 210      |
|    policy_objective       | 0.026    |
|    value_loss             | 0.00474  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 432000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 211    |
|    time_elapsed    | 44113  |
|    total_timesteps | 432128 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 433000   |
| train/                    |          |
|    explained_variance     | 0.673    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0086   |
|    learning_rate          | 0.001    |
|    n_updates              | 211      |
|    policy_objective       | 0.0428   |
|    value_loss             | 0.00444  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 434000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 212    |
|    time_elapsed    | 44317  |
|    total_timesteps | 434176 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 435000   |
| train/                    |          |
|    explained_variance     | 0.62     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00632  |
|    learning_rate          | 0.001    |
|    n_updates              | 212      |
|    policy_objective       | 0.0466   |
|    value_loss             | 0.00424  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 436000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 213    |
|    time_elapsed    | 44522  |
|    total_timesteps | 436224 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 437000   |
| train/                    |          |
|    explained_variance     | 0.521    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00884  |
|    learning_rate          | 0.001    |
|    n_updates              | 213      |
|    policy_objective       | 0.0296   |
|    value_loss             | 0.00586  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 438000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 214    |
|    time_elapsed    | 44726  |
|    total_timesteps | 438272 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 439000   |
| train/                    |          |
|    explained_variance     | 0.657    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00866  |
|    learning_rate          | 0.001    |
|    n_updates              | 214      |
|    policy_objective       | 0.0324   |
|    value_loss             | 0.00437  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 440000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 215    |
|    time_elapsed    | 44930  |
|    total_timesteps | 440320 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1.1      |
| time/                     |          |
|    total_timesteps        | 441000   |
| train/                    |          |
|    explained_variance     | 0.621    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00624  |
|    learning_rate          | 0.001    |
|    n_updates              | 215      |
|    policy_objective       | 0.052    |
|    value_loss             | 0.00365  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1.1      |
| time/              |          |
|    total_timesteps | 442000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 216    |
|    time_elapsed    | 45135  |
|    total_timesteps | 442368 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 443000   |
| train/                    |          |
|    explained_variance     | 0.627    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00766  |
|    learning_rate          | 0.001    |
|    n_updates              | 216      |
|    policy_objective       | 0.0501   |
|    value_loss             | 0.0038   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 444000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 217    |
|    time_elapsed    | 45339  |
|    total_timesteps | 444416 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 445000   |
| train/                    |          |
|    explained_variance     | 0.69     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00893  |
|    learning_rate          | 0.001    |
|    n_updates              | 217      |
|    policy_objective       | 0.0451   |
|    value_loss             | 0.004    |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 446000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 218    |
|    time_elapsed    | 45543  |
|    total_timesteps | 446464 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 447000   |
| train/                    |          |
|    explained_variance     | 0.521    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00606  |
|    learning_rate          | 0.001    |
|    n_updates              | 218      |
|    policy_objective       | 0.0345   |
|    value_loss             | 0.00403  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 448000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 219    |
|    time_elapsed    | 45748  |
|    total_timesteps | 448512 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 449000   |
| train/                    |          |
|    explained_variance     | 0.609    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00737  |
|    learning_rate          | 0.001    |
|    n_updates              | 219      |
|    policy_objective       | 0.0371   |
|    value_loss             | 0.00329  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 450000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 220    |
|    time_elapsed    | 45952  |
|    total_timesteps | 450560 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 451000   |
| train/                    |          |
|    explained_variance     | 0.614    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00562  |
|    learning_rate          | 0.001    |
|    n_updates              | 220      |
|    policy_objective       | 0.0359   |
|    value_loss             | 0.00272  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 452000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 221    |
|    time_elapsed    | 46157  |
|    total_timesteps | 452608 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 453000   |
| train/                    |          |
|    explained_variance     | 0.635    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00766  |
|    learning_rate          | 0.001    |
|    n_updates              | 221      |
|    policy_objective       | 0.03     |
|    value_loss             | 0.00451  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 454000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 222    |
|    time_elapsed    | 46361  |
|    total_timesteps | 454656 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 455000   |
| train/                    |          |
|    explained_variance     | 0.633    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00945  |
|    learning_rate          | 0.001    |
|    n_updates              | 222      |
|    policy_objective       | 0.0331   |
|    value_loss             | 0.00433  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 456000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 223    |
|    time_elapsed    | 46565  |
|    total_timesteps | 456704 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 457000   |
| train/                    |          |
|    explained_variance     | 0.563    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00821  |
|    learning_rate          | 0.001    |
|    n_updates              | 223      |
|    policy_objective       | 0.0321   |
|    value_loss             | 0.00459  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 458000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 224    |
|    time_elapsed    | 46770  |
|    total_timesteps | 458752 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 459000   |
| train/                    |          |
|    explained_variance     | 0.596    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00741  |
|    learning_rate          | 0.001    |
|    n_updates              | 224      |
|    policy_objective       | 0.0421   |
|    value_loss             | 0.00454  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 460000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 225    |
|    time_elapsed    | 46974  |
|    total_timesteps | 460800 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 461000   |
| train/                    |          |
|    explained_variance     | 0.631    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00912  |
|    learning_rate          | 0.001    |
|    n_updates              | 225      |
|    policy_objective       | 0.0388   |
|    value_loss             | 0.00431  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 462000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 226    |
|    time_elapsed    | 47179  |
|    total_timesteps | 462848 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 463000   |
| train/                    |          |
|    explained_variance     | 0.612    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00647  |
|    learning_rate          | 0.001    |
|    n_updates              | 226      |
|    policy_objective       | 0.0443   |
|    value_loss             | 0.00401  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 464000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 227    |
|    time_elapsed    | 47383  |
|    total_timesteps | 464896 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 465000   |
| train/                    |          |
|    explained_variance     | 0.64     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00776  |
|    learning_rate          | 0.001    |
|    n_updates              | 227      |
|    policy_objective       | 0.0558   |
|    value_loss             | 0.00472  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 466000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 228    |
|    time_elapsed    | 47587  |
|    total_timesteps | 466944 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 467000   |
| train/                    |          |
|    explained_variance     | 0.728    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00757  |
|    learning_rate          | 0.001    |
|    n_updates              | 228      |
|    policy_objective       | 0.0513   |
|    value_loss             | 0.00323  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 468000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 229    |
|    time_elapsed    | 47792  |
|    total_timesteps | 468992 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 469000   |
| train/                    |          |
|    explained_variance     | 0.66     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0075   |
|    learning_rate          | 0.001    |
|    n_updates              | 229      |
|    policy_objective       | 0.0321   |
|    value_loss             | 0.00331  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 470000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 471000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 230    |
|    time_elapsed    | 48096  |
|    total_timesteps | 471040 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 472000   |
| train/                    |          |
|    explained_variance     | 0.617    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00635  |
|    learning_rate          | 0.001    |
|    n_updates              | 230      |
|    policy_objective       | 0.0273   |
|    value_loss             | 0.00438  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 473000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 231    |
|    time_elapsed    | 48301  |
|    total_timesteps | 473088 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 474000   |
| train/                    |          |
|    explained_variance     | 0.714    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00666  |
|    learning_rate          | 0.001    |
|    n_updates              | 231      |
|    policy_objective       | 0.055    |
|    value_loss             | 0.00471  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 475000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 232    |
|    time_elapsed    | 48505  |
|    total_timesteps | 475136 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 476000   |
| train/                    |          |
|    explained_variance     | 0.67     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.007    |
|    learning_rate          | 0.001    |
|    n_updates              | 232      |
|    policy_objective       | 0.0546   |
|    value_loss             | 0.00319  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 477000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 233    |
|    time_elapsed    | 48709  |
|    total_timesteps | 477184 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 478000   |
| train/                    |          |
|    explained_variance     | 0.601    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00783  |
|    learning_rate          | 0.001    |
|    n_updates              | 233      |
|    policy_objective       | 0.0345   |
|    value_loss             | 0.00435  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 479000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 234    |
|    time_elapsed    | 48914  |
|    total_timesteps | 479232 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 480000   |
| train/                    |          |
|    explained_variance     | 0.647    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00736  |
|    learning_rate          | 0.001    |
|    n_updates              | 234      |
|    policy_objective       | 0.0452   |
|    value_loss             | 0.00394  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 481000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 235    |
|    time_elapsed    | 49118  |
|    total_timesteps | 481280 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 482000   |
| train/                    |          |
|    explained_variance     | 0.568    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00843  |
|    learning_rate          | 0.001    |
|    n_updates              | 235      |
|    policy_objective       | 0.0503   |
|    value_loss             | 0.00506  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 483000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 236    |
|    time_elapsed    | 49322  |
|    total_timesteps | 483328 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.9      |
| time/                     |          |
|    total_timesteps        | 484000   |
| train/                    |          |
|    explained_variance     | 0.62     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00623  |
|    learning_rate          | 0.001    |
|    n_updates              | 236      |
|    policy_objective       | 0.034    |
|    value_loss             | 0.00456  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.9      |
| time/              |          |
|    total_timesteps | 485000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 237    |
|    time_elapsed    | 49527  |
|    total_timesteps | 485376 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 486000   |
| train/                    |          |
|    explained_variance     | 0.535    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00726  |
|    learning_rate          | 0.001    |
|    n_updates              | 237      |
|    policy_objective       | 0.0295   |
|    value_loss             | 0.00657  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 487000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 238    |
|    time_elapsed    | 49731  |
|    total_timesteps | 487424 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 488000   |
| train/                    |          |
|    explained_variance     | 0.626    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00868  |
|    learning_rate          | 0.001    |
|    n_updates              | 238      |
|    policy_objective       | 0.0365   |
|    value_loss             | 0.00606  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 489000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 239    |
|    time_elapsed    | 49936  |
|    total_timesteps | 489472 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 490000   |
| train/                    |          |
|    explained_variance     | 0.664    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00534  |
|    learning_rate          | 0.001    |
|    n_updates              | 239      |
|    policy_objective       | 0.0352   |
|    value_loss             | 0.00516  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 491000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 240    |
|    time_elapsed    | 50140  |
|    total_timesteps | 491520 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 492000   |
| train/                    |          |
|    explained_variance     | 0.638    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00739  |
|    learning_rate          | 0.001    |
|    n_updates              | 240      |
|    policy_objective       | 0.04     |
|    value_loss             | 0.00551  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 493000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 241    |
|    time_elapsed    | 50344  |
|    total_timesteps | 493568 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 494000   |
| train/                    |          |
|    explained_variance     | 0.657    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00807  |
|    learning_rate          | 0.001    |
|    n_updates              | 241      |
|    policy_objective       | 0.03     |
|    value_loss             | 0.00657  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 495000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 242    |
|    time_elapsed    | 50549  |
|    total_timesteps | 495616 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 496000   |
| train/                    |          |
|    explained_variance     | 0.696    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00811  |
|    learning_rate          | 0.001    |
|    n_updates              | 242      |
|    policy_objective       | 0.0434   |
|    value_loss             | 0.00539  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 497000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 243    |
|    time_elapsed    | 50753  |
|    total_timesteps | 497664 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 498000   |
| train/                    |          |
|    explained_variance     | 0.683    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0088   |
|    learning_rate          | 0.001    |
|    n_updates              | 243      |
|    policy_objective       | 0.0409   |
|    value_loss             | 0.00586  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 499000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 244    |
|    time_elapsed    | 50957  |
|    total_timesteps | 499712 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 1        |
| time/                     |          |
|    total_timesteps        | 500000   |
| train/                    |          |
|    explained_variance     | 0.663    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00807  |
|    learning_rate          | 0.001    |
|    n_updates              | 244      |
|    policy_objective       | 0.032    |
|    value_loss             | 0.00564  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 1        |
| time/              |          |
|    total_timesteps | 501000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 245    |
|    time_elapsed    | 51162  |
|    total_timesteps | 501760 |
-------------------------------
