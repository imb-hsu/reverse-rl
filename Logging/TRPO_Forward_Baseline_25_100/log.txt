Logging to ./Logging/TRPO_Forward_Baseline_25_100
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 1000     |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 2000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 1    |
|    time_elapsed    | 204  |
|    total_timesteps | 2048 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 3000     |
| train/                    |          |
|    explained_variance     | 0.865    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 1        |
|    policy_objective       | 0.0467   |
|    value_loss             | 0.0105   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 4000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 2    |
|    time_elapsed    | 408  |
|    total_timesteps | 4096 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 5000     |
| train/                    |          |
|    explained_variance     | 0.842    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00535  |
|    learning_rate          | 0.001    |
|    n_updates              | 2        |
|    policy_objective       | 0.058    |
|    value_loss             | 0.0274   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 6000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 3    |
|    time_elapsed    | 612  |
|    total_timesteps | 6144 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 7000     |
| train/                    |          |
|    explained_variance     | 0.867    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00529  |
|    learning_rate          | 0.001    |
|    n_updates              | 3        |
|    policy_objective       | 0.0511   |
|    value_loss             | 0.0109   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 8000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 4    |
|    time_elapsed    | 817  |
|    total_timesteps | 8192 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 9000     |
| train/                    |          |
|    explained_variance     | 0.64     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0043   |
|    learning_rate          | 0.001    |
|    n_updates              | 4        |
|    policy_objective       | 0.0731   |
|    value_loss             | 0.00373  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 10000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 5     |
|    time_elapsed    | 1021  |
|    total_timesteps | 10240 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 11000    |
| train/                    |          |
|    explained_variance     | 0.707    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00572  |
|    learning_rate          | 0.001    |
|    n_updates              | 5        |
|    policy_objective       | 0.0482   |
|    value_loss             | 0.0044   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 12000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 6     |
|    time_elapsed    | 1225  |
|    total_timesteps | 12288 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 13000    |
| train/                    |          |
|    explained_variance     | 0.908    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0061   |
|    learning_rate          | 0.001    |
|    n_updates              | 6        |
|    policy_objective       | 0.0479   |
|    value_loss             | 0.0075   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 14000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 7     |
|    time_elapsed    | 1430  |
|    total_timesteps | 14336 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 15000    |
| train/                    |          |
|    explained_variance     | 0.917    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00566  |
|    learning_rate          | 0.001    |
|    n_updates              | 7        |
|    policy_objective       | 0.051    |
|    value_loss             | 0.00448  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 16000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 8     |
|    time_elapsed    | 1634  |
|    total_timesteps | 16384 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 17000    |
| train/                    |          |
|    explained_variance     | 0.863    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00489  |
|    learning_rate          | 0.001    |
|    n_updates              | 8        |
|    policy_objective       | 0.0504   |
|    value_loss             | 0.00278  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 18000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 9     |
|    time_elapsed    | 1838  |
|    total_timesteps | 18432 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 19000    |
| train/                    |          |
|    explained_variance     | 0.706    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00449  |
|    learning_rate          | 0.001    |
|    n_updates              | 9        |
|    policy_objective       | 0.0638   |
|    value_loss             | 0.00316  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 20000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 10    |
|    time_elapsed    | 2042  |
|    total_timesteps | 20480 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 21000    |
| train/                    |          |
|    explained_variance     | 0.787    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00477  |
|    learning_rate          | 0.001    |
|    n_updates              | 10       |
|    policy_objective       | 0.0546   |
|    value_loss             | 0.00266  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 22000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 11    |
|    time_elapsed    | 2247  |
|    total_timesteps | 22528 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 23000    |
| train/                    |          |
|    explained_variance     | 0.795    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00466  |
|    learning_rate          | 0.001    |
|    n_updates              | 11       |
|    policy_objective       | 0.0583   |
|    value_loss             | 0.00213  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 24000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 12    |
|    time_elapsed    | 2451  |
|    total_timesteps | 24576 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 25000    |
| train/                    |          |
|    explained_variance     | 0.854    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00458  |
|    learning_rate          | 0.001    |
|    n_updates              | 12       |
|    policy_objective       | 0.0571   |
|    value_loss             | 0.0029   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 26000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 13    |
|    time_elapsed    | 2655  |
|    total_timesteps | 26624 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 27000    |
| train/                    |          |
|    explained_variance     | 0.863    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00494  |
|    learning_rate          | 0.001    |
|    n_updates              | 13       |
|    policy_objective       | 0.0509   |
|    value_loss             | 0.00516  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 28000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 14    |
|    time_elapsed    | 2860  |
|    total_timesteps | 28672 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 29000    |
| train/                    |          |
|    explained_variance     | 0.894    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00578  |
|    learning_rate          | 0.001    |
|    n_updates              | 14       |
|    policy_objective       | 0.0494   |
|    value_loss             | 0.00255  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 30000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 15    |
|    time_elapsed    | 3064  |
|    total_timesteps | 30720 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 31000    |
| train/                    |          |
|    explained_variance     | 0.814    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00533  |
|    learning_rate          | 0.001    |
|    n_updates              | 15       |
|    policy_objective       | 0.0539   |
|    value_loss             | 0.00154  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 32000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 16    |
|    time_elapsed    | 3268  |
|    total_timesteps | 32768 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 33000    |
| train/                    |          |
|    explained_variance     | 0.593    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00672  |
|    learning_rate          | 0.001    |
|    n_updates              | 16       |
|    policy_objective       | 0.0583   |
|    value_loss             | 0.000136 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 34000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 17    |
|    time_elapsed    | 3473  |
|    total_timesteps | 34816 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 35000    |
| train/                    |          |
|    explained_variance     | 0.787    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00567  |
|    learning_rate          | 0.001    |
|    n_updates              | 17       |
|    policy_objective       | 0.0537   |
|    value_loss             | 0.0064   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 36000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 18    |
|    time_elapsed    | 3677  |
|    total_timesteps | 36864 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 37000    |
| train/                    |          |
|    explained_variance     | 0.774    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00468  |
|    learning_rate          | 0.001    |
|    n_updates              | 18       |
|    policy_objective       | 0.0591   |
|    value_loss             | 0.00301  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 38000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 19    |
|    time_elapsed    | 3881  |
|    total_timesteps | 38912 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 39000    |
| train/                    |          |
|    explained_variance     | 0.722    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00484  |
|    learning_rate          | 0.001    |
|    n_updates              | 19       |
|    policy_objective       | 0.0693   |
|    value_loss             | 0.00381  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 40000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 20    |
|    time_elapsed    | 4086  |
|    total_timesteps | 40960 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 41000    |
| train/                    |          |
|    explained_variance     | 0.834    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00412  |
|    learning_rate          | 0.001    |
|    n_updates              | 20       |
|    policy_objective       | 0.0594   |
|    value_loss             | 0.00114  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 42000    |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 43000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 21    |
|    time_elapsed    | 4390  |
|    total_timesteps | 43008 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 44000    |
| train/                    |          |
|    explained_variance     | 0.809    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00524  |
|    learning_rate          | 0.001    |
|    n_updates              | 21       |
|    policy_objective       | 0.0524   |
|    value_loss             | 0.00126  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 45000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 22    |
|    time_elapsed    | 4594  |
|    total_timesteps | 45056 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 46000    |
| train/                    |          |
|    explained_variance     | 0.788    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00656  |
|    learning_rate          | 0.001    |
|    n_updates              | 22       |
|    policy_objective       | 0.0487   |
|    value_loss             | 0.00223  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 47000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 23    |
|    time_elapsed    | 4798  |
|    total_timesteps | 47104 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 48000    |
| train/                    |          |
|    explained_variance     | 0.842    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00514  |
|    learning_rate          | 0.001    |
|    n_updates              | 23       |
|    policy_objective       | 0.055    |
|    value_loss             | 0.00172  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 49000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 24    |
|    time_elapsed    | 5003  |
|    total_timesteps | 49152 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 50000    |
| train/                    |          |
|    explained_variance     | 0.872    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00507  |
|    learning_rate          | 0.001    |
|    n_updates              | 24       |
|    policy_objective       | 0.0518   |
|    value_loss             | 0.00245  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 51000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 25    |
|    time_elapsed    | 5207  |
|    total_timesteps | 51200 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 52000    |
| train/                    |          |
|    explained_variance     | 0.837    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00497  |
|    learning_rate          | 0.001    |
|    n_updates              | 25       |
|    policy_objective       | 0.0542   |
|    value_loss             | 0.00368  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 53000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 26    |
|    time_elapsed    | 5411  |
|    total_timesteps | 53248 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 54000    |
| train/                    |          |
|    explained_variance     | 0.879    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00535  |
|    learning_rate          | 0.001    |
|    n_updates              | 26       |
|    policy_objective       | 0.0533   |
|    value_loss             | 0.00174  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 55000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 27    |
|    time_elapsed    | 5616  |
|    total_timesteps | 55296 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 56000    |
| train/                    |          |
|    explained_variance     | 0.86     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00654  |
|    learning_rate          | 0.001    |
|    n_updates              | 27       |
|    policy_objective       | 0.052    |
|    value_loss             | 0.000887 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 57000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 28    |
|    time_elapsed    | 5820  |
|    total_timesteps | 57344 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 58000    |
| train/                    |          |
|    explained_variance     | 0.88     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0075   |
|    learning_rate          | 0.001    |
|    n_updates              | 28       |
|    policy_objective       | 0.0403   |
|    value_loss             | 0.000334 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 59000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 29    |
|    time_elapsed    | 6024  |
|    total_timesteps | 59392 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 60000    |
| train/                    |          |
|    explained_variance     | 0.855    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00477  |
|    learning_rate          | 0.001    |
|    n_updates              | 29       |
|    policy_objective       | 0.0478   |
|    value_loss             | 0.000887 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 61000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 30    |
|    time_elapsed    | 6229  |
|    total_timesteps | 61440 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 62000    |
| train/                    |          |
|    explained_variance     | 0.819    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00468  |
|    learning_rate          | 0.001    |
|    n_updates              | 30       |
|    policy_objective       | 0.0511   |
|    value_loss             | 0.00241  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 63000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 31    |
|    time_elapsed    | 6433  |
|    total_timesteps | 63488 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 64000    |
| train/                    |          |
|    explained_variance     | 0.743    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00498  |
|    learning_rate          | 0.001    |
|    n_updates              | 31       |
|    policy_objective       | 0.0536   |
|    value_loss             | 0.00226  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 65000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 32    |
|    time_elapsed    | 6637  |
|    total_timesteps | 65536 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 66000    |
| train/                    |          |
|    explained_variance     | 0.828    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00424  |
|    learning_rate          | 0.001    |
|    n_updates              | 32       |
|    policy_objective       | 0.0603   |
|    value_loss             | 0.00124  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 67000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 33    |
|    time_elapsed    | 6842  |
|    total_timesteps | 67584 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 68000    |
| train/                    |          |
|    explained_variance     | 0.858    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00541  |
|    learning_rate          | 0.001    |
|    n_updates              | 33       |
|    policy_objective       | 0.0501   |
|    value_loss             | 0.00228  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 69000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 34    |
|    time_elapsed    | 7046  |
|    total_timesteps | 69632 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 70000    |
| train/                    |          |
|    explained_variance     | 0.822    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00632  |
|    learning_rate          | 0.001    |
|    n_updates              | 34       |
|    policy_objective       | 0.0467   |
|    value_loss             | 0.00135  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 71000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 35    |
|    time_elapsed    | 7250  |
|    total_timesteps | 71680 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 72000    |
| train/                    |          |
|    explained_variance     | 0.825    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00475  |
|    learning_rate          | 0.001    |
|    n_updates              | 35       |
|    policy_objective       | 0.0601   |
|    value_loss             | 0.00116  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 73000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 36    |
|    time_elapsed    | 7455  |
|    total_timesteps | 73728 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 74000    |
| train/                    |          |
|    explained_variance     | 0.779    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 36       |
|    policy_objective       | 0.0516   |
|    value_loss             | 0.000256 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 75000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 37    |
|    time_elapsed    | 7659  |
|    total_timesteps | 75776 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 76000    |
| train/                    |          |
|    explained_variance     | 0.713    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00393  |
|    learning_rate          | 0.001    |
|    n_updates              | 37       |
|    policy_objective       | 0.0629   |
|    value_loss             | 0.00159  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 77000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 38    |
|    time_elapsed    | 7863  |
|    total_timesteps | 77824 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 78000    |
| train/                    |          |
|    explained_variance     | 0.787    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00502  |
|    learning_rate          | 0.001    |
|    n_updates              | 38       |
|    policy_objective       | 0.0534   |
|    value_loss             | 0.00156  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 79000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 39    |
|    time_elapsed    | 8067  |
|    total_timesteps | 79872 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 80000    |
| train/                    |          |
|    explained_variance     | 0.856    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00585  |
|    learning_rate          | 0.001    |
|    n_updates              | 39       |
|    policy_objective       | 0.0483   |
|    value_loss             | 0.000621 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 81000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 40    |
|    time_elapsed    | 8272  |
|    total_timesteps | 81920 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 82000    |
| train/                    |          |
|    explained_variance     | 0.64     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 40       |
|    policy_objective       | 0.0492   |
|    value_loss             | 0.000718 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 83000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 41    |
|    time_elapsed    | 8476  |
|    total_timesteps | 83968 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 84000    |
| train/                    |          |
|    explained_variance     | 0.858    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00626  |
|    learning_rate          | 0.001    |
|    n_updates              | 41       |
|    policy_objective       | 0.0535   |
|    value_loss             | 0.000396 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 85000    |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 86000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 42    |
|    time_elapsed    | 8780  |
|    total_timesteps | 86016 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 87000    |
| train/                    |          |
|    explained_variance     | 0.714    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00414  |
|    learning_rate          | 0.001    |
|    n_updates              | 42       |
|    policy_objective       | 0.0709   |
|    value_loss             | 0.000743 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 88000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 43    |
|    time_elapsed    | 8985  |
|    total_timesteps | 88064 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 89000    |
| train/                    |          |
|    explained_variance     | 0.817    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00535  |
|    learning_rate          | 0.001    |
|    n_updates              | 43       |
|    policy_objective       | 0.0563   |
|    value_loss             | 0.00135  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 90000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 44    |
|    time_elapsed    | 9189  |
|    total_timesteps | 90112 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 91000    |
| train/                    |          |
|    explained_variance     | 0.732    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00506  |
|    learning_rate          | 0.001    |
|    n_updates              | 44       |
|    policy_objective       | 0.0603   |
|    value_loss             | 0.00123  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 92000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 45    |
|    time_elapsed    | 9393  |
|    total_timesteps | 92160 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 93000    |
| train/                    |          |
|    explained_variance     | 0.815    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00568  |
|    learning_rate          | 0.001    |
|    n_updates              | 45       |
|    policy_objective       | 0.0476   |
|    value_loss             | 0.000849 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 94000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 46    |
|    time_elapsed    | 9598  |
|    total_timesteps | 94208 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 95000    |
| train/                    |          |
|    explained_variance     | 0.826    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00585  |
|    learning_rate          | 0.001    |
|    n_updates              | 46       |
|    policy_objective       | 0.0437   |
|    value_loss             | 0.00276  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 96000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 47    |
|    time_elapsed    | 9802  |
|    total_timesteps | 96256 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 97000    |
| train/                    |          |
|    explained_variance     | 0.855    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00488  |
|    learning_rate          | 0.001    |
|    n_updates              | 47       |
|    policy_objective       | 0.0595   |
|    value_loss             | 0.000892 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 98000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 48    |
|    time_elapsed    | 10006 |
|    total_timesteps | 98304 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 99000    |
| train/                    |          |
|    explained_variance     | 0.819    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00592  |
|    learning_rate          | 0.001    |
|    n_updates              | 48       |
|    policy_objective       | 0.0468   |
|    value_loss             | 0.000946 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 100000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 49     |
|    time_elapsed    | 10211  |
|    total_timesteps | 100352 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 101000   |
| train/                    |          |
|    explained_variance     | 0.903    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.001    |
|    n_updates              | 49       |
|    policy_objective       | 0.048    |
|    value_loss             | 0.00124  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 102000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 50     |
|    time_elapsed    | 10415  |
|    total_timesteps | 102400 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 103000   |
| train/                    |          |
|    explained_variance     | 0.844    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00528  |
|    learning_rate          | 0.001    |
|    n_updates              | 50       |
|    policy_objective       | 0.0615   |
|    value_loss             | 0.000609 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 104000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 51     |
|    time_elapsed    | 10619  |
|    total_timesteps | 104448 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 105000   |
| train/                    |          |
|    explained_variance     | 0.635    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00286  |
|    learning_rate          | 0.001    |
|    n_updates              | 51       |
|    policy_objective       | 0.0872   |
|    value_loss             | 0.000482 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 106000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 52     |
|    time_elapsed    | 10823  |
|    total_timesteps | 106496 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 107000   |
| train/                    |          |
|    explained_variance     | 0.762    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00505  |
|    learning_rate          | 0.001    |
|    n_updates              | 52       |
|    policy_objective       | 0.0761   |
|    value_loss             | 0.00067  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 108000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 53     |
|    time_elapsed    | 11028  |
|    total_timesteps | 108544 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 109000   |
| train/                    |          |
|    explained_variance     | 0.671    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.001    |
|    n_updates              | 53       |
|    policy_objective       | 0.0627   |
|    value_loss             | 0.000722 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 110000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 54     |
|    time_elapsed    | 11232  |
|    total_timesteps | 110592 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 111000   |
| train/                    |          |
|    explained_variance     | 0.757    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 54       |
|    policy_objective       | 0.0488   |
|    value_loss             | 0.00111  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 112000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 55     |
|    time_elapsed    | 11436  |
|    total_timesteps | 112640 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 113000   |
| train/                    |          |
|    explained_variance     | 0.785    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00568  |
|    learning_rate          | 0.001    |
|    n_updates              | 55       |
|    policy_objective       | 0.0543   |
|    value_loss             | 0.000684 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 114000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 56     |
|    time_elapsed    | 11641  |
|    total_timesteps | 114688 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 115000   |
| train/                    |          |
|    explained_variance     | 0.788    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00572  |
|    learning_rate          | 0.001    |
|    n_updates              | 56       |
|    policy_objective       | 0.0549   |
|    value_loss             | 0.000599 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 116000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 57     |
|    time_elapsed    | 11845  |
|    total_timesteps | 116736 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 117000   |
| train/                    |          |
|    explained_variance     | 0.76     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00493  |
|    learning_rate          | 0.001    |
|    n_updates              | 57       |
|    policy_objective       | 0.0508   |
|    value_loss             | 0.000855 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 118000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 58     |
|    time_elapsed    | 12049  |
|    total_timesteps | 118784 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 119000   |
| train/                    |          |
|    explained_variance     | 0.74     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00449  |
|    learning_rate          | 0.001    |
|    n_updates              | 58       |
|    policy_objective       | 0.0588   |
|    value_loss             | 0.000802 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 120000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 59     |
|    time_elapsed    | 12254  |
|    total_timesteps | 120832 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 121000   |
| train/                    |          |
|    explained_variance     | 0.513    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00455  |
|    learning_rate          | 0.001    |
|    n_updates              | 59       |
|    policy_objective       | 0.0702   |
|    value_loss             | 0.000501 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 122000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 60     |
|    time_elapsed    | 12458  |
|    total_timesteps | 122880 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 123000   |
| train/                    |          |
|    explained_variance     | 0.737    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00483  |
|    learning_rate          | 0.001    |
|    n_updates              | 60       |
|    policy_objective       | 0.0573   |
|    value_loss             | 0.00087  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 124000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 61     |
|    time_elapsed    | 12662  |
|    total_timesteps | 124928 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 125000   |
| train/                    |          |
|    explained_variance     | -0.045   |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00497  |
|    learning_rate          | 0.001    |
|    n_updates              | 61       |
|    policy_objective       | 0.0608   |
|    value_loss             | 0.000674 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 126000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 62     |
|    time_elapsed    | 12867  |
|    total_timesteps | 126976 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 127000   |
| train/                    |          |
|    explained_variance     | 0.566    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00414  |
|    learning_rate          | 0.001    |
|    n_updates              | 62       |
|    policy_objective       | 0.0661   |
|    value_loss             | 0.000713 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 128000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 129000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 63     |
|    time_elapsed    | 13171  |
|    total_timesteps | 129024 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 130000   |
| train/                    |          |
|    explained_variance     | 0.677    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00461  |
|    learning_rate          | 0.001    |
|    n_updates              | 63       |
|    policy_objective       | 0.0631   |
|    value_loss             | 0.000913 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 131000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 64     |
|    time_elapsed    | 13375  |
|    total_timesteps | 131072 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 132000   |
| train/                    |          |
|    explained_variance     | 0.689    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00451  |
|    learning_rate          | 0.001    |
|    n_updates              | 64       |
|    policy_objective       | 0.0662   |
|    value_loss             | 0.0006   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 133000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 65     |
|    time_elapsed    | 13580  |
|    total_timesteps | 133120 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 134000   |
| train/                    |          |
|    explained_variance     | 0.519    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00596  |
|    learning_rate          | 0.001    |
|    n_updates              | 65       |
|    policy_objective       | 0.0604   |
|    value_loss             | 0.000798 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 135000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 66     |
|    time_elapsed    | 13784  |
|    total_timesteps | 135168 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 136000   |
| train/                    |          |
|    explained_variance     | 0.64     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00549  |
|    learning_rate          | 0.001    |
|    n_updates              | 66       |
|    policy_objective       | 0.0513   |
|    value_loss             | 0.000903 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 137000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 67     |
|    time_elapsed    | 13988  |
|    total_timesteps | 137216 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 138000   |
| train/                    |          |
|    explained_variance     | 0.706    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00445  |
|    learning_rate          | 0.001    |
|    n_updates              | 67       |
|    policy_objective       | 0.057    |
|    value_loss             | 0.000517 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 139000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 68     |
|    time_elapsed    | 14193  |
|    total_timesteps | 139264 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 140000   |
| train/                    |          |
|    explained_variance     | 0.558    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00382  |
|    learning_rate          | 0.001    |
|    n_updates              | 68       |
|    policy_objective       | 0.071    |
|    value_loss             | 0.000584 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 141000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 69     |
|    time_elapsed    | 14397  |
|    total_timesteps | 141312 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 142000   |
| train/                    |          |
|    explained_variance     | 0.728    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00415  |
|    learning_rate          | 0.001    |
|    n_updates              | 69       |
|    policy_objective       | 0.0596   |
|    value_loss             | 0.000667 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 143000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 70     |
|    time_elapsed    | 14601  |
|    total_timesteps | 143360 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 144000   |
| train/                    |          |
|    explained_variance     | 0.41     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00478  |
|    learning_rate          | 0.001    |
|    n_updates              | 70       |
|    policy_objective       | 0.0721   |
|    value_loss             | 0.000732 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 145000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 71     |
|    time_elapsed    | 14806  |
|    total_timesteps | 145408 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 146000   |
| train/                    |          |
|    explained_variance     | 0.62     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00529  |
|    learning_rate          | 0.001    |
|    n_updates              | 71       |
|    policy_objective       | 0.0598   |
|    value_loss             | 0.000533 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 147000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 72     |
|    time_elapsed    | 15010  |
|    total_timesteps | 147456 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 148000   |
| train/                    |          |
|    explained_variance     | 0.536    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00534  |
|    learning_rate          | 0.001    |
|    n_updates              | 72       |
|    policy_objective       | 0.0573   |
|    value_loss             | 0.000792 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 149000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 73     |
|    time_elapsed    | 15214  |
|    total_timesteps | 149504 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 150000   |
| train/                    |          |
|    explained_variance     | 0.774    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00555  |
|    learning_rate          | 0.001    |
|    n_updates              | 73       |
|    policy_objective       | 0.0644   |
|    value_loss             | 0.000891 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 151000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 74     |
|    time_elapsed    | 15419  |
|    total_timesteps | 151552 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 152000   |
| train/                    |          |
|    explained_variance     | 0.671    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00578  |
|    learning_rate          | 0.001    |
|    n_updates              | 74       |
|    policy_objective       | 0.0632   |
|    value_loss             | 0.000576 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 153000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 75     |
|    time_elapsed    | 15623  |
|    total_timesteps | 153600 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 154000   |
| train/                    |          |
|    explained_variance     | 0.84     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00516  |
|    learning_rate          | 0.001    |
|    n_updates              | 75       |
|    policy_objective       | 0.0524   |
|    value_loss             | 0.000498 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 155000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 76     |
|    time_elapsed    | 15827  |
|    total_timesteps | 155648 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 156000   |
| train/                    |          |
|    explained_variance     | 0.756    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00629  |
|    learning_rate          | 0.001    |
|    n_updates              | 76       |
|    policy_objective       | 0.0594   |
|    value_loss             | 0.00075  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 157000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 77     |
|    time_elapsed    | 16032  |
|    total_timesteps | 157696 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 158000   |
| train/                    |          |
|    explained_variance     | 0.796    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00537  |
|    learning_rate          | 0.001    |
|    n_updates              | 77       |
|    policy_objective       | 0.058    |
|    value_loss             | 0.000752 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 159000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 78     |
|    time_elapsed    | 16236  |
|    total_timesteps | 159744 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 160000   |
| train/                    |          |
|    explained_variance     | 0.705    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00574  |
|    learning_rate          | 0.001    |
|    n_updates              | 78       |
|    policy_objective       | 0.0559   |
|    value_loss             | 0.000711 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 161000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 79     |
|    time_elapsed    | 16440  |
|    total_timesteps | 161792 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 162000   |
| train/                    |          |
|    explained_variance     | 0.792    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00508  |
|    learning_rate          | 0.001    |
|    n_updates              | 79       |
|    policy_objective       | 0.062    |
|    value_loss             | 0.000758 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 163000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 80     |
|    time_elapsed    | 16644  |
|    total_timesteps | 163840 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 164000   |
| train/                    |          |
|    explained_variance     | 0.869    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00612  |
|    learning_rate          | 0.001    |
|    n_updates              | 80       |
|    policy_objective       | 0.059    |
|    value_loss             | 0.000679 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 165000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 81     |
|    time_elapsed    | 16849  |
|    total_timesteps | 165888 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 166000   |
| train/                    |          |
|    explained_variance     | 0.761    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00575  |
|    learning_rate          | 0.001    |
|    n_updates              | 81       |
|    policy_objective       | 0.059    |
|    value_loss             | 0.000896 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 167000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 82     |
|    time_elapsed    | 17053  |
|    total_timesteps | 167936 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 168000   |
| train/                    |          |
|    explained_variance     | 0.501    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0047   |
|    learning_rate          | 0.001    |
|    n_updates              | 82       |
|    policy_objective       | 0.066    |
|    value_loss             | 0.000447 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 169000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 83     |
|    time_elapsed    | 17257  |
|    total_timesteps | 169984 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 170000   |
| train/                    |          |
|    explained_variance     | 0.724    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00476  |
|    learning_rate          | 0.001    |
|    n_updates              | 83       |
|    policy_objective       | 0.0601   |
|    value_loss             | 0.000523 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 171000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 172000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 84     |
|    time_elapsed    | 17562  |
|    total_timesteps | 172032 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 173000   |
| train/                    |          |
|    explained_variance     | 0.491    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00455  |
|    learning_rate          | 0.001    |
|    n_updates              | 84       |
|    policy_objective       | 0.062    |
|    value_loss             | 0.000678 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 174000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 85     |
|    time_elapsed    | 17766  |
|    total_timesteps | 174080 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 175000   |
| train/                    |          |
|    explained_variance     | 0.724    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00605  |
|    learning_rate          | 0.001    |
|    n_updates              | 85       |
|    policy_objective       | 0.06     |
|    value_loss             | 0.000684 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 176000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 86     |
|    time_elapsed    | 17970  |
|    total_timesteps | 176128 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 177000   |
| train/                    |          |
|    explained_variance     | 0.593    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00451  |
|    learning_rate          | 0.001    |
|    n_updates              | 86       |
|    policy_objective       | 0.0492   |
|    value_loss             | 0.000634 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 178000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 87     |
|    time_elapsed    | 18175  |
|    total_timesteps | 178176 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 179000   |
| train/                    |          |
|    explained_variance     | 0.737    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00565  |
|    learning_rate          | 0.001    |
|    n_updates              | 87       |
|    policy_objective       | 0.0564   |
|    value_loss             | 0.000736 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 180000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 88     |
|    time_elapsed    | 18379  |
|    total_timesteps | 180224 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 181000   |
| train/                    |          |
|    explained_variance     | 0.573    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00486  |
|    learning_rate          | 0.001    |
|    n_updates              | 88       |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.000582 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 182000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 89     |
|    time_elapsed    | 18583  |
|    total_timesteps | 182272 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 183000   |
| train/                    |          |
|    explained_variance     | 0.802    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00605  |
|    learning_rate          | 0.001    |
|    n_updates              | 89       |
|    policy_objective       | 0.0575   |
|    value_loss             | 0.000863 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 184000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 90     |
|    time_elapsed    | 18788  |
|    total_timesteps | 184320 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 185000   |
| train/                    |          |
|    explained_variance     | 0.676    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00514  |
|    learning_rate          | 0.001    |
|    n_updates              | 90       |
|    policy_objective       | 0.057    |
|    value_loss             | 0.000664 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 186000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 91     |
|    time_elapsed    | 18992  |
|    total_timesteps | 186368 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 187000   |
| train/                    |          |
|    explained_variance     | 0.606    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00501  |
|    learning_rate          | 0.001    |
|    n_updates              | 91       |
|    policy_objective       | 0.0565   |
|    value_loss             | 0.000636 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 188000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 92     |
|    time_elapsed    | 19196  |
|    total_timesteps | 188416 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 189000   |
| train/                    |          |
|    explained_variance     | 0.812    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00618  |
|    learning_rate          | 0.001    |
|    n_updates              | 92       |
|    policy_objective       | 0.0506   |
|    value_loss             | 0.000534 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 190000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 93     |
|    time_elapsed    | 19401  |
|    total_timesteps | 190464 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 191000   |
| train/                    |          |
|    explained_variance     | 0.58     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0055   |
|    learning_rate          | 0.001    |
|    n_updates              | 93       |
|    policy_objective       | 0.0608   |
|    value_loss             | 0.000731 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 192000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 94     |
|    time_elapsed    | 19605  |
|    total_timesteps | 192512 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 193000   |
| train/                    |          |
|    explained_variance     | 0.805    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00826  |
|    learning_rate          | 0.001    |
|    n_updates              | 94       |
|    policy_objective       | 0.0528   |
|    value_loss             | 0.000719 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 194000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 95     |
|    time_elapsed    | 19809  |
|    total_timesteps | 194560 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 195000   |
| train/                    |          |
|    explained_variance     | 0.644    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00502  |
|    learning_rate          | 0.001    |
|    n_updates              | 95       |
|    policy_objective       | 0.0605   |
|    value_loss             | 0.000813 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 196000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 96     |
|    time_elapsed    | 20014  |
|    total_timesteps | 196608 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 197000   |
| train/                    |          |
|    explained_variance     | 0.599    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00453  |
|    learning_rate          | 0.001    |
|    n_updates              | 96       |
|    policy_objective       | 0.0543   |
|    value_loss             | 0.000956 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 198000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 97     |
|    time_elapsed    | 20218  |
|    total_timesteps | 198656 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 199000   |
| train/                    |          |
|    explained_variance     | 0.74     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0044   |
|    learning_rate          | 0.001    |
|    n_updates              | 97       |
|    policy_objective       | 0.0635   |
|    value_loss             | 0.00055  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 200000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 98     |
|    time_elapsed    | 20422  |
|    total_timesteps | 200704 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 201000   |
| train/                    |          |
|    explained_variance     | 0.594    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00537  |
|    learning_rate          | 0.001    |
|    n_updates              | 98       |
|    policy_objective       | 0.0529   |
|    value_loss             | 0.000592 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 202000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 99     |
|    time_elapsed    | 20627  |
|    total_timesteps | 202752 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 203000   |
| train/                    |          |
|    explained_variance     | 0.412    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 99       |
|    policy_objective       | 0.0613   |
|    value_loss             | 0.000663 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 204000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 100    |
|    time_elapsed    | 20831  |
|    total_timesteps | 204800 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 205000   |
| train/                    |          |
|    explained_variance     | 0.554    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00529  |
|    learning_rate          | 0.001    |
|    n_updates              | 100      |
|    policy_objective       | 0.0609   |
|    value_loss             | 0.000663 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 206000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 101    |
|    time_elapsed    | 21035  |
|    total_timesteps | 206848 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 207000   |
| train/                    |          |
|    explained_variance     | 0.634    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00555  |
|    learning_rate          | 0.001    |
|    n_updates              | 101      |
|    policy_objective       | 0.0552   |
|    value_loss             | 0.000412 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 208000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 102    |
|    time_elapsed    | 21240  |
|    total_timesteps | 208896 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 209000   |
| train/                    |          |
|    explained_variance     | 0.525    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00533  |
|    learning_rate          | 0.001    |
|    n_updates              | 102      |
|    policy_objective       | 0.0528   |
|    value_loss             | 0.00069  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 210000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 103    |
|    time_elapsed    | 21444  |
|    total_timesteps | 210944 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 211000   |
| train/                    |          |
|    explained_variance     | 0.612    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00575  |
|    learning_rate          | 0.001    |
|    n_updates              | 103      |
|    policy_objective       | 0.0589   |
|    value_loss             | 0.000549 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 212000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 104    |
|    time_elapsed    | 21648  |
|    total_timesteps | 212992 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 213000   |
| train/                    |          |
|    explained_variance     | 0.671    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00492  |
|    learning_rate          | 0.001    |
|    n_updates              | 104      |
|    policy_objective       | 0.0584   |
|    value_loss             | 0.000491 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 214000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 215000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 105    |
|    time_elapsed    | 21953  |
|    total_timesteps | 215040 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 216000   |
| train/                    |          |
|    explained_variance     | 0.565    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00343  |
|    learning_rate          | 0.001    |
|    n_updates              | 105      |
|    policy_objective       | 0.0699   |
|    value_loss             | 0.000638 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 217000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 106    |
|    time_elapsed    | 22157  |
|    total_timesteps | 217088 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 218000   |
| train/                    |          |
|    explained_variance     | 0.749    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00575  |
|    learning_rate          | 0.001    |
|    n_updates              | 106      |
|    policy_objective       | 0.0479   |
|    value_loss             | 0.000862 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 219000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 107    |
|    time_elapsed    | 22361  |
|    total_timesteps | 219136 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 220000   |
| train/                    |          |
|    explained_variance     | 0.644    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00518  |
|    learning_rate          | 0.001    |
|    n_updates              | 107      |
|    policy_objective       | 0.0583   |
|    value_loss             | 0.000621 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 221000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 108    |
|    time_elapsed    | 22565  |
|    total_timesteps | 221184 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 222000   |
| train/                    |          |
|    explained_variance     | 0.519    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00534  |
|    learning_rate          | 0.001    |
|    n_updates              | 108      |
|    policy_objective       | 0.0596   |
|    value_loss             | 0.000685 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 223000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 109    |
|    time_elapsed    | 22770  |
|    total_timesteps | 223232 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 224000   |
| train/                    |          |
|    explained_variance     | 0.451    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00488  |
|    learning_rate          | 0.001    |
|    n_updates              | 109      |
|    policy_objective       | 0.0602   |
|    value_loss             | 0.000947 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 225000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 110    |
|    time_elapsed    | 22974  |
|    total_timesteps | 225280 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 226000   |
| train/                    |          |
|    explained_variance     | 0.236    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00561  |
|    learning_rate          | 0.001    |
|    n_updates              | 110      |
|    policy_objective       | 0.059    |
|    value_loss             | 0.000679 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 227000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 111    |
|    time_elapsed    | 23178  |
|    total_timesteps | 227328 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 228000   |
| train/                    |          |
|    explained_variance     | 0.198    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00594  |
|    learning_rate          | 0.001    |
|    n_updates              | 111      |
|    policy_objective       | 0.0547   |
|    value_loss             | 0.000854 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 229000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 112    |
|    time_elapsed    | 23383  |
|    total_timesteps | 229376 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 230000   |
| train/                    |          |
|    explained_variance     | 0.595    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00533  |
|    learning_rate          | 0.001    |
|    n_updates              | 112      |
|    policy_objective       | 0.0565   |
|    value_loss             | 0.00057  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 231000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 113    |
|    time_elapsed    | 23587  |
|    total_timesteps | 231424 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 232000   |
| train/                    |          |
|    explained_variance     | 0.316    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00513  |
|    learning_rate          | 0.001    |
|    n_updates              | 113      |
|    policy_objective       | 0.0538   |
|    value_loss             | 0.000684 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 233000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 114    |
|    time_elapsed    | 23791  |
|    total_timesteps | 233472 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 234000   |
| train/                    |          |
|    explained_variance     | 0.481    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0054   |
|    learning_rate          | 0.001    |
|    n_updates              | 114      |
|    policy_objective       | 0.0519   |
|    value_loss             | 0.00057  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 235000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 115    |
|    time_elapsed    | 23996  |
|    total_timesteps | 235520 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 236000   |
| train/                    |          |
|    explained_variance     | 0.632    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 115      |
|    policy_objective       | 0.059    |
|    value_loss             | 0.000609 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 237000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 116    |
|    time_elapsed    | 24200  |
|    total_timesteps | 237568 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 238000   |
| train/                    |          |
|    explained_variance     | 0.548    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00495  |
|    learning_rate          | 0.001    |
|    n_updates              | 116      |
|    policy_objective       | 0.0615   |
|    value_loss             | 0.000835 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 239000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 117    |
|    time_elapsed    | 24404  |
|    total_timesteps | 239616 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 240000   |
| train/                    |          |
|    explained_variance     | 0.299    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00596  |
|    learning_rate          | 0.001    |
|    n_updates              | 117      |
|    policy_objective       | 0.0557   |
|    value_loss             | 0.000777 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 241000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 118    |
|    time_elapsed    | 24609  |
|    total_timesteps | 241664 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 242000   |
| train/                    |          |
|    explained_variance     | 0.29     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00559  |
|    learning_rate          | 0.001    |
|    n_updates              | 118      |
|    policy_objective       | 0.0541   |
|    value_loss             | 0.000766 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 243000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 119    |
|    time_elapsed    | 24813  |
|    total_timesteps | 243712 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 244000   |
| train/                    |          |
|    explained_variance     | 0.22     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00529  |
|    learning_rate          | 0.001    |
|    n_updates              | 119      |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.000895 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 245000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 120    |
|    time_elapsed    | 25017  |
|    total_timesteps | 245760 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 246000   |
| train/                    |          |
|    explained_variance     | 0.282    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0061   |
|    learning_rate          | 0.001    |
|    n_updates              | 120      |
|    policy_objective       | 0.0528   |
|    value_loss             | 0.00103  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 247000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 121    |
|    time_elapsed    | 25222  |
|    total_timesteps | 247808 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 248000   |
| train/                    |          |
|    explained_variance     | 0.518    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0051   |
|    learning_rate          | 0.001    |
|    n_updates              | 121      |
|    policy_objective       | 0.0567   |
|    value_loss             | 0.000779 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 249000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 122    |
|    time_elapsed    | 25426  |
|    total_timesteps | 249856 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 250000   |
| train/                    |          |
|    explained_variance     | 0.149    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0057   |
|    learning_rate          | 0.001    |
|    n_updates              | 122      |
|    policy_objective       | 0.0496   |
|    value_loss             | 0.000939 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 251000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 123    |
|    time_elapsed    | 25630  |
|    total_timesteps | 251904 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 252000   |
| train/                    |          |
|    explained_variance     | 0.243    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00536  |
|    learning_rate          | 0.001    |
|    n_updates              | 123      |
|    policy_objective       | 0.056    |
|    value_loss             | 0.000901 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 253000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 124    |
|    time_elapsed    | 25835  |
|    total_timesteps | 253952 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 254000   |
| train/                    |          |
|    explained_variance     | 0.102    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00531  |
|    learning_rate          | 0.001    |
|    n_updates              | 124      |
|    policy_objective       | 0.0556   |
|    value_loss             | 0.000745 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 255000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 256000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 125    |
|    time_elapsed    | 26139  |
|    total_timesteps | 256000 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 257000   |
| train/                    |          |
|    explained_variance     | 0.211    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00461  |
|    learning_rate          | 0.001    |
|    n_updates              | 125      |
|    policy_objective       | 0.0559   |
|    value_loss             | 0.000717 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 258000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 126    |
|    time_elapsed    | 26343  |
|    total_timesteps | 258048 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 259000   |
| train/                    |          |
|    explained_variance     | 0.198    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00572  |
|    learning_rate          | 0.001    |
|    n_updates              | 126      |
|    policy_objective       | 0.0521   |
|    value_loss             | 0.000882 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 260000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 127    |
|    time_elapsed    | 26548  |
|    total_timesteps | 260096 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 261000   |
| train/                    |          |
|    explained_variance     | 0.424    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 127      |
|    policy_objective       | 0.0489   |
|    value_loss             | 0.000746 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 262000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 128    |
|    time_elapsed    | 26752  |
|    total_timesteps | 262144 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 263000   |
| train/                    |          |
|    explained_variance     | 0.39     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00592  |
|    learning_rate          | 0.001    |
|    n_updates              | 128      |
|    policy_objective       | 0.0617   |
|    value_loss             | 0.000956 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 264000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 129    |
|    time_elapsed    | 26956  |
|    total_timesteps | 264192 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 265000   |
| train/                    |          |
|    explained_variance     | 0.558    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00545  |
|    learning_rate          | 0.001    |
|    n_updates              | 129      |
|    policy_objective       | 0.0594   |
|    value_loss             | 0.000889 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 266000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 130    |
|    time_elapsed    | 27160  |
|    total_timesteps | 266240 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 267000   |
| train/                    |          |
|    explained_variance     | 0.462    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00558  |
|    learning_rate          | 0.001    |
|    n_updates              | 130      |
|    policy_objective       | 0.0577   |
|    value_loss             | 0.000951 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 268000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 131    |
|    time_elapsed    | 27365  |
|    total_timesteps | 268288 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 269000   |
| train/                    |          |
|    explained_variance     | 0.546    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0059   |
|    learning_rate          | 0.001    |
|    n_updates              | 131      |
|    policy_objective       | 0.0547   |
|    value_loss             | 0.001    |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 270000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 132    |
|    time_elapsed    | 27569  |
|    total_timesteps | 270336 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 271000   |
| train/                    |          |
|    explained_variance     | 0.437    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00539  |
|    learning_rate          | 0.001    |
|    n_updates              | 132      |
|    policy_objective       | 0.0514   |
|    value_loss             | 0.00104  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 272000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 133    |
|    time_elapsed    | 27773  |
|    total_timesteps | 272384 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 273000   |
| train/                    |          |
|    explained_variance     | 0.478    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00423  |
|    learning_rate          | 0.001    |
|    n_updates              | 133      |
|    policy_objective       | 0.0811   |
|    value_loss             | 0.00079  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 274000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 134    |
|    time_elapsed    | 27978  |
|    total_timesteps | 274432 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 275000   |
| train/                    |          |
|    explained_variance     | 0.424    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 134      |
|    policy_objective       | 0.057    |
|    value_loss             | 0.000829 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 276000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 135    |
|    time_elapsed    | 28182  |
|    total_timesteps | 276480 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 277000   |
| train/                    |          |
|    explained_variance     | 0.329    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00464  |
|    learning_rate          | 0.001    |
|    n_updates              | 135      |
|    policy_objective       | 0.0568   |
|    value_loss             | 0.000843 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 278000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 136    |
|    time_elapsed    | 28386  |
|    total_timesteps | 278528 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 279000   |
| train/                    |          |
|    explained_variance     | 0.27     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00496  |
|    learning_rate          | 0.001    |
|    n_updates              | 136      |
|    policy_objective       | 0.0632   |
|    value_loss             | 0.000936 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 280000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 137    |
|    time_elapsed    | 28591  |
|    total_timesteps | 280576 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 281000   |
| train/                    |          |
|    explained_variance     | 0.496    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00617  |
|    learning_rate          | 0.001    |
|    n_updates              | 137      |
|    policy_objective       | 0.0531   |
|    value_loss             | 0.000948 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 282000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 138    |
|    time_elapsed    | 28795  |
|    total_timesteps | 282624 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 283000   |
| train/                    |          |
|    explained_variance     | 0.569    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00596  |
|    learning_rate          | 0.001    |
|    n_updates              | 138      |
|    policy_objective       | 0.0585   |
|    value_loss             | 0.000739 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 284000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 139    |
|    time_elapsed    | 28999  |
|    total_timesteps | 284672 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 285000   |
| train/                    |          |
|    explained_variance     | 0.429    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00621  |
|    learning_rate          | 0.001    |
|    n_updates              | 139      |
|    policy_objective       | 0.0526   |
|    value_loss             | 0.00107  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 286000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 140    |
|    time_elapsed    | 29204  |
|    total_timesteps | 286720 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 287000   |
| train/                    |          |
|    explained_variance     | 0.523    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0061   |
|    learning_rate          | 0.001    |
|    n_updates              | 140      |
|    policy_objective       | 0.0616   |
|    value_loss             | 0.000935 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 288000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 141    |
|    time_elapsed    | 29408  |
|    total_timesteps | 288768 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 289000   |
| train/                    |          |
|    explained_variance     | 0.525    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00535  |
|    learning_rate          | 0.001    |
|    n_updates              | 141      |
|    policy_objective       | 0.0536   |
|    value_loss             | 0.00131  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 290000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 142    |
|    time_elapsed    | 29612  |
|    total_timesteps | 290816 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 291000   |
| train/                    |          |
|    explained_variance     | 0.112    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00535  |
|    learning_rate          | 0.001    |
|    n_updates              | 142      |
|    policy_objective       | 0.0736   |
|    value_loss             | 0.000895 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 292000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 143    |
|    time_elapsed    | 29817  |
|    total_timesteps | 292864 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 293000   |
| train/                    |          |
|    explained_variance     | 0.337    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00531  |
|    learning_rate          | 0.001    |
|    n_updates              | 143      |
|    policy_objective       | 0.0664   |
|    value_loss             | 0.001    |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 294000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 144    |
|    time_elapsed    | 30021  |
|    total_timesteps | 294912 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 295000   |
| train/                    |          |
|    explained_variance     | 0.195    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00525  |
|    learning_rate          | 0.001    |
|    n_updates              | 144      |
|    policy_objective       | 0.0582   |
|    value_loss             | 0.00121  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 296000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 145    |
|    time_elapsed    | 30225  |
|    total_timesteps | 296960 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 297000   |
| train/                    |          |
|    explained_variance     | 0.593    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00532  |
|    learning_rate          | 0.001    |
|    n_updates              | 145      |
|    policy_objective       | 0.06     |
|    value_loss             | 0.00107  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 298000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 299000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 146    |
|    time_elapsed    | 30530  |
|    total_timesteps | 299008 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 300000   |
| train/                    |          |
|    explained_variance     | 0.371    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00581  |
|    learning_rate          | 0.001    |
|    n_updates              | 146      |
|    policy_objective       | 0.0566   |
|    value_loss             | 0.0011   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 301000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 147    |
|    time_elapsed    | 30734  |
|    total_timesteps | 301056 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 302000   |
| train/                    |          |
|    explained_variance     | 0.525    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00598  |
|    learning_rate          | 0.001    |
|    n_updates              | 147      |
|    policy_objective       | 0.0549   |
|    value_loss             | 0.00103  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 303000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 148    |
|    time_elapsed    | 30938  |
|    total_timesteps | 303104 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 304000   |
| train/                    |          |
|    explained_variance     | 0.254    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00534  |
|    learning_rate          | 0.001    |
|    n_updates              | 148      |
|    policy_objective       | 0.0529   |
|    value_loss             | 0.00126  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 305000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 149    |
|    time_elapsed    | 31142  |
|    total_timesteps | 305152 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 306000   |
| train/                    |          |
|    explained_variance     | 0.334    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00571  |
|    learning_rate          | 0.001    |
|    n_updates              | 149      |
|    policy_objective       | 0.0538   |
|    value_loss             | 0.00108  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 307000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 150    |
|    time_elapsed    | 31347  |
|    total_timesteps | 307200 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 308000   |
| train/                    |          |
|    explained_variance     | 0.195    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00475  |
|    learning_rate          | 0.001    |
|    n_updates              | 150      |
|    policy_objective       | 0.0616   |
|    value_loss             | 0.000974 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 309000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 151    |
|    time_elapsed    | 31551  |
|    total_timesteps | 309248 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 310000   |
| train/                    |          |
|    explained_variance     | 0.414    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00508  |
|    learning_rate          | 0.001    |
|    n_updates              | 151      |
|    policy_objective       | 0.0725   |
|    value_loss             | 0.00109  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 311000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 152    |
|    time_elapsed    | 31755  |
|    total_timesteps | 311296 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 312000   |
| train/                    |          |
|    explained_variance     | 0.574    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00596  |
|    learning_rate          | 0.001    |
|    n_updates              | 152      |
|    policy_objective       | 0.0582   |
|    value_loss             | 0.000961 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 313000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 153    |
|    time_elapsed    | 31960  |
|    total_timesteps | 313344 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 314000   |
| train/                    |          |
|    explained_variance     | 0.127    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00576  |
|    learning_rate          | 0.001    |
|    n_updates              | 153      |
|    policy_objective       | 0.0543   |
|    value_loss             | 0.000986 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 315000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 154    |
|    time_elapsed    | 32164  |
|    total_timesteps | 315392 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 316000   |
| train/                    |          |
|    explained_variance     | 0.29     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00533  |
|    learning_rate          | 0.001    |
|    n_updates              | 154      |
|    policy_objective       | 0.0577   |
|    value_loss             | 0.00111  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 317000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 155    |
|    time_elapsed    | 32368  |
|    total_timesteps | 317440 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 318000   |
| train/                    |          |
|    explained_variance     | 0.503    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00524  |
|    learning_rate          | 0.001    |
|    n_updates              | 155      |
|    policy_objective       | 0.0568   |
|    value_loss             | 0.000998 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 319000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 156    |
|    time_elapsed    | 32573  |
|    total_timesteps | 319488 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 320000   |
| train/                    |          |
|    explained_variance     | 0.472    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00511  |
|    learning_rate          | 0.001    |
|    n_updates              | 156      |
|    policy_objective       | 0.0509   |
|    value_loss             | 0.00112  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 321000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 157    |
|    time_elapsed    | 32777  |
|    total_timesteps | 321536 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 322000   |
| train/                    |          |
|    explained_variance     | 0.53     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00775  |
|    learning_rate          | 0.001    |
|    n_updates              | 157      |
|    policy_objective       | 0.0499   |
|    value_loss             | 0.0011   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 323000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 158    |
|    time_elapsed    | 32981  |
|    total_timesteps | 323584 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 324000   |
| train/                    |          |
|    explained_variance     | 0.558    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00646  |
|    learning_rate          | 0.001    |
|    n_updates              | 158      |
|    policy_objective       | 0.057    |
|    value_loss             | 0.00132  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 325000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 159    |
|    time_elapsed    | 33186  |
|    total_timesteps | 325632 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 326000   |
| train/                    |          |
|    explained_variance     | 0.493    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00499  |
|    learning_rate          | 0.001    |
|    n_updates              | 159      |
|    policy_objective       | 0.0551   |
|    value_loss             | 0.00105  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 327000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 160    |
|    time_elapsed    | 33390  |
|    total_timesteps | 327680 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 328000   |
| train/                    |          |
|    explained_variance     | 0.472    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00551  |
|    learning_rate          | 0.001    |
|    n_updates              | 160      |
|    policy_objective       | 0.0532   |
|    value_loss             | 0.00109  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 329000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 161    |
|    time_elapsed    | 33594  |
|    total_timesteps | 329728 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 330000   |
| train/                    |          |
|    explained_variance     | 0.662    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00508  |
|    learning_rate          | 0.001    |
|    n_updates              | 161      |
|    policy_objective       | 0.0612   |
|    value_loss             | 0.000991 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 331000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 162    |
|    time_elapsed    | 33799  |
|    total_timesteps | 331776 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 332000   |
| train/                    |          |
|    explained_variance     | 0.596    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00565  |
|    learning_rate          | 0.001    |
|    n_updates              | 162      |
|    policy_objective       | 0.0552   |
|    value_loss             | 0.000989 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 333000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 163    |
|    time_elapsed    | 34003  |
|    total_timesteps | 333824 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 334000   |
| train/                    |          |
|    explained_variance     | 0.584    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00543  |
|    learning_rate          | 0.001    |
|    n_updates              | 163      |
|    policy_objective       | 0.0591   |
|    value_loss             | 0.00133  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 335000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 164    |
|    time_elapsed    | 34208  |
|    total_timesteps | 335872 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 336000   |
| train/                    |          |
|    explained_variance     | 0.554    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00536  |
|    learning_rate          | 0.001    |
|    n_updates              | 164      |
|    policy_objective       | 0.0555   |
|    value_loss             | 0.00149  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 337000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 165    |
|    time_elapsed    | 34412  |
|    total_timesteps | 337920 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 338000   |
| train/                    |          |
|    explained_variance     | 0.671    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00518  |
|    learning_rate          | 0.001    |
|    n_updates              | 165      |
|    policy_objective       | 0.0605   |
|    value_loss             | 0.00132  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 339000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 166    |
|    time_elapsed    | 34616  |
|    total_timesteps | 339968 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 340000   |
| train/                    |          |
|    explained_variance     | 0.64     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00579  |
|    learning_rate          | 0.001    |
|    n_updates              | 166      |
|    policy_objective       | 0.0663   |
|    value_loss             | 0.00126  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 341000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 342000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 167    |
|    time_elapsed    | 34921  |
|    total_timesteps | 342016 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 343000   |
| train/                    |          |
|    explained_variance     | 0.585    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00645  |
|    learning_rate          | 0.001    |
|    n_updates              | 167      |
|    policy_objective       | 0.058    |
|    value_loss             | 0.00145  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 344000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 168    |
|    time_elapsed    | 35125  |
|    total_timesteps | 344064 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 345000   |
| train/                    |          |
|    explained_variance     | 0.524    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00742  |
|    learning_rate          | 0.001    |
|    n_updates              | 168      |
|    policy_objective       | 0.052    |
|    value_loss             | 0.00132  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 346000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 169    |
|    time_elapsed    | 35329  |
|    total_timesteps | 346112 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 347000   |
| train/                    |          |
|    explained_variance     | 0.629    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00556  |
|    learning_rate          | 0.001    |
|    n_updates              | 169      |
|    policy_objective       | 0.0548   |
|    value_loss             | 0.0017   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 348000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 170    |
|    time_elapsed    | 35534  |
|    total_timesteps | 348160 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 349000   |
| train/                    |          |
|    explained_variance     | 0.458    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00608  |
|    learning_rate          | 0.001    |
|    n_updates              | 170      |
|    policy_objective       | 0.0579   |
|    value_loss             | 0.00113  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 350000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 171    |
|    time_elapsed    | 35738  |
|    total_timesteps | 350208 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 351000   |
| train/                    |          |
|    explained_variance     | 0.629    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0062   |
|    learning_rate          | 0.001    |
|    n_updates              | 171      |
|    policy_objective       | 0.0528   |
|    value_loss             | 0.00186  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 352000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 172    |
|    time_elapsed    | 35942  |
|    total_timesteps | 352256 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 353000   |
| train/                    |          |
|    explained_variance     | 0.739    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00785  |
|    learning_rate          | 0.001    |
|    n_updates              | 172      |
|    policy_objective       | 0.0468   |
|    value_loss             | 0.00138  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 354000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 173    |
|    time_elapsed    | 36146  |
|    total_timesteps | 354304 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 355000   |
| train/                    |          |
|    explained_variance     | 0.526    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0062   |
|    learning_rate          | 0.001    |
|    n_updates              | 173      |
|    policy_objective       | 0.0575   |
|    value_loss             | 0.00147  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 356000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 174    |
|    time_elapsed    | 36351  |
|    total_timesteps | 356352 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 357000   |
| train/                    |          |
|    explained_variance     | 0.55     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00651  |
|    learning_rate          | 0.001    |
|    n_updates              | 174      |
|    policy_objective       | 0.0451   |
|    value_loss             | 0.00151  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 358000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 175    |
|    time_elapsed    | 36555  |
|    total_timesteps | 358400 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 359000   |
| train/                    |          |
|    explained_variance     | 0.524    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00643  |
|    learning_rate          | 0.001    |
|    n_updates              | 175      |
|    policy_objective       | 0.0603   |
|    value_loss             | 0.00168  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 360000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 176    |
|    time_elapsed    | 36760  |
|    total_timesteps | 360448 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 361000   |
| train/                    |          |
|    explained_variance     | 0.638    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00715  |
|    learning_rate          | 0.001    |
|    n_updates              | 176      |
|    policy_objective       | 0.0575   |
|    value_loss             | 0.00151  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 362000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 177    |
|    time_elapsed    | 36964  |
|    total_timesteps | 362496 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 363000   |
| train/                    |          |
|    explained_variance     | 0.658    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00661  |
|    learning_rate          | 0.001    |
|    n_updates              | 177      |
|    policy_objective       | 0.0527   |
|    value_loss             | 0.00166  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 364000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 178    |
|    time_elapsed    | 37168  |
|    total_timesteps | 364544 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 365000   |
| train/                    |          |
|    explained_variance     | 0.575    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0062   |
|    learning_rate          | 0.001    |
|    n_updates              | 178      |
|    policy_objective       | 0.0596   |
|    value_loss             | 0.00129  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 366000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 179    |
|    time_elapsed    | 37373  |
|    total_timesteps | 366592 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 367000   |
| train/                    |          |
|    explained_variance     | 0.599    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00593  |
|    learning_rate          | 0.001    |
|    n_updates              | 179      |
|    policy_objective       | 0.0543   |
|    value_loss             | 0.00152  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 368000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 180    |
|    time_elapsed    | 37577  |
|    total_timesteps | 368640 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 369000   |
| train/                    |          |
|    explained_variance     | 0.5      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00596  |
|    learning_rate          | 0.001    |
|    n_updates              | 180      |
|    policy_objective       | 0.0469   |
|    value_loss             | 0.00174  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 370000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 181    |
|    time_elapsed    | 37781  |
|    total_timesteps | 370688 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 371000   |
| train/                    |          |
|    explained_variance     | 0.677    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00638  |
|    learning_rate          | 0.001    |
|    n_updates              | 181      |
|    policy_objective       | 0.0493   |
|    value_loss             | 0.00159  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 372000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 182    |
|    time_elapsed    | 37986  |
|    total_timesteps | 372736 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 373000   |
| train/                    |          |
|    explained_variance     | 0.606    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00589  |
|    learning_rate          | 0.001    |
|    n_updates              | 182      |
|    policy_objective       | 0.0575   |
|    value_loss             | 0.0012   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 374000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 183    |
|    time_elapsed    | 38190  |
|    total_timesteps | 374784 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 375000   |
| train/                    |          |
|    explained_variance     | 0.535    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00616  |
|    learning_rate          | 0.001    |
|    n_updates              | 183      |
|    policy_objective       | 0.0546   |
|    value_loss             | 0.00149  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 376000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 184    |
|    time_elapsed    | 38394  |
|    total_timesteps | 376832 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 377000   |
| train/                    |          |
|    explained_variance     | 0.593    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00674  |
|    learning_rate          | 0.001    |
|    n_updates              | 184      |
|    policy_objective       | 0.0604   |
|    value_loss             | 0.00151  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 378000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 185    |
|    time_elapsed    | 38599  |
|    total_timesteps | 378880 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 379000   |
| train/                    |          |
|    explained_variance     | 0.496    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00583  |
|    learning_rate          | 0.001    |
|    n_updates              | 185      |
|    policy_objective       | 0.0524   |
|    value_loss             | 0.00151  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 380000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 186    |
|    time_elapsed    | 38803  |
|    total_timesteps | 380928 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 381000   |
| train/                    |          |
|    explained_variance     | 0.601    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00589  |
|    learning_rate          | 0.001    |
|    n_updates              | 186      |
|    policy_objective       | 0.0488   |
|    value_loss             | 0.00146  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 382000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 187    |
|    time_elapsed    | 39007  |
|    total_timesteps | 382976 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 383000   |
| train/                    |          |
|    explained_variance     | 0.401    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00614  |
|    learning_rate          | 0.001    |
|    n_updates              | 187      |
|    policy_objective       | 0.0583   |
|    value_loss             | 0.00203  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 384000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 385000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 188    |
|    time_elapsed    | 39312  |
|    total_timesteps | 385024 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 386000   |
| train/                    |          |
|    explained_variance     | 0.511    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00628  |
|    learning_rate          | 0.001    |
|    n_updates              | 188      |
|    policy_objective       | 0.0517   |
|    value_loss             | 0.00158  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 387000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 189    |
|    time_elapsed    | 39516  |
|    total_timesteps | 387072 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 388000   |
| train/                    |          |
|    explained_variance     | 0.512    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00687  |
|    learning_rate          | 0.001    |
|    n_updates              | 189      |
|    policy_objective       | 0.0645   |
|    value_loss             | 0.00117  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 389000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 190    |
|    time_elapsed    | 39720  |
|    total_timesteps | 389120 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 390000   |
| train/                    |          |
|    explained_variance     | 0.365    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00594  |
|    learning_rate          | 0.001    |
|    n_updates              | 190      |
|    policy_objective       | 0.0508   |
|    value_loss             | 0.00141  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 391000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 191    |
|    time_elapsed    | 39925  |
|    total_timesteps | 391168 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 392000   |
| train/                    |          |
|    explained_variance     | 0.225    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00649  |
|    learning_rate          | 0.001    |
|    n_updates              | 191      |
|    policy_objective       | 0.053    |
|    value_loss             | 0.00159  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 393000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 192    |
|    time_elapsed    | 40129  |
|    total_timesteps | 393216 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 394000   |
| train/                    |          |
|    explained_variance     | 0.294    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0064   |
|    learning_rate          | 0.001    |
|    n_updates              | 192      |
|    policy_objective       | 0.0553   |
|    value_loss             | 0.00125  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 395000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 193    |
|    time_elapsed    | 40333  |
|    total_timesteps | 395264 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 396000   |
| train/                    |          |
|    explained_variance     | 0.443    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00642  |
|    learning_rate          | 0.001    |
|    n_updates              | 193      |
|    policy_objective       | 0.0591   |
|    value_loss             | 0.0019   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 397000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 194    |
|    time_elapsed    | 40538  |
|    total_timesteps | 397312 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 398000   |
| train/                    |          |
|    explained_variance     | 0.63     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00493  |
|    learning_rate          | 0.001    |
|    n_updates              | 194      |
|    policy_objective       | 0.0607   |
|    value_loss             | 0.00174  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 399000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 195    |
|    time_elapsed    | 40742  |
|    total_timesteps | 399360 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 400000   |
| train/                    |          |
|    explained_variance     | 0.627    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0059   |
|    learning_rate          | 0.001    |
|    n_updates              | 195      |
|    policy_objective       | 0.0529   |
|    value_loss             | 0.00159  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 401000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 196    |
|    time_elapsed    | 40946  |
|    total_timesteps | 401408 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 402000   |
| train/                    |          |
|    explained_variance     | 0.51     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00622  |
|    learning_rate          | 0.001    |
|    n_updates              | 196      |
|    policy_objective       | 0.0512   |
|    value_loss             | 0.00158  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 403000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 197    |
|    time_elapsed    | 41151  |
|    total_timesteps | 403456 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 404000   |
| train/                    |          |
|    explained_variance     | 0.709    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 197      |
|    policy_objective       | 0.045    |
|    value_loss             | 0.00184  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 405000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 198    |
|    time_elapsed    | 41355  |
|    total_timesteps | 405504 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.6      |
| time/                     |          |
|    total_timesteps        | 406000   |
| train/                    |          |
|    explained_variance     | 0.536    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00671  |
|    learning_rate          | 0.001    |
|    n_updates              | 198      |
|    policy_objective       | 0.0501   |
|    value_loss             | 0.00231  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 407000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 199    |
|    time_elapsed    | 41559  |
|    total_timesteps | 407552 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 408000   |
| train/                    |          |
|    explained_variance     | 0.575    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00687  |
|    learning_rate          | 0.001    |
|    n_updates              | 199      |
|    policy_objective       | 0.0515   |
|    value_loss             | 0.00245  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 409000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 200    |
|    time_elapsed    | 41764  |
|    total_timesteps | 409600 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.6      |
| time/                     |          |
|    total_timesteps        | 410000   |
| train/                    |          |
|    explained_variance     | 0.6      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00584  |
|    learning_rate          | 0.001    |
|    n_updates              | 200      |
|    policy_objective       | 0.0532   |
|    value_loss             | 0.00208  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 411000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 201    |
|    time_elapsed    | 41968  |
|    total_timesteps | 411648 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.6      |
| time/                     |          |
|    total_timesteps        | 412000   |
| train/                    |          |
|    explained_variance     | 0.516    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00579  |
|    learning_rate          | 0.001    |
|    n_updates              | 201      |
|    policy_objective       | 0.0495   |
|    value_loss             | 0.00209  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 413000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 202    |
|    time_elapsed    | 42172  |
|    total_timesteps | 413696 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.6      |
| time/                     |          |
|    total_timesteps        | 414000   |
| train/                    |          |
|    explained_variance     | 0.627    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.006    |
|    learning_rate          | 0.001    |
|    n_updates              | 202      |
|    policy_objective       | 0.0539   |
|    value_loss             | 0.00233  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 415000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 203    |
|    time_elapsed    | 42377  |
|    total_timesteps | 415744 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 416000   |
| train/                    |          |
|    explained_variance     | 0.577    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00835  |
|    learning_rate          | 0.001    |
|    n_updates              | 203      |
|    policy_objective       | 0.0525   |
|    value_loss             | 0.00253  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 417000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 204    |
|    time_elapsed    | 42581  |
|    total_timesteps | 417792 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 418000   |
| train/                    |          |
|    explained_variance     | 0.502    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00676  |
|    learning_rate          | 0.001    |
|    n_updates              | 204      |
|    policy_objective       | 0.0499   |
|    value_loss             | 0.00223  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 419000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 205    |
|    time_elapsed    | 42785  |
|    total_timesteps | 419840 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 420000   |
| train/                    |          |
|    explained_variance     | 0.594    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00636  |
|    learning_rate          | 0.001    |
|    n_updates              | 205      |
|    policy_objective       | 0.0447   |
|    value_loss             | 0.00204  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 421000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 206    |
|    time_elapsed    | 42990  |
|    total_timesteps | 421888 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 422000   |
| train/                    |          |
|    explained_variance     | 0.512    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00604  |
|    learning_rate          | 0.001    |
|    n_updates              | 206      |
|    policy_objective       | 0.0521   |
|    value_loss             | 0.00227  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 423000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 207    |
|    time_elapsed    | 43194  |
|    total_timesteps | 423936 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 424000   |
| train/                    |          |
|    explained_variance     | 0.551    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00637  |
|    learning_rate          | 0.001    |
|    n_updates              | 207      |
|    policy_objective       | 0.0539   |
|    value_loss             | 0.00153  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 425000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 208    |
|    time_elapsed    | 43398  |
|    total_timesteps | 425984 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 426000   |
| train/                    |          |
|    explained_variance     | 0.262    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00545  |
|    learning_rate          | 0.001    |
|    n_updates              | 208      |
|    policy_objective       | 0.0637   |
|    value_loss             | 0.00192  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 427000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 428000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 209    |
|    time_elapsed    | 43703  |
|    total_timesteps | 428032 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 429000   |
| train/                    |          |
|    explained_variance     | 0.485    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0063   |
|    learning_rate          | 0.001    |
|    n_updates              | 209      |
|    policy_objective       | 0.0682   |
|    value_loss             | 0.00205  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 430000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 210    |
|    time_elapsed    | 43907  |
|    total_timesteps | 430080 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 431000   |
| train/                    |          |
|    explained_variance     | 0.435    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00683  |
|    learning_rate          | 0.001    |
|    n_updates              | 210      |
|    policy_objective       | 0.0471   |
|    value_loss             | 0.00207  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 432000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 211    |
|    time_elapsed    | 44112  |
|    total_timesteps | 432128 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 433000   |
| train/                    |          |
|    explained_variance     | 0.469    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00706  |
|    learning_rate          | 0.001    |
|    n_updates              | 211      |
|    policy_objective       | 0.0442   |
|    value_loss             | 0.00211  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 434000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 212    |
|    time_elapsed    | 44316  |
|    total_timesteps | 434176 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 435000   |
| train/                    |          |
|    explained_variance     | 0.559    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00747  |
|    learning_rate          | 0.001    |
|    n_updates              | 212      |
|    policy_objective       | 0.0493   |
|    value_loss             | 0.0017   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 436000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 213    |
|    time_elapsed    | 44520  |
|    total_timesteps | 436224 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 437000   |
| train/                    |          |
|    explained_variance     | 0.458    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00633  |
|    learning_rate          | 0.001    |
|    n_updates              | 213      |
|    policy_objective       | 0.0484   |
|    value_loss             | 0.00202  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 438000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 214    |
|    time_elapsed    | 44725  |
|    total_timesteps | 438272 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 439000   |
| train/                    |          |
|    explained_variance     | 0.517    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0067   |
|    learning_rate          | 0.001    |
|    n_updates              | 214      |
|    policy_objective       | 0.0523   |
|    value_loss             | 0.00218  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 440000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 215    |
|    time_elapsed    | 44929  |
|    total_timesteps | 440320 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 441000   |
| train/                    |          |
|    explained_variance     | 0.563    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00792  |
|    learning_rate          | 0.001    |
|    n_updates              | 215      |
|    policy_objective       | 0.0522   |
|    value_loss             | 0.00217  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 442000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 216    |
|    time_elapsed    | 45133  |
|    total_timesteps | 442368 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 443000   |
| train/                    |          |
|    explained_variance     | 0.563    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00592  |
|    learning_rate          | 0.001    |
|    n_updates              | 216      |
|    policy_objective       | 0.0541   |
|    value_loss             | 0.00137  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 444000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 217    |
|    time_elapsed    | 45338  |
|    total_timesteps | 444416 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 445000   |
| train/                    |          |
|    explained_variance     | 0.725    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00788  |
|    learning_rate          | 0.001    |
|    n_updates              | 217      |
|    policy_objective       | 0.0408   |
|    value_loss             | 0.00315  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 446000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 218    |
|    time_elapsed    | 45542  |
|    total_timesteps | 446464 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 447000   |
| train/                    |          |
|    explained_variance     | 0.595    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00708  |
|    learning_rate          | 0.001    |
|    n_updates              | 218      |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.00189  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 448000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 219    |
|    time_elapsed    | 45746  |
|    total_timesteps | 448512 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 449000   |
| train/                    |          |
|    explained_variance     | 0.565    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00832  |
|    learning_rate          | 0.001    |
|    n_updates              | 219      |
|    policy_objective       | 0.0392   |
|    value_loss             | 0.00314  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 450000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 220    |
|    time_elapsed    | 45950  |
|    total_timesteps | 450560 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 451000   |
| train/                    |          |
|    explained_variance     | 0.663    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00734  |
|    learning_rate          | 0.001    |
|    n_updates              | 220      |
|    policy_objective       | 0.0495   |
|    value_loss             | 0.00287  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 452000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 221    |
|    time_elapsed    | 46155  |
|    total_timesteps | 452608 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 453000   |
| train/                    |          |
|    explained_variance     | 0.66     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00727  |
|    learning_rate          | 0.001    |
|    n_updates              | 221      |
|    policy_objective       | 0.0613   |
|    value_loss             | 0.00182  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 454000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 222    |
|    time_elapsed    | 46359  |
|    total_timesteps | 454656 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 455000   |
| train/                    |          |
|    explained_variance     | 0.562    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00522  |
|    learning_rate          | 0.001    |
|    n_updates              | 222      |
|    policy_objective       | 0.043    |
|    value_loss             | 0.00237  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 456000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 223    |
|    time_elapsed    | 46563  |
|    total_timesteps | 456704 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 457000   |
| train/                    |          |
|    explained_variance     | 0.503    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00778  |
|    learning_rate          | 0.001    |
|    n_updates              | 223      |
|    policy_objective       | 0.0493   |
|    value_loss             | 0.0021   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 458000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 224    |
|    time_elapsed    | 46768  |
|    total_timesteps | 458752 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 459000   |
| train/                    |          |
|    explained_variance     | 0.577    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00721  |
|    learning_rate          | 0.001    |
|    n_updates              | 224      |
|    policy_objective       | 0.048    |
|    value_loss             | 0.00222  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 460000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 225    |
|    time_elapsed    | 46972  |
|    total_timesteps | 460800 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 461000   |
| train/                    |          |
|    explained_variance     | 0.637    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00629  |
|    learning_rate          | 0.001    |
|    n_updates              | 225      |
|    policy_objective       | 0.0555   |
|    value_loss             | 0.00177  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 462000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 226    |
|    time_elapsed    | 47177  |
|    total_timesteps | 462848 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 463000   |
| train/                    |          |
|    explained_variance     | 0.554    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00728  |
|    learning_rate          | 0.001    |
|    n_updates              | 226      |
|    policy_objective       | 0.0445   |
|    value_loss             | 0.00268  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 464000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 227    |
|    time_elapsed    | 47381  |
|    total_timesteps | 464896 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 465000   |
| train/                    |          |
|    explained_variance     | 0.579    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00686  |
|    learning_rate          | 0.001    |
|    n_updates              | 227      |
|    policy_objective       | 0.037    |
|    value_loss             | 0.00247  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 466000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 228    |
|    time_elapsed    | 47585  |
|    total_timesteps | 466944 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 467000   |
| train/                    |          |
|    explained_variance     | 0.591    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00694  |
|    learning_rate          | 0.001    |
|    n_updates              | 228      |
|    policy_objective       | 0.0502   |
|    value_loss             | 0.00206  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 468000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 229    |
|    time_elapsed    | 47789  |
|    total_timesteps | 468992 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 469000   |
| train/                    |          |
|    explained_variance     | 0.616    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0064   |
|    learning_rate          | 0.001    |
|    n_updates              | 229      |
|    policy_objective       | 0.0586   |
|    value_loss             | 0.00198  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 470000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 471000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 230    |
|    time_elapsed    | 48094  |
|    total_timesteps | 471040 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 472000   |
| train/                    |          |
|    explained_variance     | 0.597    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00933  |
|    learning_rate          | 0.001    |
|    n_updates              | 230      |
|    policy_objective       | 0.0365   |
|    value_loss             | 0.00254  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 473000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 231    |
|    time_elapsed    | 48298  |
|    total_timesteps | 473088 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 474000   |
| train/                    |          |
|    explained_variance     | 0.432    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00733  |
|    learning_rate          | 0.001    |
|    n_updates              | 231      |
|    policy_objective       | 0.0585   |
|    value_loss             | 0.00242  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 475000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 232    |
|    time_elapsed    | 48503  |
|    total_timesteps | 475136 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 476000   |
| train/                    |          |
|    explained_variance     | 0.33     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00683  |
|    learning_rate          | 0.001    |
|    n_updates              | 232      |
|    policy_objective       | 0.0599   |
|    value_loss             | 0.00239  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 477000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 233    |
|    time_elapsed    | 48707  |
|    total_timesteps | 477184 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 478000   |
| train/                    |          |
|    explained_variance     | 0.551    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00766  |
|    learning_rate          | 0.001    |
|    n_updates              | 233      |
|    policy_objective       | 0.0469   |
|    value_loss             | 0.0027   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 479000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 234    |
|    time_elapsed    | 48911  |
|    total_timesteps | 479232 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 480000   |
| train/                    |          |
|    explained_variance     | 0.519    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00679  |
|    learning_rate          | 0.001    |
|    n_updates              | 234      |
|    policy_objective       | 0.0401   |
|    value_loss             | 0.00241  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 481000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 235    |
|    time_elapsed    | 49116  |
|    total_timesteps | 481280 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 482000   |
| train/                    |          |
|    explained_variance     | 0.648    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00574  |
|    learning_rate          | 0.001    |
|    n_updates              | 235      |
|    policy_objective       | 0.0529   |
|    value_loss             | 0.00204  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 483000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 236    |
|    time_elapsed    | 49320  |
|    total_timesteps | 483328 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 484000   |
| train/                    |          |
|    explained_variance     | -0.0599  |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0059   |
|    learning_rate          | 0.001    |
|    n_updates              | 236      |
|    policy_objective       | 0.0582   |
|    value_loss             | 0.00239  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 485000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 237    |
|    time_elapsed    | 49524  |
|    total_timesteps | 485376 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 486000   |
| train/                    |          |
|    explained_variance     | 0.32     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00852  |
|    learning_rate          | 0.001    |
|    n_updates              | 237      |
|    policy_objective       | 0.0469   |
|    value_loss             | 0.00196  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 487000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 238    |
|    time_elapsed    | 49729  |
|    total_timesteps | 487424 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 488000   |
| train/                    |          |
|    explained_variance     | 0.531    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00824  |
|    learning_rate          | 0.001    |
|    n_updates              | 238      |
|    policy_objective       | 0.0338   |
|    value_loss             | 0.00246  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 489000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 239    |
|    time_elapsed    | 49933  |
|    total_timesteps | 489472 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 490000   |
| train/                    |          |
|    explained_variance     | 0.558    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00662  |
|    learning_rate          | 0.001    |
|    n_updates              | 239      |
|    policy_objective       | 0.0559   |
|    value_loss             | 0.00193  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 491000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 240    |
|    time_elapsed    | 50137  |
|    total_timesteps | 491520 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 492000   |
| train/                    |          |
|    explained_variance     | 0.475    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00705  |
|    learning_rate          | 0.001    |
|    n_updates              | 240      |
|    policy_objective       | 0.0467   |
|    value_loss             | 0.00223  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 493000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 241    |
|    time_elapsed    | 50342  |
|    total_timesteps | 493568 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 494000   |
| train/                    |          |
|    explained_variance     | 0.456    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00907  |
|    learning_rate          | 0.001    |
|    n_updates              | 241      |
|    policy_objective       | 0.0385   |
|    value_loss             | 0.00241  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 495000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 242    |
|    time_elapsed    | 50546  |
|    total_timesteps | 495616 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 496000   |
| train/                    |          |
|    explained_variance     | 0.604    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00665  |
|    learning_rate          | 0.001    |
|    n_updates              | 242      |
|    policy_objective       | 0.0496   |
|    value_loss             | 0.00232  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 497000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 243    |
|    time_elapsed    | 50750  |
|    total_timesteps | 497664 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 498000   |
| train/                    |          |
|    explained_variance     | 0.638    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00742  |
|    learning_rate          | 0.001    |
|    n_updates              | 243      |
|    policy_objective       | 0.0443   |
|    value_loss             | 0.00253  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 499000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 244    |
|    time_elapsed    | 50955  |
|    total_timesteps | 499712 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 500000   |
| train/                    |          |
|    explained_variance     | 0.495    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00752  |
|    learning_rate          | 0.001    |
|    n_updates              | 244      |
|    policy_objective       | 0.0546   |
|    value_loss             | 0.00265  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 501000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 245    |
|    time_elapsed    | 51159  |
|    total_timesteps | 501760 |
-------------------------------
