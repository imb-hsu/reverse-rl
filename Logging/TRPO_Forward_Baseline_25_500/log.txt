Logging to ./Logging/TRPO_Forward_Baseline_25_500
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 1000     |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 2000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 1    |
|    time_elapsed    | 204  |
|    total_timesteps | 2048 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 3000     |
| train/                    |          |
|    explained_variance     | 0.654    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00546  |
|    learning_rate          | 0.001    |
|    n_updates              | 1        |
|    policy_objective       | 0.0548   |
|    value_loss             | 0.0246   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 4000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 2    |
|    time_elapsed    | 408  |
|    total_timesteps | 4096 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 5000     |
| train/                    |          |
|    explained_variance     | 0.879    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00643  |
|    learning_rate          | 0.001    |
|    n_updates              | 2        |
|    policy_objective       | 0.0564   |
|    value_loss             | 0.0155   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 6000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 3    |
|    time_elapsed    | 612  |
|    total_timesteps | 6144 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 7000     |
| train/                    |          |
|    explained_variance     | 0.895    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00565  |
|    learning_rate          | 0.001    |
|    n_updates              | 3        |
|    policy_objective       | 0.0485   |
|    value_loss             | 0.0178   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 8000     |
---------------------------------
-----------------------------
| time/              |      |
|    fps             | 10   |
|    iterations      | 4    |
|    time_elapsed    | 817  |
|    total_timesteps | 8192 |
-----------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 9000     |
| train/                    |          |
|    explained_variance     | 0.714    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00534  |
|    learning_rate          | 0.001    |
|    n_updates              | 4        |
|    policy_objective       | 0.048    |
|    value_loss             | 0.00591  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 10000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 5     |
|    time_elapsed    | 1021  |
|    total_timesteps | 10240 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 11000    |
| train/                    |          |
|    explained_variance     | 0.86     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00625  |
|    learning_rate          | 0.001    |
|    n_updates              | 5        |
|    policy_objective       | 0.0458   |
|    value_loss             | 0.0119   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 12000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 6     |
|    time_elapsed    | 1226  |
|    total_timesteps | 12288 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 13000    |
| train/                    |          |
|    explained_variance     | 0.783    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00495  |
|    learning_rate          | 0.001    |
|    n_updates              | 6        |
|    policy_objective       | 0.0533   |
|    value_loss             | 0.0057   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 14000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 7     |
|    time_elapsed    | 1430  |
|    total_timesteps | 14336 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 15000    |
| train/                    |          |
|    explained_variance     | 0.892    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00451  |
|    learning_rate          | 0.001    |
|    n_updates              | 7        |
|    policy_objective       | 0.0708   |
|    value_loss             | 0.00747  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 16000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 8     |
|    time_elapsed    | 1634  |
|    total_timesteps | 16384 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 17000    |
| train/                    |          |
|    explained_variance     | 0.839    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00571  |
|    learning_rate          | 0.001    |
|    n_updates              | 8        |
|    policy_objective       | 0.0443   |
|    value_loss             | 0.00324  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 18000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 9     |
|    time_elapsed    | 1839  |
|    total_timesteps | 18432 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 19000    |
| train/                    |          |
|    explained_variance     | 0.876    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0044   |
|    learning_rate          | 0.001    |
|    n_updates              | 9        |
|    policy_objective       | 0.0521   |
|    value_loss             | 0.0133   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 20000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 10    |
|    time_elapsed    | 2043  |
|    total_timesteps | 20480 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 21000    |
| train/                    |          |
|    explained_variance     | 0.676    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00572  |
|    learning_rate          | 0.001    |
|    n_updates              | 10       |
|    policy_objective       | 0.0509   |
|    value_loss             | 0.00376  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 22000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 11    |
|    time_elapsed    | 2247  |
|    total_timesteps | 22528 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 23000    |
| train/                    |          |
|    explained_variance     | 0.921    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.001    |
|    n_updates              | 11       |
|    policy_objective       | 0.0495   |
|    value_loss             | 0.00218  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 24000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 12    |
|    time_elapsed    | 2452  |
|    total_timesteps | 24576 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 25000    |
| train/                    |          |
|    explained_variance     | 0.761    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00423  |
|    learning_rate          | 0.001    |
|    n_updates              | 12       |
|    policy_objective       | 0.0547   |
|    value_loss             | 0.00462  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 26000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 13    |
|    time_elapsed    | 2656  |
|    total_timesteps | 26624 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 27000    |
| train/                    |          |
|    explained_variance     | 0.787    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00565  |
|    learning_rate          | 0.001    |
|    n_updates              | 13       |
|    policy_objective       | 0.0502   |
|    value_loss             | 0.00534  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 28000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 14    |
|    time_elapsed    | 2860  |
|    total_timesteps | 28672 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 29000    |
| train/                    |          |
|    explained_variance     | 0.768    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0041   |
|    learning_rate          | 0.001    |
|    n_updates              | 14       |
|    policy_objective       | 0.0501   |
|    value_loss             | 0.002    |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 30000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 15    |
|    time_elapsed    | 3065  |
|    total_timesteps | 30720 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 31000    |
| train/                    |          |
|    explained_variance     | 0.862    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00628  |
|    learning_rate          | 0.001    |
|    n_updates              | 15       |
|    policy_objective       | 0.0472   |
|    value_loss             | 0.00571  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 32000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 16    |
|    time_elapsed    | 3269  |
|    total_timesteps | 32768 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 33000    |
| train/                    |          |
|    explained_variance     | 0.757    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00448  |
|    learning_rate          | 0.001    |
|    n_updates              | 16       |
|    policy_objective       | 0.063    |
|    value_loss             | 0.00257  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 34000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 17    |
|    time_elapsed    | 3474  |
|    total_timesteps | 34816 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 35000    |
| train/                    |          |
|    explained_variance     | 0.78     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00553  |
|    learning_rate          | 0.001    |
|    n_updates              | 17       |
|    policy_objective       | 0.0565   |
|    value_loss             | 0.00533  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 36000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 18    |
|    time_elapsed    | 3678  |
|    total_timesteps | 36864 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 37000    |
| train/                    |          |
|    explained_variance     | 0.817    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00562  |
|    learning_rate          | 0.001    |
|    n_updates              | 18       |
|    policy_objective       | 0.0557   |
|    value_loss             | 0.00261  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 38000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 19    |
|    time_elapsed    | 3882  |
|    total_timesteps | 38912 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 39000    |
| train/                    |          |
|    explained_variance     | 0.759    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00465  |
|    learning_rate          | 0.001    |
|    n_updates              | 19       |
|    policy_objective       | 0.0581   |
|    value_loss             | 0.00172  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 40000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 10    |
|    iterations      | 20    |
|    time_elapsed    | 4087  |
|    total_timesteps | 40960 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 41000    |
| train/                    |          |
|    explained_variance     | 0.829    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00468  |
|    learning_rate          | 0.001    |
|    n_updates              | 20       |
|    policy_objective       | 0.0524   |
|    value_loss             | 0.0027   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 42000    |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 43000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 21    |
|    time_elapsed    | 4391  |
|    total_timesteps | 43008 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 44000    |
| train/                    |          |
|    explained_variance     | 0.827    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00596  |
|    learning_rate          | 0.001    |
|    n_updates              | 21       |
|    policy_objective       | 0.0501   |
|    value_loss             | 0.0018   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 45000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 22    |
|    time_elapsed    | 4595  |
|    total_timesteps | 45056 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 46000    |
| train/                    |          |
|    explained_variance     | 0.788    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00492  |
|    learning_rate          | 0.001    |
|    n_updates              | 22       |
|    policy_objective       | 0.0669   |
|    value_loss             | 0.00164  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 47000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 23    |
|    time_elapsed    | 4800  |
|    total_timesteps | 47104 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 48000    |
| train/                    |          |
|    explained_variance     | 0.894    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00614  |
|    learning_rate          | 0.001    |
|    n_updates              | 23       |
|    policy_objective       | 0.0495   |
|    value_loss             | 0.00187  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 49000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 24    |
|    time_elapsed    | 5004  |
|    total_timesteps | 49152 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 50000    |
| train/                    |          |
|    explained_variance     | 0.825    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00473  |
|    learning_rate          | 0.001    |
|    n_updates              | 24       |
|    policy_objective       | 0.0477   |
|    value_loss             | 0.000649 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 51000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 25    |
|    time_elapsed    | 5209  |
|    total_timesteps | 51200 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 52000    |
| train/                    |          |
|    explained_variance     | 0.831    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00602  |
|    learning_rate          | 0.001    |
|    n_updates              | 25       |
|    policy_objective       | 0.0495   |
|    value_loss             | 0.000801 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 53000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 26    |
|    time_elapsed    | 5413  |
|    total_timesteps | 53248 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 54000    |
| train/                    |          |
|    explained_variance     | 0.799    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0058   |
|    learning_rate          | 0.001    |
|    n_updates              | 26       |
|    policy_objective       | 0.0596   |
|    value_loss             | 0.000731 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 55000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 27    |
|    time_elapsed    | 5617  |
|    total_timesteps | 55296 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 56000    |
| train/                    |          |
|    explained_variance     | 0.871    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00551  |
|    learning_rate          | 0.001    |
|    n_updates              | 27       |
|    policy_objective       | 0.0488   |
|    value_loss             | 0.00155  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 57000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 28    |
|    time_elapsed    | 5822  |
|    total_timesteps | 57344 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 58000    |
| train/                    |          |
|    explained_variance     | 0.921    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0049   |
|    learning_rate          | 0.001    |
|    n_updates              | 28       |
|    policy_objective       | 0.0501   |
|    value_loss             | 0.0014   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 59000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 29    |
|    time_elapsed    | 6026  |
|    total_timesteps | 59392 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 60000    |
| train/                    |          |
|    explained_variance     | 0.848    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00456  |
|    learning_rate          | 0.001    |
|    n_updates              | 29       |
|    policy_objective       | 0.057    |
|    value_loss             | 0.000916 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 61000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 30    |
|    time_elapsed    | 6230  |
|    total_timesteps | 61440 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 62000    |
| train/                    |          |
|    explained_variance     | 0.898    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00494  |
|    learning_rate          | 0.001    |
|    n_updates              | 30       |
|    policy_objective       | 0.0489   |
|    value_loss             | 0.000681 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 63000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 31    |
|    time_elapsed    | 6435  |
|    total_timesteps | 63488 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 64000    |
| train/                    |          |
|    explained_variance     | 0.587    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00374  |
|    learning_rate          | 0.001    |
|    n_updates              | 31       |
|    policy_objective       | 0.0749   |
|    value_loss             | 0.000986 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 65000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 32    |
|    time_elapsed    | 6639  |
|    total_timesteps | 65536 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0        |
| time/                     |          |
|    total_timesteps        | 66000    |
| train/                    |          |
|    explained_variance     | 0.817    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00482  |
|    learning_rate          | 0.001    |
|    n_updates              | 32       |
|    policy_objective       | 0.0512   |
|    value_loss             | 0.0018   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 67000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 33    |
|    time_elapsed    | 6844  |
|    total_timesteps | 67584 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 68000    |
| train/                    |          |
|    explained_variance     | 0.861    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00527  |
|    learning_rate          | 0.001    |
|    n_updates              | 33       |
|    policy_objective       | 0.0571   |
|    value_loss             | 0.00174  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 69000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 34    |
|    time_elapsed    | 7048  |
|    total_timesteps | 69632 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 70000    |
| train/                    |          |
|    explained_variance     | 0.925    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00569  |
|    learning_rate          | 0.001    |
|    n_updates              | 34       |
|    policy_objective       | 0.0579   |
|    value_loss             | 0.000739 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 71000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 35    |
|    time_elapsed    | 7252  |
|    total_timesteps | 71680 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 72000    |
| train/                    |          |
|    explained_variance     | 0.816    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00529  |
|    learning_rate          | 0.001    |
|    n_updates              | 35       |
|    policy_objective       | 0.0594   |
|    value_loss             | 0.00164  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 73000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 36    |
|    time_elapsed    | 7457  |
|    total_timesteps | 73728 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 74000    |
| train/                    |          |
|    explained_variance     | 0.67     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0044   |
|    learning_rate          | 0.001    |
|    n_updates              | 36       |
|    policy_objective       | 0.0591   |
|    value_loss             | 0.00205  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 75000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 37    |
|    time_elapsed    | 7661  |
|    total_timesteps | 75776 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 76000    |
| train/                    |          |
|    explained_variance     | 0.864    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00439  |
|    learning_rate          | 0.001    |
|    n_updates              | 37       |
|    policy_objective       | 0.0528   |
|    value_loss             | 0.00117  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 77000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 38    |
|    time_elapsed    | 7865  |
|    total_timesteps | 77824 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 78000    |
| train/                    |          |
|    explained_variance     | 0.633    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00447  |
|    learning_rate          | 0.001    |
|    n_updates              | 38       |
|    policy_objective       | 0.0549   |
|    value_loss             | 0.00153  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 79000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 39    |
|    time_elapsed    | 8070  |
|    total_timesteps | 79872 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 80000    |
| train/                    |          |
|    explained_variance     | 0.718    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00577  |
|    learning_rate          | 0.001    |
|    n_updates              | 39       |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.000422 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 81000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 40    |
|    time_elapsed    | 8274  |
|    total_timesteps | 81920 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 82000    |
| train/                    |          |
|    explained_variance     | 0.619    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00513  |
|    learning_rate          | 0.001    |
|    n_updates              | 40       |
|    policy_objective       | 0.0759   |
|    value_loss             | 0.000896 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 83000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 41    |
|    time_elapsed    | 8479  |
|    total_timesteps | 83968 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 84000    |
| train/                    |          |
|    explained_variance     | 0.424    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00477  |
|    learning_rate          | 0.001    |
|    n_updates              | 41       |
|    policy_objective       | 0.0656   |
|    value_loss             | 0.00056  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 85000    |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 86000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 42    |
|    time_elapsed    | 8783  |
|    total_timesteps | 86016 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 87000    |
| train/                    |          |
|    explained_variance     | 0.668    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00438  |
|    learning_rate          | 0.001    |
|    n_updates              | 42       |
|    policy_objective       | 0.0624   |
|    value_loss             | 0.000747 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 88000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 43    |
|    time_elapsed    | 8987  |
|    total_timesteps | 88064 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 89000    |
| train/                    |          |
|    explained_variance     | 0.814    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00483  |
|    learning_rate          | 0.001    |
|    n_updates              | 43       |
|    policy_objective       | 0.0555   |
|    value_loss             | 0.000826 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 90000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 44    |
|    time_elapsed    | 9192  |
|    total_timesteps | 90112 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 91000    |
| train/                    |          |
|    explained_variance     | 0.728    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00591  |
|    learning_rate          | 0.001    |
|    n_updates              | 44       |
|    policy_objective       | 0.0514   |
|    value_loss             | 0.00117  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 92000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 45    |
|    time_elapsed    | 9396  |
|    total_timesteps | 92160 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 93000    |
| train/                    |          |
|    explained_variance     | 0.556    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00543  |
|    learning_rate          | 0.001    |
|    n_updates              | 45       |
|    policy_objective       | 0.0566   |
|    value_loss             | 0.000604 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 94000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 46    |
|    time_elapsed    | 9600  |
|    total_timesteps | 94208 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 95000    |
| train/                    |          |
|    explained_variance     | 0.561    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00481  |
|    learning_rate          | 0.001    |
|    n_updates              | 46       |
|    policy_objective       | 0.0571   |
|    value_loss             | 0.0012   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 96000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 47    |
|    time_elapsed    | 9805  |
|    total_timesteps | 96256 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 97000    |
| train/                    |          |
|    explained_variance     | 0.782    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00449  |
|    learning_rate          | 0.001    |
|    n_updates              | 47       |
|    policy_objective       | 0.0513   |
|    value_loss             | 0.00076  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 98000    |
---------------------------------
------------------------------
| time/              |       |
|    fps             | 9     |
|    iterations      | 48    |
|    time_elapsed    | 10009 |
|    total_timesteps | 98304 |
------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 99000    |
| train/                    |          |
|    explained_variance     | 0.65     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00408  |
|    learning_rate          | 0.001    |
|    n_updates              | 48       |
|    policy_objective       | 0.0635   |
|    value_loss             | 0.000898 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 100000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 49     |
|    time_elapsed    | 10213  |
|    total_timesteps | 100352 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 101000   |
| train/                    |          |
|    explained_variance     | 0.87     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00495  |
|    learning_rate          | 0.001    |
|    n_updates              | 49       |
|    policy_objective       | 0.0582   |
|    value_loss             | 0.00101  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 102000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 50     |
|    time_elapsed    | 10418  |
|    total_timesteps | 102400 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 103000   |
| train/                    |          |
|    explained_variance     | 0.786    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00445  |
|    learning_rate          | 0.001    |
|    n_updates              | 50       |
|    policy_objective       | 0.0605   |
|    value_loss             | 0.000969 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 104000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 51     |
|    time_elapsed    | 10622  |
|    total_timesteps | 104448 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 105000   |
| train/                    |          |
|    explained_variance     | 0.773    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00463  |
|    learning_rate          | 0.001    |
|    n_updates              | 51       |
|    policy_objective       | 0.0597   |
|    value_loss             | 0.000918 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 106000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 52     |
|    time_elapsed    | 10827  |
|    total_timesteps | 106496 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 107000   |
| train/                    |          |
|    explained_variance     | 0.847    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00405  |
|    learning_rate          | 0.001    |
|    n_updates              | 52       |
|    policy_objective       | 0.0626   |
|    value_loss             | 0.000518 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 108000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 53     |
|    time_elapsed    | 11031  |
|    total_timesteps | 108544 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 109000   |
| train/                    |          |
|    explained_variance     | 0.823    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0052   |
|    learning_rate          | 0.001    |
|    n_updates              | 53       |
|    policy_objective       | 0.0549   |
|    value_loss             | 0.00129  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 110000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 54     |
|    time_elapsed    | 11235  |
|    total_timesteps | 110592 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 111000   |
| train/                    |          |
|    explained_variance     | 0.824    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00468  |
|    learning_rate          | 0.001    |
|    n_updates              | 54       |
|    policy_objective       | 0.0644   |
|    value_loss             | 0.000679 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 112000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 55     |
|    time_elapsed    | 11440  |
|    total_timesteps | 112640 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 113000   |
| train/                    |          |
|    explained_variance     | 0.791    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00431  |
|    learning_rate          | 0.001    |
|    n_updates              | 55       |
|    policy_objective       | 0.0696   |
|    value_loss             | 0.000624 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 114000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 56     |
|    time_elapsed    | 11644  |
|    total_timesteps | 114688 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 115000   |
| train/                    |          |
|    explained_variance     | 0.863    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00628  |
|    learning_rate          | 0.001    |
|    n_updates              | 56       |
|    policy_objective       | 0.0518   |
|    value_loss             | 0.000569 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 116000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 57     |
|    time_elapsed    | 11848  |
|    total_timesteps | 116736 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 117000   |
| train/                    |          |
|    explained_variance     | 0.785    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00555  |
|    learning_rate          | 0.001    |
|    n_updates              | 57       |
|    policy_objective       | 0.063    |
|    value_loss             | 0.000886 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 118000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 58     |
|    time_elapsed    | 12053  |
|    total_timesteps | 118784 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 119000   |
| train/                    |          |
|    explained_variance     | 0.948    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 58       |
|    policy_objective       | 0.0566   |
|    value_loss             | 0.000389 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 120000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 59     |
|    time_elapsed    | 12257  |
|    total_timesteps | 120832 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 121000   |
| train/                    |          |
|    explained_variance     | 0.804    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 59       |
|    policy_objective       | 0.06     |
|    value_loss             | 0.000734 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 122000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 60     |
|    time_elapsed    | 12461  |
|    total_timesteps | 122880 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 123000   |
| train/                    |          |
|    explained_variance     | 0.741    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00643  |
|    learning_rate          | 0.001    |
|    n_updates              | 60       |
|    policy_objective       | 0.0552   |
|    value_loss             | 0.00132  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 124000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 61     |
|    time_elapsed    | 12666  |
|    total_timesteps | 124928 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 125000   |
| train/                    |          |
|    explained_variance     | 0.757    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00554  |
|    learning_rate          | 0.001    |
|    n_updates              | 61       |
|    policy_objective       | 0.0554   |
|    value_loss             | 0.000468 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 126000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 62     |
|    time_elapsed    | 12870  |
|    total_timesteps | 126976 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 127000   |
| train/                    |          |
|    explained_variance     | 0.814    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00596  |
|    learning_rate          | 0.001    |
|    n_updates              | 62       |
|    policy_objective       | 0.0544   |
|    value_loss             | 0.00055  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 128000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 129000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 63     |
|    time_elapsed    | 13174  |
|    total_timesteps | 129024 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 130000   |
| train/                    |          |
|    explained_variance     | 0.767    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00394  |
|    learning_rate          | 0.001    |
|    n_updates              | 63       |
|    policy_objective       | 0.063    |
|    value_loss             | 0.000377 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 131000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 64     |
|    time_elapsed    | 13379  |
|    total_timesteps | 131072 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 132000   |
| train/                    |          |
|    explained_variance     | 0.69     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00461  |
|    learning_rate          | 0.001    |
|    n_updates              | 64       |
|    policy_objective       | 0.0607   |
|    value_loss             | 0.0004   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 133000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 65     |
|    time_elapsed    | 13583  |
|    total_timesteps | 133120 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 134000   |
| train/                    |          |
|    explained_variance     | 0.613    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00466  |
|    learning_rate          | 0.001    |
|    n_updates              | 65       |
|    policy_objective       | 0.0658   |
|    value_loss             | 0.000713 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 135000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 66     |
|    time_elapsed    | 13787  |
|    total_timesteps | 135168 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 136000   |
| train/                    |          |
|    explained_variance     | 0.824    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0054   |
|    learning_rate          | 0.001    |
|    n_updates              | 66       |
|    policy_objective       | 0.0603   |
|    value_loss             | 0.000966 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 137000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 67     |
|    time_elapsed    | 13992  |
|    total_timesteps | 137216 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 138000   |
| train/                    |          |
|    explained_variance     | 0.739    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00576  |
|    learning_rate          | 0.001    |
|    n_updates              | 67       |
|    policy_objective       | 0.0505   |
|    value_loss             | 0.000539 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 139000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 68     |
|    time_elapsed    | 14196  |
|    total_timesteps | 139264 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 140000   |
| train/                    |          |
|    explained_variance     | 0.613    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00412  |
|    learning_rate          | 0.001    |
|    n_updates              | 68       |
|    policy_objective       | 0.0753   |
|    value_loss             | 0.000698 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 141000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 69     |
|    time_elapsed    | 14400  |
|    total_timesteps | 141312 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 142000   |
| train/                    |          |
|    explained_variance     | 0.596    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0046   |
|    learning_rate          | 0.001    |
|    n_updates              | 69       |
|    policy_objective       | 0.0568   |
|    value_loss             | 0.000838 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 143000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 70     |
|    time_elapsed    | 14605  |
|    total_timesteps | 143360 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 144000   |
| train/                    |          |
|    explained_variance     | 0.772    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00563  |
|    learning_rate          | 0.001    |
|    n_updates              | 70       |
|    policy_objective       | 0.0555   |
|    value_loss             | 0.00083  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 145000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 71     |
|    time_elapsed    | 14809  |
|    total_timesteps | 145408 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 146000   |
| train/                    |          |
|    explained_variance     | 0.455    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00478  |
|    learning_rate          | 0.001    |
|    n_updates              | 71       |
|    policy_objective       | 0.0599   |
|    value_loss             | 0.000546 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 147000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 72     |
|    time_elapsed    | 15014  |
|    total_timesteps | 147456 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 148000   |
| train/                    |          |
|    explained_variance     | 0.698    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00374  |
|    learning_rate          | 0.001    |
|    n_updates              | 72       |
|    policy_objective       | 0.0693   |
|    value_loss             | 0.000643 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 149000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 73     |
|    time_elapsed    | 15218  |
|    total_timesteps | 149504 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 150000   |
| train/                    |          |
|    explained_variance     | 0.389    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00558  |
|    learning_rate          | 0.001    |
|    n_updates              | 73       |
|    policy_objective       | 0.0646   |
|    value_loss             | 0.000612 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 151000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 74     |
|    time_elapsed    | 15422  |
|    total_timesteps | 151552 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 152000   |
| train/                    |          |
|    explained_variance     | 0.497    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00519  |
|    learning_rate          | 0.001    |
|    n_updates              | 74       |
|    policy_objective       | 0.0619   |
|    value_loss             | 0.000876 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 153000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 75     |
|    time_elapsed    | 15627  |
|    total_timesteps | 153600 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 154000   |
| train/                    |          |
|    explained_variance     | 0.704    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00446  |
|    learning_rate          | 0.001    |
|    n_updates              | 75       |
|    policy_objective       | 0.0701   |
|    value_loss             | 0.000623 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 155000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 76     |
|    time_elapsed    | 15831  |
|    total_timesteps | 155648 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 156000   |
| train/                    |          |
|    explained_variance     | 0.769    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.001    |
|    n_updates              | 76       |
|    policy_objective       | 0.0531   |
|    value_loss             | 0.000563 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 157000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 77     |
|    time_elapsed    | 16036  |
|    total_timesteps | 157696 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 158000   |
| train/                    |          |
|    explained_variance     | 0.794    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00535  |
|    learning_rate          | 0.001    |
|    n_updates              | 77       |
|    policy_objective       | 0.053    |
|    value_loss             | 0.000627 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 159000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 78     |
|    time_elapsed    | 16240  |
|    total_timesteps | 159744 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 160000   |
| train/                    |          |
|    explained_variance     | 0.303    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00474  |
|    learning_rate          | 0.001    |
|    n_updates              | 78       |
|    policy_objective       | 0.0669   |
|    value_loss             | 0.000766 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 161000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 79     |
|    time_elapsed    | 16444  |
|    total_timesteps | 161792 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 162000   |
| train/                    |          |
|    explained_variance     | 0.699    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00448  |
|    learning_rate          | 0.001    |
|    n_updates              | 79       |
|    policy_objective       | 0.0638   |
|    value_loss             | 0.000445 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 163000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 80     |
|    time_elapsed    | 16649  |
|    total_timesteps | 163840 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 164000   |
| train/                    |          |
|    explained_variance     | 0.896    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00576  |
|    learning_rate          | 0.001    |
|    n_updates              | 80       |
|    policy_objective       | 0.053    |
|    value_loss             | 0.00106  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 165000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 81     |
|    time_elapsed    | 16853  |
|    total_timesteps | 165888 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 166000   |
| train/                    |          |
|    explained_variance     | 0.756    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00537  |
|    learning_rate          | 0.001    |
|    n_updates              | 81       |
|    policy_objective       | 0.0498   |
|    value_loss             | 0.000843 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 167000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 82     |
|    time_elapsed    | 17057  |
|    total_timesteps | 167936 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 168000   |
| train/                    |          |
|    explained_variance     | 0.675    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00514  |
|    learning_rate          | 0.001    |
|    n_updates              | 82       |
|    policy_objective       | 0.0679   |
|    value_loss             | 0.000533 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 169000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 83     |
|    time_elapsed    | 17262  |
|    total_timesteps | 169984 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 170000   |
| train/                    |          |
|    explained_variance     | 0.356    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00567  |
|    learning_rate          | 0.001    |
|    n_updates              | 83       |
|    policy_objective       | 0.0553   |
|    value_loss             | 0.000598 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 171000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 172000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 84     |
|    time_elapsed    | 17566  |
|    total_timesteps | 172032 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 173000   |
| train/                    |          |
|    explained_variance     | 0.473    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00523  |
|    learning_rate          | 0.001    |
|    n_updates              | 84       |
|    policy_objective       | 0.05     |
|    value_loss             | 0.000493 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 174000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 85     |
|    time_elapsed    | 17770  |
|    total_timesteps | 174080 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 175000   |
| train/                    |          |
|    explained_variance     | 0.799    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00555  |
|    learning_rate          | 0.001    |
|    n_updates              | 85       |
|    policy_objective       | 0.0568   |
|    value_loss             | 0.00074  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 176000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 86     |
|    time_elapsed    | 17975  |
|    total_timesteps | 176128 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.1      |
| time/                     |          |
|    total_timesteps        | 177000   |
| train/                    |          |
|    explained_variance     | 0.731    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00484  |
|    learning_rate          | 0.001    |
|    n_updates              | 86       |
|    policy_objective       | 0.0632   |
|    value_loss             | 0.000676 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 178000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 87     |
|    time_elapsed    | 18179  |
|    total_timesteps | 178176 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 179000   |
| train/                    |          |
|    explained_variance     | 0.708    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00505  |
|    learning_rate          | 0.001    |
|    n_updates              | 87       |
|    policy_objective       | 0.0596   |
|    value_loss             | 0.000697 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 180000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 88     |
|    time_elapsed    | 18384  |
|    total_timesteps | 180224 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 181000   |
| train/                    |          |
|    explained_variance     | 0.742    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0058   |
|    learning_rate          | 0.001    |
|    n_updates              | 88       |
|    policy_objective       | 0.0557   |
|    value_loss             | 0.00063  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 182000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 89     |
|    time_elapsed    | 18588  |
|    total_timesteps | 182272 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 183000   |
| train/                    |          |
|    explained_variance     | 0.8      |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00544  |
|    learning_rate          | 0.001    |
|    n_updates              | 89       |
|    policy_objective       | 0.057    |
|    value_loss             | 0.000665 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 184000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 90     |
|    time_elapsed    | 18792  |
|    total_timesteps | 184320 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 185000   |
| train/                    |          |
|    explained_variance     | 0.741    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00533  |
|    learning_rate          | 0.001    |
|    n_updates              | 90       |
|    policy_objective       | 0.0498   |
|    value_loss             | 0.000807 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 186000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 91     |
|    time_elapsed    | 18997  |
|    total_timesteps | 186368 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 187000   |
| train/                    |          |
|    explained_variance     | 0.744    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00605  |
|    learning_rate          | 0.001    |
|    n_updates              | 91       |
|    policy_objective       | 0.0585   |
|    value_loss             | 0.000717 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 188000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 92     |
|    time_elapsed    | 19201  |
|    total_timesteps | 188416 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 189000   |
| train/                    |          |
|    explained_variance     | 0.694    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00535  |
|    learning_rate          | 0.001    |
|    n_updates              | 92       |
|    policy_objective       | 0.0532   |
|    value_loss             | 0.000575 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 190000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 93     |
|    time_elapsed    | 19405  |
|    total_timesteps | 190464 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 191000   |
| train/                    |          |
|    explained_variance     | 0.616    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00528  |
|    learning_rate          | 0.001    |
|    n_updates              | 93       |
|    policy_objective       | 0.0506   |
|    value_loss             | 0.000663 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 192000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 94     |
|    time_elapsed    | 19610  |
|    total_timesteps | 192512 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 193000   |
| train/                    |          |
|    explained_variance     | 0.785    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00525  |
|    learning_rate          | 0.001    |
|    n_updates              | 94       |
|    policy_objective       | 0.0461   |
|    value_loss             | 0.000859 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 194000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 95     |
|    time_elapsed    | 19814  |
|    total_timesteps | 194560 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 195000   |
| train/                    |          |
|    explained_variance     | 0.69     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00609  |
|    learning_rate          | 0.001    |
|    n_updates              | 95       |
|    policy_objective       | 0.0488   |
|    value_loss             | 0.000568 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 196000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 96     |
|    time_elapsed    | 20019  |
|    total_timesteps | 196608 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 197000   |
| train/                    |          |
|    explained_variance     | 0.594    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0054   |
|    learning_rate          | 0.001    |
|    n_updates              | 96       |
|    policy_objective       | 0.057    |
|    value_loss             | 0.000852 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 198000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 97     |
|    time_elapsed    | 20223  |
|    total_timesteps | 198656 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 199000   |
| train/                    |          |
|    explained_variance     | 0.749    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00593  |
|    learning_rate          | 0.001    |
|    n_updates              | 97       |
|    policy_objective       | 0.0532   |
|    value_loss             | 0.00156  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 200000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 98     |
|    time_elapsed    | 20427  |
|    total_timesteps | 200704 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 201000   |
| train/                    |          |
|    explained_variance     | 0.649    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.001    |
|    n_updates              | 98       |
|    policy_objective       | 0.0526   |
|    value_loss             | 0.00092  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 202000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 99     |
|    time_elapsed    | 20632  |
|    total_timesteps | 202752 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 203000   |
| train/                    |          |
|    explained_variance     | 0.713    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00517  |
|    learning_rate          | 0.001    |
|    n_updates              | 99       |
|    policy_objective       | 0.0512   |
|    value_loss             | 0.000904 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 204000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 100    |
|    time_elapsed    | 20836  |
|    total_timesteps | 204800 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 205000   |
| train/                    |          |
|    explained_variance     | 0.666    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00551  |
|    learning_rate          | 0.001    |
|    n_updates              | 100      |
|    policy_objective       | 0.0541   |
|    value_loss             | 0.000416 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 206000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 101    |
|    time_elapsed    | 21040  |
|    total_timesteps | 206848 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 207000   |
| train/                    |          |
|    explained_variance     | 0.71     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00505  |
|    learning_rate          | 0.001    |
|    n_updates              | 101      |
|    policy_objective       | 0.0635   |
|    value_loss             | 0.00123  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 208000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 102    |
|    time_elapsed    | 21245  |
|    total_timesteps | 208896 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 209000   |
| train/                    |          |
|    explained_variance     | 0.813    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00484  |
|    learning_rate          | 0.001    |
|    n_updates              | 102      |
|    policy_objective       | 0.058    |
|    value_loss             | 0.000549 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 210000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 103    |
|    time_elapsed    | 21449  |
|    total_timesteps | 210944 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 211000   |
| train/                    |          |
|    explained_variance     | 0.675    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00572  |
|    learning_rate          | 0.001    |
|    n_updates              | 103      |
|    policy_objective       | 0.0592   |
|    value_loss             | 0.000895 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 212000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 104    |
|    time_elapsed    | 21653  |
|    total_timesteps | 212992 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 213000   |
| train/                    |          |
|    explained_variance     | 0.649    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00532  |
|    learning_rate          | 0.001    |
|    n_updates              | 104      |
|    policy_objective       | 0.0674   |
|    value_loss             | 0.000804 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 214000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 215000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 105    |
|    time_elapsed    | 21958  |
|    total_timesteps | 215040 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 216000   |
| train/                    |          |
|    explained_variance     | 0.611    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00364  |
|    learning_rate          | 0.001    |
|    n_updates              | 105      |
|    policy_objective       | 0.0709   |
|    value_loss             | 0.00111  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 217000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 106    |
|    time_elapsed    | 22162  |
|    total_timesteps | 217088 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 218000   |
| train/                    |          |
|    explained_variance     | 0.771    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00598  |
|    learning_rate          | 0.001    |
|    n_updates              | 106      |
|    policy_objective       | 0.0495   |
|    value_loss             | 0.000792 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 219000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 107    |
|    time_elapsed    | 22366  |
|    total_timesteps | 219136 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 220000   |
| train/                    |          |
|    explained_variance     | 0.794    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00481  |
|    learning_rate          | 0.001    |
|    n_updates              | 107      |
|    policy_objective       | 0.0501   |
|    value_loss             | 0.00101  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 221000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 108    |
|    time_elapsed    | 22571  |
|    total_timesteps | 221184 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 222000   |
| train/                    |          |
|    explained_variance     | 0.597    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00458  |
|    learning_rate          | 0.001    |
|    n_updates              | 108      |
|    policy_objective       | 0.064    |
|    value_loss             | 0.000879 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 223000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 109    |
|    time_elapsed    | 22775  |
|    total_timesteps | 223232 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 224000   |
| train/                    |          |
|    explained_variance     | 0.721    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00477  |
|    learning_rate          | 0.001    |
|    n_updates              | 109      |
|    policy_objective       | 0.0473   |
|    value_loss             | 0.00059  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 225000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 110    |
|    time_elapsed    | 22979  |
|    total_timesteps | 225280 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 226000   |
| train/                    |          |
|    explained_variance     | 0.532    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00532  |
|    learning_rate          | 0.001    |
|    n_updates              | 110      |
|    policy_objective       | 0.0585   |
|    value_loss             | 0.00138  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 227000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 111    |
|    time_elapsed    | 23184  |
|    total_timesteps | 227328 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 228000   |
| train/                    |          |
|    explained_variance     | 0.674    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00622  |
|    learning_rate          | 0.001    |
|    n_updates              | 111      |
|    policy_objective       | 0.0716   |
|    value_loss             | 0.000997 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 229000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 112    |
|    time_elapsed    | 23388  |
|    total_timesteps | 229376 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 230000   |
| train/                    |          |
|    explained_variance     | 0.686    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00519  |
|    learning_rate          | 0.001    |
|    n_updates              | 112      |
|    policy_objective       | 0.0528   |
|    value_loss             | 0.000794 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 231000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 113    |
|    time_elapsed    | 23593  |
|    total_timesteps | 231424 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 232000   |
| train/                    |          |
|    explained_variance     | 0.707    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00641  |
|    learning_rate          | 0.001    |
|    n_updates              | 113      |
|    policy_objective       | 0.0437   |
|    value_loss             | 0.00101  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 233000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 114    |
|    time_elapsed    | 23797  |
|    total_timesteps | 233472 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 234000   |
| train/                    |          |
|    explained_variance     | 0.535    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00563  |
|    learning_rate          | 0.001    |
|    n_updates              | 114      |
|    policy_objective       | 0.0534   |
|    value_loss             | 0.000843 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 235000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 115    |
|    time_elapsed    | 24001  |
|    total_timesteps | 235520 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 236000   |
| train/                    |          |
|    explained_variance     | 0.533    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00543  |
|    learning_rate          | 0.001    |
|    n_updates              | 115      |
|    policy_objective       | 0.0637   |
|    value_loss             | 0.000935 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 237000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 116    |
|    time_elapsed    | 24206  |
|    total_timesteps | 237568 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 238000   |
| train/                    |          |
|    explained_variance     | 0.641    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00595  |
|    learning_rate          | 0.001    |
|    n_updates              | 116      |
|    policy_objective       | 0.064    |
|    value_loss             | 0.000885 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 239000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 117    |
|    time_elapsed    | 24410  |
|    total_timesteps | 239616 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 240000   |
| train/                    |          |
|    explained_variance     | 0.238    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00532  |
|    learning_rate          | 0.001    |
|    n_updates              | 117      |
|    policy_objective       | 0.0577   |
|    value_loss             | 0.00101  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 241000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 118    |
|    time_elapsed    | 24614  |
|    total_timesteps | 241664 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 242000   |
| train/                    |          |
|    explained_variance     | 0.559    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00582  |
|    learning_rate          | 0.001    |
|    n_updates              | 118      |
|    policy_objective       | 0.0621   |
|    value_loss             | 0.000906 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 243000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 119    |
|    time_elapsed    | 24819  |
|    total_timesteps | 243712 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 244000   |
| train/                    |          |
|    explained_variance     | 0.456    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0056   |
|    learning_rate          | 0.001    |
|    n_updates              | 119      |
|    policy_objective       | 0.0594   |
|    value_loss             | 0.000813 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 245000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 120    |
|    time_elapsed    | 25023  |
|    total_timesteps | 245760 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 246000   |
| train/                    |          |
|    explained_variance     | 0.454    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00546  |
|    learning_rate          | 0.001    |
|    n_updates              | 120      |
|    policy_objective       | 0.0672   |
|    value_loss             | 0.000871 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 247000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 121    |
|    time_elapsed    | 25228  |
|    total_timesteps | 247808 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 248000   |
| train/                    |          |
|    explained_variance     | 0.431    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00494  |
|    learning_rate          | 0.001    |
|    n_updates              | 121      |
|    policy_objective       | 0.0717   |
|    value_loss             | 0.00073  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 249000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 122    |
|    time_elapsed    | 25432  |
|    total_timesteps | 249856 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 250000   |
| train/                    |          |
|    explained_variance     | 0.486    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00556  |
|    learning_rate          | 0.001    |
|    n_updates              | 122      |
|    policy_objective       | 0.0586   |
|    value_loss             | 0.000892 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 251000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 123    |
|    time_elapsed    | 25636  |
|    total_timesteps | 251904 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 252000   |
| train/                    |          |
|    explained_variance     | 0.375    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00424  |
|    learning_rate          | 0.001    |
|    n_updates              | 123      |
|    policy_objective       | 0.0567   |
|    value_loss             | 0.00071  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 253000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 124    |
|    time_elapsed    | 25841  |
|    total_timesteps | 253952 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 254000   |
| train/                    |          |
|    explained_variance     | 0.371    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00583  |
|    learning_rate          | 0.001    |
|    n_updates              | 124      |
|    policy_objective       | 0.0548   |
|    value_loss             | 0.001    |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 255000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 256000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 125    |
|    time_elapsed    | 26145  |
|    total_timesteps | 256000 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 257000   |
| train/                    |          |
|    explained_variance     | 0.492    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00397  |
|    learning_rate          | 0.001    |
|    n_updates              | 125      |
|    policy_objective       | 0.0643   |
|    value_loss             | 0.000499 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 258000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 126    |
|    time_elapsed    | 26350  |
|    total_timesteps | 258048 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 259000   |
| train/                    |          |
|    explained_variance     | 0.331    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00369  |
|    learning_rate          | 0.001    |
|    n_updates              | 126      |
|    policy_objective       | 0.0678   |
|    value_loss             | 0.000695 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 260000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 127    |
|    time_elapsed    | 26554  |
|    total_timesteps | 260096 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 261000   |
| train/                    |          |
|    explained_variance     | 0.686    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00489  |
|    learning_rate          | 0.001    |
|    n_updates              | 127      |
|    policy_objective       | 0.0618   |
|    value_loss             | 0.000581 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 262000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 128    |
|    time_elapsed    | 26758  |
|    total_timesteps | 262144 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 263000   |
| train/                    |          |
|    explained_variance     | 0.503    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00536  |
|    learning_rate          | 0.001    |
|    n_updates              | 128      |
|    policy_objective       | 0.0614   |
|    value_loss             | 0.000697 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 264000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 129    |
|    time_elapsed    | 26963  |
|    total_timesteps | 264192 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 265000   |
| train/                    |          |
|    explained_variance     | 0.371    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00559  |
|    learning_rate          | 0.001    |
|    n_updates              | 129      |
|    policy_objective       | 0.0575   |
|    value_loss             | 0.000682 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 266000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 130    |
|    time_elapsed    | 27167  |
|    total_timesteps | 266240 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 267000   |
| train/                    |          |
|    explained_variance     | 0.504    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00678  |
|    learning_rate          | 0.001    |
|    n_updates              | 130      |
|    policy_objective       | 0.0499   |
|    value_loss             | 0.000928 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 268000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 131    |
|    time_elapsed    | 27371  |
|    total_timesteps | 268288 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 269000   |
| train/                    |          |
|    explained_variance     | 0.414    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0054   |
|    learning_rate          | 0.001    |
|    n_updates              | 131      |
|    policy_objective       | 0.0569   |
|    value_loss             | 0.00094  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 270000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 132    |
|    time_elapsed    | 27576  |
|    total_timesteps | 270336 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 271000   |
| train/                    |          |
|    explained_variance     | 0.16     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00582  |
|    learning_rate          | 0.001    |
|    n_updates              | 132      |
|    policy_objective       | 0.0565   |
|    value_loss             | 0.0011   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 272000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 133    |
|    time_elapsed    | 27780  |
|    total_timesteps | 272384 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 273000   |
| train/                    |          |
|    explained_variance     | 0.462    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00545  |
|    learning_rate          | 0.001    |
|    n_updates              | 133      |
|    policy_objective       | 0.0542   |
|    value_loss             | 0.00095  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 274000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 134    |
|    time_elapsed    | 27985  |
|    total_timesteps | 274432 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 275000   |
| train/                    |          |
|    explained_variance     | 0.438    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00551  |
|    learning_rate          | 0.001    |
|    n_updates              | 134      |
|    policy_objective       | 0.0558   |
|    value_loss             | 0.00108  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 276000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 135    |
|    time_elapsed    | 28189  |
|    total_timesteps | 276480 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 277000   |
| train/                    |          |
|    explained_variance     | 0.51     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00613  |
|    learning_rate          | 0.001    |
|    n_updates              | 135      |
|    policy_objective       | 0.0511   |
|    value_loss             | 0.00073  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 278000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 136    |
|    time_elapsed    | 28393  |
|    total_timesteps | 278528 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 279000   |
| train/                    |          |
|    explained_variance     | 0.471    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00625  |
|    learning_rate          | 0.001    |
|    n_updates              | 136      |
|    policy_objective       | 0.0635   |
|    value_loss             | 0.000846 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 280000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 137    |
|    time_elapsed    | 28598  |
|    total_timesteps | 280576 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 281000   |
| train/                    |          |
|    explained_variance     | 0.394    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00527  |
|    learning_rate          | 0.001    |
|    n_updates              | 137      |
|    policy_objective       | 0.054    |
|    value_loss             | 0.000913 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 282000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 138    |
|    time_elapsed    | 28802  |
|    total_timesteps | 282624 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 283000   |
| train/                    |          |
|    explained_variance     | 0.509    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00524  |
|    learning_rate          | 0.001    |
|    n_updates              | 138      |
|    policy_objective       | 0.0529   |
|    value_loss             | 0.00107  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 284000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 139    |
|    time_elapsed    | 29006  |
|    total_timesteps | 284672 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 285000   |
| train/                    |          |
|    explained_variance     | 0.49     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00787  |
|    learning_rate          | 0.001    |
|    n_updates              | 139      |
|    policy_objective       | 0.051    |
|    value_loss             | 0.000841 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 286000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 140    |
|    time_elapsed    | 29211  |
|    total_timesteps | 286720 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 287000   |
| train/                    |          |
|    explained_variance     | 0.37     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00486  |
|    learning_rate          | 0.001    |
|    n_updates              | 140      |
|    policy_objective       | 0.0632   |
|    value_loss             | 0.000852 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 288000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 141    |
|    time_elapsed    | 29415  |
|    total_timesteps | 288768 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 289000   |
| train/                    |          |
|    explained_variance     | 0.372    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00535  |
|    learning_rate          | 0.001    |
|    n_updates              | 141      |
|    policy_objective       | 0.0557   |
|    value_loss             | 0.00145  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 290000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 142    |
|    time_elapsed    | 29620  |
|    total_timesteps | 290816 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 291000   |
| train/                    |          |
|    explained_variance     | 0.559    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00484  |
|    learning_rate          | 0.001    |
|    n_updates              | 142      |
|    policy_objective       | 0.0574   |
|    value_loss             | 0.000985 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 292000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 143    |
|    time_elapsed    | 29824  |
|    total_timesteps | 292864 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 293000   |
| train/                    |          |
|    explained_variance     | 0.515    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00521  |
|    learning_rate          | 0.001    |
|    n_updates              | 143      |
|    policy_objective       | 0.0592   |
|    value_loss             | 0.00111  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 294000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 144    |
|    time_elapsed    | 30029  |
|    total_timesteps | 294912 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 295000   |
| train/                    |          |
|    explained_variance     | 0.542    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00443  |
|    learning_rate          | 0.001    |
|    n_updates              | 144      |
|    policy_objective       | 0.0628   |
|    value_loss             | 0.000771 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 296000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 145    |
|    time_elapsed    | 30233  |
|    total_timesteps | 296960 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 297000   |
| train/                    |          |
|    explained_variance     | 0.338    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0046   |
|    learning_rate          | 0.001    |
|    n_updates              | 145      |
|    policy_objective       | 0.0647   |
|    value_loss             | 0.00106  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 298000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 299000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 146    |
|    time_elapsed    | 30537  |
|    total_timesteps | 299008 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 300000   |
| train/                    |          |
|    explained_variance     | 0.235    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00572  |
|    learning_rate          | 0.001    |
|    n_updates              | 146      |
|    policy_objective       | 0.0585   |
|    value_loss             | 0.00112  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 301000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 147    |
|    time_elapsed    | 30742  |
|    total_timesteps | 301056 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 302000   |
| train/                    |          |
|    explained_variance     | 0.579    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00576  |
|    learning_rate          | 0.001    |
|    n_updates              | 147      |
|    policy_objective       | 0.048    |
|    value_loss             | 0.000934 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 303000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 148    |
|    time_elapsed    | 30946  |
|    total_timesteps | 303104 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 304000   |
| train/                    |          |
|    explained_variance     | 0.43     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00435  |
|    learning_rate          | 0.001    |
|    n_updates              | 148      |
|    policy_objective       | 0.06     |
|    value_loss             | 0.000855 |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 305000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 149    |
|    time_elapsed    | 31151  |
|    total_timesteps | 305152 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 306000   |
| train/                    |          |
|    explained_variance     | 0.501    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00551  |
|    learning_rate          | 0.001    |
|    n_updates              | 149      |
|    policy_objective       | 0.0498   |
|    value_loss             | 0.0011   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 307000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 150    |
|    time_elapsed    | 31355  |
|    total_timesteps | 307200 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 308000   |
| train/                    |          |
|    explained_variance     | 0.396    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00571  |
|    learning_rate          | 0.001    |
|    n_updates              | 150      |
|    policy_objective       | 0.0536   |
|    value_loss             | 0.00109  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 309000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 151    |
|    time_elapsed    | 31559  |
|    total_timesteps | 309248 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 310000   |
| train/                    |          |
|    explained_variance     | 0.516    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00569  |
|    learning_rate          | 0.001    |
|    n_updates              | 151      |
|    policy_objective       | 0.0542   |
|    value_loss             | 0.00117  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 311000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 152    |
|    time_elapsed    | 31764  |
|    total_timesteps | 311296 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 312000   |
| train/                    |          |
|    explained_variance     | 0.471    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00588  |
|    learning_rate          | 0.001    |
|    n_updates              | 152      |
|    policy_objective       | 0.0541   |
|    value_loss             | 0.00126  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 313000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 153    |
|    time_elapsed    | 31968  |
|    total_timesteps | 313344 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 314000   |
| train/                    |          |
|    explained_variance     | 0.604    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00597  |
|    learning_rate          | 0.001    |
|    n_updates              | 153      |
|    policy_objective       | 0.0511   |
|    value_loss             | 0.0011   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 315000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 154    |
|    time_elapsed    | 32173  |
|    total_timesteps | 315392 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 316000   |
| train/                    |          |
|    explained_variance     | 0.364    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00522  |
|    learning_rate          | 0.001    |
|    n_updates              | 154      |
|    policy_objective       | 0.0525   |
|    value_loss             | 0.00129  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 317000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 155    |
|    time_elapsed    | 32377  |
|    total_timesteps | 317440 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 318000   |
| train/                    |          |
|    explained_variance     | 0.548    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00573  |
|    learning_rate          | 0.001    |
|    n_updates              | 155      |
|    policy_objective       | 0.062    |
|    value_loss             | 0.00108  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 319000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 156    |
|    time_elapsed    | 32581  |
|    total_timesteps | 319488 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 320000   |
| train/                    |          |
|    explained_variance     | 0.622    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00613  |
|    learning_rate          | 0.001    |
|    n_updates              | 156      |
|    policy_objective       | 0.0511   |
|    value_loss             | 0.0012   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 321000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 157    |
|    time_elapsed    | 32786  |
|    total_timesteps | 321536 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 322000   |
| train/                    |          |
|    explained_variance     | 0.423    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00476  |
|    learning_rate          | 0.001    |
|    n_updates              | 157      |
|    policy_objective       | 0.0642   |
|    value_loss             | 0.00123  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 323000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 158    |
|    time_elapsed    | 32990  |
|    total_timesteps | 323584 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 324000   |
| train/                    |          |
|    explained_variance     | 0.585    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00492  |
|    learning_rate          | 0.001    |
|    n_updates              | 158      |
|    policy_objective       | 0.0924   |
|    value_loss             | 0.00135  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 325000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 159    |
|    time_elapsed    | 33195  |
|    total_timesteps | 325632 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 326000   |
| train/                    |          |
|    explained_variance     | 0.581    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00508  |
|    learning_rate          | 0.001    |
|    n_updates              | 159      |
|    policy_objective       | 0.0617   |
|    value_loss             | 0.00148  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 327000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 160    |
|    time_elapsed    | 33399  |
|    total_timesteps | 327680 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 328000   |
| train/                    |          |
|    explained_variance     | 0.672    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00524  |
|    learning_rate          | 0.001    |
|    n_updates              | 160      |
|    policy_objective       | 0.0488   |
|    value_loss             | 0.00162  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 329000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 161    |
|    time_elapsed    | 33603  |
|    total_timesteps | 329728 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 330000   |
| train/                    |          |
|    explained_variance     | 0.479    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00537  |
|    learning_rate          | 0.001    |
|    n_updates              | 161      |
|    policy_objective       | 0.0496   |
|    value_loss             | 0.00185  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 331000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 162    |
|    time_elapsed    | 33808  |
|    total_timesteps | 331776 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 332000   |
| train/                    |          |
|    explained_variance     | 0.558    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00608  |
|    learning_rate          | 0.001    |
|    n_updates              | 162      |
|    policy_objective       | 0.0525   |
|    value_loss             | 0.00157  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 333000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 163    |
|    time_elapsed    | 34012  |
|    total_timesteps | 333824 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 334000   |
| train/                    |          |
|    explained_variance     | 0.55     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00644  |
|    learning_rate          | 0.001    |
|    n_updates              | 163      |
|    policy_objective       | 0.0614   |
|    value_loss             | 0.0012   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 335000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 164    |
|    time_elapsed    | 34217  |
|    total_timesteps | 335872 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 336000   |
| train/                    |          |
|    explained_variance     | 0.557    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00646  |
|    learning_rate          | 0.001    |
|    n_updates              | 164      |
|    policy_objective       | 0.0538   |
|    value_loss             | 0.00146  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 337000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 165    |
|    time_elapsed    | 34421  |
|    total_timesteps | 337920 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 338000   |
| train/                    |          |
|    explained_variance     | 0.747    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.006    |
|    learning_rate          | 0.001    |
|    n_updates              | 165      |
|    policy_objective       | 0.0544   |
|    value_loss             | 0.0011   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 339000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 166    |
|    time_elapsed    | 34625  |
|    total_timesteps | 339968 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 340000   |
| train/                    |          |
|    explained_variance     | 0.694    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00548  |
|    learning_rate          | 0.001    |
|    n_updates              | 166      |
|    policy_objective       | 0.0757   |
|    value_loss             | 0.00115  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 341000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 342000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 167    |
|    time_elapsed    | 34930  |
|    total_timesteps | 342016 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 343000   |
| train/                    |          |
|    explained_variance     | 0.544    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00542  |
|    learning_rate          | 0.001    |
|    n_updates              | 167      |
|    policy_objective       | 0.0713   |
|    value_loss             | 0.00138  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 344000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 168    |
|    time_elapsed    | 35134  |
|    total_timesteps | 344064 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 345000   |
| train/                    |          |
|    explained_variance     | 0.646    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00602  |
|    learning_rate          | 0.001    |
|    n_updates              | 168      |
|    policy_objective       | 0.0569   |
|    value_loss             | 0.00125  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 346000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 169    |
|    time_elapsed    | 35338  |
|    total_timesteps | 346112 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 347000   |
| train/                    |          |
|    explained_variance     | 0.574    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00594  |
|    learning_rate          | 0.001    |
|    n_updates              | 169      |
|    policy_objective       | 0.0595   |
|    value_loss             | 0.00144  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 348000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 170    |
|    time_elapsed    | 35543  |
|    total_timesteps | 348160 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 349000   |
| train/                    |          |
|    explained_variance     | 0.596    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00621  |
|    learning_rate          | 0.001    |
|    n_updates              | 170      |
|    policy_objective       | 0.0577   |
|    value_loss             | 0.00128  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 350000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 171    |
|    time_elapsed    | 35747  |
|    total_timesteps | 350208 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.3      |
| time/                     |          |
|    total_timesteps        | 351000   |
| train/                    |          |
|    explained_variance     | 0.598    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00708  |
|    learning_rate          | 0.001    |
|    n_updates              | 171      |
|    policy_objective       | 0.0531   |
|    value_loss             | 0.00145  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 352000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 172    |
|    time_elapsed    | 35952  |
|    total_timesteps | 352256 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 353000   |
| train/                    |          |
|    explained_variance     | 0.345    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00573  |
|    learning_rate          | 0.001    |
|    n_updates              | 172      |
|    policy_objective       | 0.0473   |
|    value_loss             | 0.00182  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 354000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 173    |
|    time_elapsed    | 36156  |
|    total_timesteps | 354304 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 355000   |
| train/                    |          |
|    explained_variance     | 0.619    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00477  |
|    learning_rate          | 0.001    |
|    n_updates              | 173      |
|    policy_objective       | 0.0585   |
|    value_loss             | 0.0014   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 356000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 174    |
|    time_elapsed    | 36360  |
|    total_timesteps | 356352 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 357000   |
| train/                    |          |
|    explained_variance     | 0.611    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00605  |
|    learning_rate          | 0.001    |
|    n_updates              | 174      |
|    policy_objective       | 0.0615   |
|    value_loss             | 0.00181  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 358000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 175    |
|    time_elapsed    | 36565  |
|    total_timesteps | 358400 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 359000   |
| train/                    |          |
|    explained_variance     | 0.64     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00733  |
|    learning_rate          | 0.001    |
|    n_updates              | 175      |
|    policy_objective       | 0.0564   |
|    value_loss             | 0.00186  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 360000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 176    |
|    time_elapsed    | 36769  |
|    total_timesteps | 360448 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 361000   |
| train/                    |          |
|    explained_variance     | 0.584    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00661  |
|    learning_rate          | 0.001    |
|    n_updates              | 176      |
|    policy_objective       | 0.048    |
|    value_loss             | 0.00128  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 362000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 177    |
|    time_elapsed    | 36974  |
|    total_timesteps | 362496 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 363000   |
| train/                    |          |
|    explained_variance     | 0.66     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00543  |
|    learning_rate          | 0.001    |
|    n_updates              | 177      |
|    policy_objective       | 0.067    |
|    value_loss             | 0.00119  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 364000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 178    |
|    time_elapsed    | 37178  |
|    total_timesteps | 364544 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 365000   |
| train/                    |          |
|    explained_variance     | 0.578    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00722  |
|    learning_rate          | 0.001    |
|    n_updates              | 178      |
|    policy_objective       | 0.0694   |
|    value_loss             | 0.00157  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 366000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 179    |
|    time_elapsed    | 37382  |
|    total_timesteps | 366592 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 367000   |
| train/                    |          |
|    explained_variance     | 0.426    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00592  |
|    learning_rate          | 0.001    |
|    n_updates              | 179      |
|    policy_objective       | 0.0457   |
|    value_loss             | 0.00201  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 368000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 180    |
|    time_elapsed    | 37587  |
|    total_timesteps | 368640 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 369000   |
| train/                    |          |
|    explained_variance     | 0.353    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00589  |
|    learning_rate          | 0.001    |
|    n_updates              | 180      |
|    policy_objective       | 0.0676   |
|    value_loss             | 0.00162  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 370000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 181    |
|    time_elapsed    | 37791  |
|    total_timesteps | 370688 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 371000   |
| train/                    |          |
|    explained_variance     | 0.619    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00705  |
|    learning_rate          | 0.001    |
|    n_updates              | 181      |
|    policy_objective       | 0.0493   |
|    value_loss             | 0.00221  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 372000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 182    |
|    time_elapsed    | 37996  |
|    total_timesteps | 372736 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 373000   |
| train/                    |          |
|    explained_variance     | 0.581    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0063   |
|    learning_rate          | 0.001    |
|    n_updates              | 182      |
|    policy_objective       | 0.0567   |
|    value_loss             | 0.00229  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 374000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 183    |
|    time_elapsed    | 38200  |
|    total_timesteps | 374784 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 375000   |
| train/                    |          |
|    explained_variance     | 0.57     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00608  |
|    learning_rate          | 0.001    |
|    n_updates              | 183      |
|    policy_objective       | 0.0824   |
|    value_loss             | 0.00188  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 376000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 184    |
|    time_elapsed    | 38405  |
|    total_timesteps | 376832 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.6      |
| time/                     |          |
|    total_timesteps        | 377000   |
| train/                    |          |
|    explained_variance     | 0.556    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00538  |
|    learning_rate          | 0.001    |
|    n_updates              | 184      |
|    policy_objective       | 0.0585   |
|    value_loss             | 0.00151  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 378000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 185    |
|    time_elapsed    | 38609  |
|    total_timesteps | 378880 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.6      |
| time/                     |          |
|    total_timesteps        | 379000   |
| train/                    |          |
|    explained_variance     | 0.576    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00575  |
|    learning_rate          | 0.001    |
|    n_updates              | 185      |
|    policy_objective       | 0.0622   |
|    value_loss             | 0.00149  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 380000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 186    |
|    time_elapsed    | 38814  |
|    total_timesteps | 380928 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 381000   |
| train/                    |          |
|    explained_variance     | 0.449    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00645  |
|    learning_rate          | 0.001    |
|    n_updates              | 186      |
|    policy_objective       | 0.0543   |
|    value_loss             | 0.0016   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 382000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 187    |
|    time_elapsed    | 39018  |
|    total_timesteps | 382976 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 383000   |
| train/                    |          |
|    explained_variance     | 0.527    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00532  |
|    learning_rate          | 0.001    |
|    n_updates              | 187      |
|    policy_objective       | 0.0537   |
|    value_loss             | 0.00179  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 384000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 385000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 188    |
|    time_elapsed    | 39322  |
|    total_timesteps | 385024 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 386000   |
| train/                    |          |
|    explained_variance     | 0.449    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00655  |
|    learning_rate          | 0.001    |
|    n_updates              | 188      |
|    policy_objective       | 0.0526   |
|    value_loss             | 0.00231  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 387000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 189    |
|    time_elapsed    | 39527  |
|    total_timesteps | 387072 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 388000   |
| train/                    |          |
|    explained_variance     | 0.527    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00727  |
|    learning_rate          | 0.001    |
|    n_updates              | 189      |
|    policy_objective       | 0.0439   |
|    value_loss             | 0.00243  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 389000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 190    |
|    time_elapsed    | 39731  |
|    total_timesteps | 389120 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 390000   |
| train/                    |          |
|    explained_variance     | 0.586    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00746  |
|    learning_rate          | 0.001    |
|    n_updates              | 190      |
|    policy_objective       | 0.049    |
|    value_loss             | 0.00162  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 391000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 191    |
|    time_elapsed    | 39936  |
|    total_timesteps | 391168 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 392000   |
| train/                    |          |
|    explained_variance     | 0.767    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00737  |
|    learning_rate          | 0.001    |
|    n_updates              | 191      |
|    policy_objective       | 0.0766   |
|    value_loss             | 0.00203  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 393000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 192    |
|    time_elapsed    | 40140  |
|    total_timesteps | 393216 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 394000   |
| train/                    |          |
|    explained_variance     | 0.597    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00659  |
|    learning_rate          | 0.001    |
|    n_updates              | 192      |
|    policy_objective       | 0.058    |
|    value_loss             | 0.00178  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 395000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 193    |
|    time_elapsed    | 40345  |
|    total_timesteps | 395264 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 396000   |
| train/                    |          |
|    explained_variance     | 0.563    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00564  |
|    learning_rate          | 0.001    |
|    n_updates              | 193      |
|    policy_objective       | 0.064    |
|    value_loss             | 0.00154  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 397000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 194    |
|    time_elapsed    | 40549  |
|    total_timesteps | 397312 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 398000   |
| train/                    |          |
|    explained_variance     | 0.527    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00751  |
|    learning_rate          | 0.001    |
|    n_updates              | 194      |
|    policy_objective       | 0.0595   |
|    value_loss             | 0.00156  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 399000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 195    |
|    time_elapsed    | 40754  |
|    total_timesteps | 399360 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 400000   |
| train/                    |          |
|    explained_variance     | 0.527    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00621  |
|    learning_rate          | 0.001    |
|    n_updates              | 195      |
|    policy_objective       | 0.0434   |
|    value_loss             | 0.00246  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 401000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 196    |
|    time_elapsed    | 40958  |
|    total_timesteps | 401408 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 402000   |
| train/                    |          |
|    explained_variance     | 0.596    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00677  |
|    learning_rate          | 0.001    |
|    n_updates              | 196      |
|    policy_objective       | 0.0494   |
|    value_loss             | 0.00221  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 403000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 197    |
|    time_elapsed    | 41162  |
|    total_timesteps | 403456 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 404000   |
| train/                    |          |
|    explained_variance     | 0.588    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00661  |
|    learning_rate          | 0.001    |
|    n_updates              | 197      |
|    policy_objective       | 0.0612   |
|    value_loss             | 0.00194  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 405000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 198    |
|    time_elapsed    | 41367  |
|    total_timesteps | 405504 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 406000   |
| train/                    |          |
|    explained_variance     | 0.62     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00711  |
|    learning_rate          | 0.001    |
|    n_updates              | 198      |
|    policy_objective       | 0.0509   |
|    value_loss             | 0.0023   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 407000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 199    |
|    time_elapsed    | 41571  |
|    total_timesteps | 407552 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 408000   |
| train/                    |          |
|    explained_variance     | 0.524    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00701  |
|    learning_rate          | 0.001    |
|    n_updates              | 199      |
|    policy_objective       | 0.0566   |
|    value_loss             | 0.00249  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 409000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 200    |
|    time_elapsed    | 41776  |
|    total_timesteps | 409600 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 410000   |
| train/                    |          |
|    explained_variance     | 0.595    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00563  |
|    learning_rate          | 0.001    |
|    n_updates              | 200      |
|    policy_objective       | 0.0521   |
|    value_loss             | 0.00231  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 411000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 201    |
|    time_elapsed    | 41980  |
|    total_timesteps | 411648 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 412000   |
| train/                    |          |
|    explained_variance     | 0.601    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00613  |
|    learning_rate          | 0.001    |
|    n_updates              | 201      |
|    policy_objective       | 0.0566   |
|    value_loss             | 0.002    |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 413000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 202    |
|    time_elapsed    | 42185  |
|    total_timesteps | 413696 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 414000   |
| train/                    |          |
|    explained_variance     | 0.431    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00694  |
|    learning_rate          | 0.001    |
|    n_updates              | 202      |
|    policy_objective       | 0.0632   |
|    value_loss             | 0.0018   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 415000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 203    |
|    time_elapsed    | 42389  |
|    total_timesteps | 415744 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 416000   |
| train/                    |          |
|    explained_variance     | 0.428    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00824  |
|    learning_rate          | 0.001    |
|    n_updates              | 203      |
|    policy_objective       | 0.0492   |
|    value_loss             | 0.00287  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 417000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 204    |
|    time_elapsed    | 42594  |
|    total_timesteps | 417792 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 418000   |
| train/                    |          |
|    explained_variance     | 0.508    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00609  |
|    learning_rate          | 0.001    |
|    n_updates              | 204      |
|    policy_objective       | 0.0551   |
|    value_loss             | 0.00246  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 419000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 205    |
|    time_elapsed    | 42798  |
|    total_timesteps | 419840 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 420000   |
| train/                    |          |
|    explained_variance     | 0.448    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00635  |
|    learning_rate          | 0.001    |
|    n_updates              | 205      |
|    policy_objective       | 0.0549   |
|    value_loss             | 0.00263  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 421000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 206    |
|    time_elapsed    | 43002  |
|    total_timesteps | 421888 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 422000   |
| train/                    |          |
|    explained_variance     | 0.444    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00657  |
|    learning_rate          | 0.001    |
|    n_updates              | 206      |
|    policy_objective       | 0.0739   |
|    value_loss             | 0.00186  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 423000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 207    |
|    time_elapsed    | 43207  |
|    total_timesteps | 423936 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 424000   |
| train/                    |          |
|    explained_variance     | 0.612    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00575  |
|    learning_rate          | 0.001    |
|    n_updates              | 207      |
|    policy_objective       | 0.0619   |
|    value_loss             | 0.00218  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 425000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 208    |
|    time_elapsed    | 43411  |
|    total_timesteps | 425984 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 426000   |
| train/                    |          |
|    explained_variance     | 0.644    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00754  |
|    learning_rate          | 0.001    |
|    n_updates              | 208      |
|    policy_objective       | 0.0473   |
|    value_loss             | 0.00216  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 427000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 428000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 209    |
|    time_elapsed    | 43716  |
|    total_timesteps | 428032 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 429000   |
| train/                    |          |
|    explained_variance     | 0.525    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00777  |
|    learning_rate          | 0.001    |
|    n_updates              | 209      |
|    policy_objective       | 0.0501   |
|    value_loss             | 0.00267  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 430000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 210    |
|    time_elapsed    | 43920  |
|    total_timesteps | 430080 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 431000   |
| train/                    |          |
|    explained_variance     | 0.526    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00607  |
|    learning_rate          | 0.001    |
|    n_updates              | 210      |
|    policy_objective       | 0.0498   |
|    value_loss             | 0.00235  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 432000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 211    |
|    time_elapsed    | 44124  |
|    total_timesteps | 432128 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 433000   |
| train/                    |          |
|    explained_variance     | 0.536    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00728  |
|    learning_rate          | 0.001    |
|    n_updates              | 211      |
|    policy_objective       | 0.0464   |
|    value_loss             | 0.00198  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 434000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 212    |
|    time_elapsed    | 44329  |
|    total_timesteps | 434176 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 435000   |
| train/                    |          |
|    explained_variance     | 0.595    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00644  |
|    learning_rate          | 0.001    |
|    n_updates              | 212      |
|    policy_objective       | 0.0577   |
|    value_loss             | 0.00193  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 436000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 213    |
|    time_elapsed    | 44533  |
|    total_timesteps | 436224 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.4      |
| time/                     |          |
|    total_timesteps        | 437000   |
| train/                    |          |
|    explained_variance     | 0.786    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00711  |
|    learning_rate          | 0.001    |
|    n_updates              | 213      |
|    policy_objective       | 0.0572   |
|    value_loss             | 0.00137  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 438000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 214    |
|    time_elapsed    | 44738  |
|    total_timesteps | 438272 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 439000   |
| train/                    |          |
|    explained_variance     | 0.58     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00715  |
|    learning_rate          | 0.001    |
|    n_updates              | 214      |
|    policy_objective       | 0.0424   |
|    value_loss             | 0.00241  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 440000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 215    |
|    time_elapsed    | 44942  |
|    total_timesteps | 440320 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 441000   |
| train/                    |          |
|    explained_variance     | 0.59     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00539  |
|    learning_rate          | 0.001    |
|    n_updates              | 215      |
|    policy_objective       | 0.055    |
|    value_loss             | 0.00195  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 442000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 216    |
|    time_elapsed    | 45147  |
|    total_timesteps | 442368 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 443000   |
| train/                    |          |
|    explained_variance     | 0.63     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00511  |
|    learning_rate          | 0.001    |
|    n_updates              | 216      |
|    policy_objective       | 0.0604   |
|    value_loss             | 0.00219  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 444000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 217    |
|    time_elapsed    | 45351  |
|    total_timesteps | 444416 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 445000   |
| train/                    |          |
|    explained_variance     | 0.753    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00659  |
|    learning_rate          | 0.001    |
|    n_updates              | 217      |
|    policy_objective       | 0.0551   |
|    value_loss             | 0.00215  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 446000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 218    |
|    time_elapsed    | 45556  |
|    total_timesteps | 446464 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 447000   |
| train/                    |          |
|    explained_variance     | 0.509    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00631  |
|    learning_rate          | 0.001    |
|    n_updates              | 218      |
|    policy_objective       | 0.055    |
|    value_loss             | 0.00191  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 448000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 219    |
|    time_elapsed    | 45760  |
|    total_timesteps | 448512 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.5      |
| time/                     |          |
|    total_timesteps        | 449000   |
| train/                    |          |
|    explained_variance     | 0.464    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00733  |
|    learning_rate          | 0.001    |
|    n_updates              | 219      |
|    policy_objective       | 0.0498   |
|    value_loss             | 0.00231  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 450000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 220    |
|    time_elapsed    | 45964  |
|    total_timesteps | 450560 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 451000   |
| train/                    |          |
|    explained_variance     | 0.458    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00631  |
|    learning_rate          | 0.001    |
|    n_updates              | 220      |
|    policy_objective       | 0.0527   |
|    value_loss             | 0.00242  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 452000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 221    |
|    time_elapsed    | 46169  |
|    total_timesteps | 452608 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 453000   |
| train/                    |          |
|    explained_variance     | 0.534    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00614  |
|    learning_rate          | 0.001    |
|    n_updates              | 221      |
|    policy_objective       | 0.057    |
|    value_loss             | 0.00246  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 454000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 222    |
|    time_elapsed    | 46373  |
|    total_timesteps | 454656 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 455000   |
| train/                    |          |
|    explained_variance     | 0.557    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00841  |
|    learning_rate          | 0.001    |
|    n_updates              | 222      |
|    policy_objective       | 0.0696   |
|    value_loss             | 0.00293  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 456000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 223    |
|    time_elapsed    | 46578  |
|    total_timesteps | 456704 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 457000   |
| train/                    |          |
|    explained_variance     | 0.597    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00679  |
|    learning_rate          | 0.001    |
|    n_updates              | 223      |
|    policy_objective       | 0.0564   |
|    value_loss             | 0.00261  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 458000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 224    |
|    time_elapsed    | 46782  |
|    total_timesteps | 458752 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 459000   |
| train/                    |          |
|    explained_variance     | 0.731    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00609  |
|    learning_rate          | 0.001    |
|    n_updates              | 224      |
|    policy_objective       | 0.0495   |
|    value_loss             | 0.00242  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 460000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 225    |
|    time_elapsed    | 46986  |
|    total_timesteps | 460800 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 461000   |
| train/                    |          |
|    explained_variance     | 0.617    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0066   |
|    learning_rate          | 0.001    |
|    n_updates              | 225      |
|    policy_objective       | 0.0531   |
|    value_loss             | 0.00225  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 462000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 226    |
|    time_elapsed    | 47191  |
|    total_timesteps | 462848 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 463000   |
| train/                    |          |
|    explained_variance     | 0.517    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00693  |
|    learning_rate          | 0.001    |
|    n_updates              | 226      |
|    policy_objective       | 0.0527   |
|    value_loss             | 0.00293  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 464000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 227    |
|    time_elapsed    | 47395  |
|    total_timesteps | 464896 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 465000   |
| train/                    |          |
|    explained_variance     | 0.56     |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00582  |
|    learning_rate          | 0.001    |
|    n_updates              | 227      |
|    policy_objective       | 0.0805   |
|    value_loss             | 0.0015   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 466000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 228    |
|    time_elapsed    | 47600  |
|    total_timesteps | 466944 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 467000   |
| train/                    |          |
|    explained_variance     | 0.538    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00889  |
|    learning_rate          | 0.001    |
|    n_updates              | 228      |
|    policy_objective       | 0.0767   |
|    value_loss             | 0.00297  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 468000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 229    |
|    time_elapsed    | 47804  |
|    total_timesteps | 468992 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 469000   |
| train/                    |          |
|    explained_variance     | 0.489    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00579  |
|    learning_rate          | 0.001    |
|    n_updates              | 229      |
|    policy_objective       | 0.078    |
|    value_loss             | 0.00235  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 470000   |
---------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 471000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 230    |
|    time_elapsed    | 48109  |
|    total_timesteps | 471040 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 472000   |
| train/                    |          |
|    explained_variance     | 0.628    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00726  |
|    learning_rate          | 0.001    |
|    n_updates              | 230      |
|    policy_objective       | 0.0558   |
|    value_loss             | 0.00248  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 473000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 231    |
|    time_elapsed    | 48313  |
|    total_timesteps | 473088 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 474000   |
| train/                    |          |
|    explained_variance     | 0.752    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.0068   |
|    learning_rate          | 0.001    |
|    n_updates              | 231      |
|    policy_objective       | 0.0473   |
|    value_loss             | 0.00207  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 475000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 232    |
|    time_elapsed    | 48518  |
|    total_timesteps | 475136 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 476000   |
| train/                    |          |
|    explained_variance     | 0.714    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00692  |
|    learning_rate          | 0.001    |
|    n_updates              | 232      |
|    policy_objective       | 0.0396   |
|    value_loss             | 0.00307  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 477000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 233    |
|    time_elapsed    | 48722  |
|    total_timesteps | 477184 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 478000   |
| train/                    |          |
|    explained_variance     | 0.647    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00785  |
|    learning_rate          | 0.001    |
|    n_updates              | 233      |
|    policy_objective       | 0.0505   |
|    value_loss             | 0.00303  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 479000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 234    |
|    time_elapsed    | 48926  |
|    total_timesteps | 479232 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 480000   |
| train/                    |          |
|    explained_variance     | 0.672    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00432  |
|    learning_rate          | 0.001    |
|    n_updates              | 234      |
|    policy_objective       | 0.0662   |
|    value_loss             | 0.00203  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 481000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 235    |
|    time_elapsed    | 49131  |
|    total_timesteps | 481280 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.2      |
| time/                     |          |
|    total_timesteps        | 482000   |
| train/                    |          |
|    explained_variance     | 0.679    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00783  |
|    learning_rate          | 0.001    |
|    n_updates              | 235      |
|    policy_objective       | 0.0505   |
|    value_loss             | 0.0025   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 483000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 236    |
|    time_elapsed    | 49335  |
|    total_timesteps | 483328 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 484000   |
| train/                    |          |
|    explained_variance     | 0.815    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00702  |
|    learning_rate          | 0.001    |
|    n_updates              | 236      |
|    policy_objective       | 0.0468   |
|    value_loss             | 0.0027   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 485000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 237    |
|    time_elapsed    | 49540  |
|    total_timesteps | 485376 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 486000   |
| train/                    |          |
|    explained_variance     | 0.701    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00753  |
|    learning_rate          | 0.001    |
|    n_updates              | 237      |
|    policy_objective       | 0.0523   |
|    value_loss             | 0.00252  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 487000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 238    |
|    time_elapsed    | 49744  |
|    total_timesteps | 487424 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 488000   |
| train/                    |          |
|    explained_variance     | 0.612    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00891  |
|    learning_rate          | 0.001    |
|    n_updates              | 238      |
|    policy_objective       | 0.0362   |
|    value_loss             | 0.00312  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 489000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 239    |
|    time_elapsed    | 49949  |
|    total_timesteps | 489472 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 490000   |
| train/                    |          |
|    explained_variance     | 0.789    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00711  |
|    learning_rate          | 0.001    |
|    n_updates              | 239      |
|    policy_objective       | 0.0491   |
|    value_loss             | 0.00262  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 491000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 240    |
|    time_elapsed    | 50153  |
|    total_timesteps | 491520 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 492000   |
| train/                    |          |
|    explained_variance     | 0.882    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00648  |
|    learning_rate          | 0.001    |
|    n_updates              | 240      |
|    policy_objective       | 0.0503   |
|    value_loss             | 0.00154  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 493000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 241    |
|    time_elapsed    | 50357  |
|    total_timesteps | 493568 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 494000   |
| train/                    |          |
|    explained_variance     | 0.541    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00662  |
|    learning_rate          | 0.001    |
|    n_updates              | 241      |
|    policy_objective       | 0.0622   |
|    value_loss             | 0.00193  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 495000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 242    |
|    time_elapsed    | 50562  |
|    total_timesteps | 495616 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 496000   |
| train/                    |          |
|    explained_variance     | 0.662    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00932  |
|    learning_rate          | 0.001    |
|    n_updates              | 242      |
|    policy_objective       | 0.0483   |
|    value_loss             | 0.00308  |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 497000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 243    |
|    time_elapsed    | 50766  |
|    total_timesteps | 497664 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 498000   |
| train/                    |          |
|    explained_variance     | 0.758    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00719  |
|    learning_rate          | 0.001    |
|    n_updates              | 243      |
|    policy_objective       | 0.0731   |
|    value_loss             | 0.0021   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 499000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 244    |
|    time_elapsed    | 50971  |
|    total_timesteps | 499712 |
-------------------------------
----------------------------------------
| eval/                     |          |
|    mean_ep_length         | 1e+04    |
|    mean_reward            | 0.7      |
| time/                     |          |
|    total_timesteps        | 500000   |
| train/                    |          |
|    explained_variance     | 0.568    |
|    is_line_search_success | 1        |
|    kl_divergence_loss     | 0.00773  |
|    learning_rate          | 0.001    |
|    n_updates              | 244      |
|    policy_objective       | 0.0416   |
|    value_loss             | 0.0037   |
----------------------------------------
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+04    |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 501000   |
---------------------------------
-------------------------------
| time/              |        |
|    fps             | 9      |
|    iterations      | 245    |
|    time_elapsed    | 51175  |
|    total_timesteps | 501760 |
-------------------------------
